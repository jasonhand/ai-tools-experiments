[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.9.0","content-config-digest","3473618981a7e9db","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"file\",\"client\":{},\"server\":{},\"assets\":\"assets\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"experimentalDefaultStyles\":true},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"csp\":false},\"legacy\":{\"collections\":false}}","episodes",["Map",11,12,108,109,195,196,280,281,356,357,435,436,516,517,594,595,662,663,747,748,841,842,928,929,1023,1024,1121,1122,1230,1231,1331,1332,1434,1435,1530,1531,1621,1622,1707,1708,1801,1802,1892,1893,1983,1984,2093,2094,2203,2204,2260,2261,2332,2333,2424,2425,2519,2520,2613,2614,2708,2709],"ep01",{"id":11,"data":13,"body":103,"filePath":105,"digest":106,"legacyId":107,"deferredRender":104},{"title":14,"description":15,"heroImg":16,"videoId":17,"episodeNumber":18,"date":19,"author":20,"participants":21,"tags":24,"takeaways":27,"resources":49,"jumpTo":66,"summary":103,"featured":54,"transcriptAvailable":104},"Building Quick Web Interfaces for Machine Learning Models with Gradio","Exploring how to build simple but effective web interfaces for machine learning models using Gradio, allowing non-technical users to interact with ML systems.","../images/thumbnails/ep01.png","hESEOJRZ-wc",1,"2025-04-26T00:00:00.000Z","jasonhand24@gmail.com",[22,23],"Jason Hand","Ryan MacLean",[25,26],"web-dev","ml-models",[28,33,36,40,43,46],{"text":29,"tools":30},"Gradio is a very easy way to get a Huggingface Space locally (via `load`)",[31,32],"Gradio","Hugging Face",{"text":34,"tools":35},"It provides a simple way to build frontends for ML applications",[31],{"text":37,"tools":38},"When installing, make sure to create a virtual environment first",[39,31],"Python",{"text":41,"tools":42},"Ensure to install Gradio in that environment after activation",[31,39],{"text":44,"tools":45},"Do not try to run your project in the `Gradio` repo by mistake",[31],{"text":47,"tools":48},"Gradio is particularly useful for quickly creating interfaces to demonstrate ML models",[31],[50,55,59,62],{"name":51,"url":52,"description":53,"featured":54},"Gradio Quickstart","https://www.gradio.app/guides/quickstart","Official quickstart guide for getting started with Gradio",false,{"name":56,"url":57,"description":58,"featured":54},"Gradio Install","https://github.com/gradio-app/gradio","Installation instructions and repository for Gradio",{"name":60,"url":57,"description":61,"featured":54},"Gradio Repository","Main GitHub repository for the Gradio project",{"name":63,"url":64,"description":65,"featured":54},"Gradio `load`","https://www.gradio.app/docs/gradio/load","Documentation for loading Hugging Face spaces with Gradio",[67,71,75,79,83,87,91,95,99],{"title":68,"url":69,"timestamp":70},"Introduction to AI Lab Experiments project","https://youtu.be/hESEOJRZ-wc?t=0","00:00:00",{"title":72,"url":73,"timestamp":74},"Jason sharing his process for tracking AI tools","https://youtu.be/hESEOJRZ-wc?t=66","00:01:06",{"title":76,"url":77,"timestamp":78},"Ryan explains his work with image generation models","https://youtu.be/hESEOJRZ-wc?t=149","00:02:29",{"title":80,"url":81,"timestamp":82},"Setting up a virtual environment and installing Gradio","https://youtu.be/hESEOJRZ-wc?t=303","00:05:03",{"title":84,"url":85,"timestamp":86},"Jason's thoughts on creating interfaces","https://youtu.be/hESEOJRZ-wc?t=462","00:07:42",{"title":88,"url":89,"timestamp":90},"Discussion about HuggingFace spaces","https://youtu.be/hESEOJRZ-wc?t=509","00:08:29",{"title":92,"url":93,"timestamp":94},"Testing image generation through Gradio","https://youtu.be/hESEOJRZ-wc?t=676","00:11:16",{"title":96,"url":97,"timestamp":98},"Why you would use Gradio","https://youtu.be/hESEOJRZ-wc?t=961","00:16:01",{"title":100,"url":101,"timestamp":102},"Wrapping up and plans for next tool exploration","https://youtu.be/hESEOJRZ-wc?t=1087","00:18:07","What if you could turn any machine learning model into a web app with just three lines of Python code? Jason Hand and Ryan MacLean kick off their AI Lab Experiments project by tackling this exact challenge with Gradio. Ryan walks through the surprisingly simple process of creating web interfaces for ML models, from setting up virtual environments to loading Hugging Face spaces locally. Watch as they transform complex AI models into user-friendly interfaces, including a question-answering system and image generation tool. Perfect for backend developers who want to showcase their ML work without diving into JavaScript frameworks.",true,"src/content/episodes/ep01.mdx","d4d521da2c309a29","ep01.mdx","ep02",{"id":108,"data":110,"body":191,"filePath":192,"digest":193,"legacyId":194,"deferredRender":104},{"title":111,"description":112,"heroImg":113,"videoId":114,"episodeNumber":115,"date":19,"author":20,"participants":116,"tags":117,"takeaways":120,"resources":144,"jumpTo":151,"summary":191,"featured":54,"transcriptAvailable":104},"Exploring Warp Terminal and Cursor for Productivity","A walkthrough of Warp Terminal and Cursor IDE, demonstrating how these AI-enhanced tools can significantly boost developer productivity and workflow.","../images/thumbnails/ep02.png","QYTe2BBhN1c",2,[22,23],[118,119],"productivity","cursor",[121,125,128,131,135,138,141],{"text":122,"tools":123},"Warp Terminal offers a more intuitive terminal experience compared to traditional terminals",[124],"Warp Terminal",{"text":126,"tools":127},"Warp's AI features help with command discovery and syntax",[124],{"text":129,"tools":130},"Warp is great for both beginners and experienced developers",[124],{"text":132,"tools":133},"Cursor streamlines the coding process with AI assistance",[134],"Cursor",{"text":136,"tools":137},"Cursor is excellent for code review and refactoring",[134],{"text":139,"tools":140},"Cursor helps write better documentation",[134],{"text":142,"tools":143},"Cursor is useful for learning new programming concepts through AI explanations",[134],[145,148],{"name":124,"url":146,"description":147,"featured":54},"https://warp.dev/","Modern AI-powered terminal application with intelligent command assistance",{"name":134,"url":149,"description":150,"featured":54},"https://cursor.sh/","AI-enhanced code editor built on VSCode for improved development workflow",[152,155,159,163,167,171,175,179,183,187],{"title":153,"url":154,"timestamp":70},"Introduction to Warp Terminal","https://youtu.be/QYTe2BBhN1c?t=0",{"title":156,"url":157,"timestamp":158},"Features of Warp Terminal","https://youtu.be/QYTe2BBhN1c?t=180","00:03:00",{"title":160,"url":161,"timestamp":162},"Introduction to Cursor","https://youtu.be/QYTe2BBhN1c?t=360","00:06:00",{"title":164,"url":165,"timestamp":166},"Reviewing Python code with Cursor","https://youtu.be/QYTe2BBhN1c?t=540","00:09:00",{"title":168,"url":169,"timestamp":170},"PEP8 formatting assistance","https://youtu.be/QYTe2BBhN1c?t=720","00:12:00",{"title":172,"url":173,"timestamp":174},"Fixing Datadog API integration","https://youtu.be/QYTe2BBhN1c?t=900","00:15:00",{"title":176,"url":177,"timestamp":178},"API key environment variables","https://youtu.be/QYTe2BBhN1c?t=1080","00:18:00",{"title":180,"url":181,"timestamp":182},"Cursor's documentation capabilities","https://youtu.be/QYTe2BBhN1c?t=1260","00:21:00",{"title":184,"url":185,"timestamp":186},"Comparing AI tools and workflows","https://youtu.be/QYTe2BBhN1c?t=1440","00:24:00",{"title":188,"url":189,"timestamp":190},"Final thoughts and conclusion","https://youtu.be/QYTe2BBhN1c?t=1620","00:27:00","Your terminal and code editor are about to get a major AI upgrade. Jason and Ryan dive deep into two game-changing developer tools that are reshaping how we write and execute code. First up is Warp Terminal, which transforms the command line from a cryptic black box into an intelligent assistant that actually understands what you're trying to do. Then they explore Cursor, the AI-enhanced editor that doesn't just autocomplete—it refactors, documents, and explains your code like a knowledgeable pair programmer. Watch them tackle real Python code improvements, from PEP8 formatting to Datadog API integration, showing how AI can elevate your coding workflow without getting in the way.","src/content/episodes/ep02.mdx","b3a28347c119350b","ep02.mdx","ep03",{"id":195,"data":197,"body":276,"filePath":277,"digest":278,"legacyId":279,"deferredRender":104},{"title":198,"description":199,"heroImg":200,"videoId":201,"episodeNumber":202,"date":19,"author":20,"participants":203,"tags":204,"takeaways":206,"resources":224,"jumpTo":236,"summary":276,"featured":54,"transcriptAvailable":104},"Automatic1111 and Local Text-to-Image Generation","A guide to setting up and using Automatic1111 for local text-to-image generation, covering installation, configuration, and effective prompt techniques.","../images/thumbnails/ep03.png","l2H0HADOa5o",3,[22,23],[205],"image-gen",[207,212,215,218,221],{"text":208,"tools":209},"Automatic1111 provides a web UI for Stable Diffusion image generation models",[210,211],"Automatic1111","Stable Diffusion",{"text":213,"tools":214},"Local image generation is slower but offers privacy, offline access, and cost savings",[210],{"text":216,"tools":217},"Older models like SD 1.5 have limitations but are faster than newer ones",[211],{"text":219,"tools":220},"Prompt engineering with positive and negative prompts can improve generation results",[210],{"text":222,"tools":223},"The tool can be useful for brainstorming, ideation, and inspiration rather than final assets",[210],[225,229,232],{"name":226,"url":227,"description":228,"featured":54},"Automatic1111 GitHub Repository","https://github.com/AUTOMATIC1111/stable-diffusion-webui","Main repository for the Stable Diffusion web UI",{"name":211,"url":230,"description":231,"featured":54},"https://stability.ai/stable-diffusion","Official Stable Diffusion model and documentation",{"name":233,"url":234,"description":235,"featured":54},"Hugging Face Spaces","https://huggingface.co/spaces","Collection of AI model demos and spaces",[237,240,244,248,252,256,260,264,268,272],{"title":238,"url":239,"timestamp":70},"Introduction to Automatic1111","https://youtu.be/l2H0HADOa5o?t=0",{"title":241,"url":242,"timestamp":243},"Overview of Automatic1111 and its features","https://youtu.be/l2H0HADOa5o?t=184","00:03:04",{"title":245,"url":246,"timestamp":247},"Installing Automatic1111 and connection to Gradio","https://youtu.be/l2H0HADOa5o?t=317","00:05:17",{"title":249,"url":250,"timestamp":251},"Discussing options for local vs. cloud deployment","https://youtu.be/l2H0HADOa5o?t=411","00:06:51",{"title":253,"url":254,"timestamp":255},"First image generation attempt","https://youtu.be/l2H0HADOa5o?t=486","00:08:06",{"title":257,"url":258,"timestamp":259},"Prompt engineering techniques for better results","https://youtu.be/l2H0HADOa5o?t=633","00:10:33",{"title":261,"url":262,"timestamp":263},"Working with negative prompts","https://youtu.be/l2H0HADOa5o?t=737","00:12:17",{"title":265,"url":266,"timestamp":267},"Comparing local generation vs. online options","https://youtu.be/l2H0HADOa5o?t=979","00:16:19",{"title":269,"url":270,"timestamp":271},"Limitations of older Stable Diffusion models","https://youtu.be/l2H0HADOa5o?t=1153","00:19:13",{"title":273,"url":274,"timestamp":275},"Final thoughts and practical applications","https://youtu.be/l2H0HADOa5o?t=1389","00:23:09","Forget expensive cloud services and API limits—what if you could generate unlimited AI images right on your own machine? Ryan and Jason take us through the wild world of Automatic1111, the Swiss Army knife of local image generation. From wrestling with installation quirks to mastering the art of prompt engineering, watch as simple text descriptions transform into visual reality. Jason explores everything from basic text-to-image generation to advanced techniques like inpainting and img2img conversion, revealing why running Stable Diffusion locally might be slower than cloud alternatives, but offers something far more valuable: complete creative freedom.","src/content/episodes/ep03.mdx","fdb221a1a6ed7cbb","ep03.mdx","ep04",{"id":280,"data":282,"body":352,"filePath":353,"digest":354,"legacyId":355,"deferredRender":104},{"title":283,"description":284,"heroImg":285,"videoId":286,"episodeNumber":287,"date":19,"author":20,"participants":288,"tags":289,"takeaways":291,"resources":311,"jumpTo":324,"summary":352,"featured":54,"transcriptAvailable":104},"Building a Secure Feedback Form with Datadog Logs with Claude Code","How to create a secure feedback form that captures user input and sends it to Datadog for logging and analysis, built with Claude Code assistance.","../images/thumbnails/ep04.png","ciLO96MDFbE",4,[22],[25,290],"claude",[292,296,301,304,308],{"text":293,"tools":294},"Claude Code can effectively help build functional websites and solve complex integration challenges",[295],"Claude Code",{"text":297,"tools":298},"GitHub Pages has CORS limitations for API calls, while Netlify offers better support for dynamic functionality",[299,300],"GitHub Pages","Netlify",{"text":302,"tools":303},"Environment variables in Netlify provide a secure way to store API keys",[300],{"text":305,"tools":306},"Static websites can be enhanced with third-party services through secure API integrations",[307],"Datadog",{"text":309,"tools":310},"Datadog can be used in creative ways, such as capturing form submissions as logs",[307],[312,316,320],{"name":313,"url":314,"description":315,"featured":54},"Claude Code GitHub","https://github.com/anthropics/claude-code","AI-powered coding assistant for building applications",{"name":317,"url":318,"description":319,"featured":54},"Netlify Documentation","https://docs.netlify.com/","Documentation for Netlify hosting and deployment platform",{"name":321,"url":322,"description":323,"featured":54},"Datadog API Documentation","https://docs.datadoghq.com/api/latest/","Complete API reference for Datadog services",[325,328,332,335,339,342,346,349],{"title":326,"url":327,"timestamp":70},"Introduction to Claude Code and project goals","https://youtu.be/ciLO96MDFbE?t=0",{"title":329,"url":330,"timestamp":331},"Explaining the Datadog logging integration plan","https://youtu.be/ciLO96MDFbE?t=120","00:02:00",{"title":333,"url":334,"timestamp":158},"Discussing GitHub Pages limitations and secrets","https://youtu.be/ciLO96MDFbE?t=180",{"title":336,"url":337,"timestamp":338},"Overview of GitHub actions for deployment","https://youtu.be/ciLO96MDFbE?t=300","00:05:00",{"title":340,"url":341,"timestamp":162},"Previous experience with Claude Code","https://youtu.be/ciLO96MDFbE?t=360",{"title":343,"url":344,"timestamp":345},"Setting up the Claude Code environment","https://youtu.be/ciLO96MDFbE?t=480","00:08:00",{"title":347,"url":348,"timestamp":166},"Crafting detailed instructions for Claude Code","https://youtu.be/ciLO96MDFbE?t=540",{"title":350,"url":351,"timestamp":170},"Waiting for Claude Code's file generation","https://youtu.be/ciLO96MDFbE?t=720","Can AI actually build a production-ready web application from scratch? Jason puts Claude Code to the ultimate test, tasking it with creating a secure feedback form that integrates with Datadog's logging API. What starts as a simple request quickly becomes a masterclass in real-world development challenges: navigating GitHub Pages limitations, wrestling with CORS policies, and implementing secure API key management. Watch as human creativity meets AI capability, revealing both the impressive potential and practical limitations of AI-assisted development.","src/content/episodes/ep04.mdx","5d8ed5763cf56bb2","ep04.mdx","ep05",{"id":356,"data":358,"body":431,"filePath":432,"digest":433,"legacyId":434,"deferredRender":104},{"title":359,"description":360,"heroImg":361,"videoId":362,"episodeNumber":363,"date":19,"author":20,"participants":364,"tags":365,"takeaways":366,"resources":385,"jumpTo":393,"summary":431,"featured":54,"transcriptAvailable":104},"Using Claude Code for Automated HTML Updates and Styling","A demonstration of how Claude Code can automate HTML updates and apply consistent styling across a website, improving efficiency and maintainability.","../images/thumbnails/ep05.png","5ovKpnUeCb8",5,[22],[25,290],[367,370,373,376,379,382],{"text":368,"tools":369},"Claude Code can efficiently update HTML/CSS without requiring manual coding",[295],{"text":371,"tools":372},"Using AI assistants for website maintenance saves significant time",[295],{"text":374,"tools":375},"Consistent styling across pages improves user experience",[295],{"text":377,"tools":378},"Adding proper navigation and chapter markers enhances content accessibility",[295],{"text":380,"tools":381},"Claude can read and understand complex HTML structures to make targeted changes",[295],{"text":383,"tools":384},"Website maintenance becomes conversational rather than technical when using AI",[295],[386,389],{"name":295,"url":387,"description":388,"featured":54},"https://claude.ai/claude-code","AI-powered coding assistant for automated development tasks",{"name":390,"url":391,"description":392,"featured":54},"GitHub Repository for AI Lab Experiments","https://github.com/jasonhand/ai-tools-experiments","Source code repository for the AI Tools Lab website",[394,397,401,405,409,412,416,420,424,427],{"title":395,"url":396,"timestamp":70},"Introduction to website updates using Claude Code","https://youtu.be/5ovKpnUeCb8?t=0",{"title":398,"url":399,"timestamp":400},"Demonstrating inconsistencies across episode pages","https://youtu.be/5ovKpnUeCb8?t=90","00:01:30",{"title":402,"url":403,"timestamp":404},"Starting a Claude chat to standardize page layouts","https://youtu.be/5ovKpnUeCb8?t=150","00:02:30",{"title":406,"url":407,"timestamp":408},"Claude examining HTML structure differences","https://youtu.be/5ovKpnUeCb8?t=270","00:04:30",{"title":410,"url":411,"timestamp":162},"Reviewing Claude's transcript navigation improvements","https://youtu.be/5ovKpnUeCb8?t=360",{"title":413,"url":414,"timestamp":415},"Adding episode navigation sections to page bottoms","https://youtu.be/5ovKpnUeCb8?t=450","00:07:30",{"title":417,"url":418,"timestamp":419},"Fixing container structure and spacing issues","https://youtu.be/5ovKpnUeCb8?t=570","00:09:30",{"title":421,"url":422,"timestamp":423},"Creating chapter markers for better video navigation","https://youtu.be/5ovKpnUeCb8?t=630","00:10:30",{"title":425,"url":426,"timestamp":170},"Renaming sections and updating links","https://youtu.be/5ovKpnUeCb8?t=720",{"title":428,"url":429,"timestamp":430},"Planning to split multi-video episodes and conclusion","https://youtu.be/5ovKpnUeCb8?t=780","00:13:00","When your website looks like it was designed by a committee of caffeinated developers from different decades, it's time for an intervention. Jason tackles the chaos of inconsistent styling across his AI Tools Lab site, armed with nothing but Claude Code and a healthy dose of frustration with manual HTML editing. Watch as conversational commands transform into precise code changes, standardizing layouts, fixing navigation quirks, and adding proper chapter markers. It's like having a patient, tireless intern who actually knows CSS—and never complains about tedious tasks.","src/content/episodes/ep05.mdx","95ea6a051e51bcd5","ep05.mdx","ep06",{"id":435,"data":437,"body":512,"filePath":513,"digest":514,"legacyId":515,"deferredRender":104},{"title":438,"description":439,"heroImg":440,"videoId":441,"episodeNumber":442,"date":19,"author":20,"participants":443,"tags":444,"takeaways":445,"resources":462,"jumpTo":472,"summary":512,"featured":54,"transcriptAvailable":104},"Using Cursor and Claude to Solve Record Search Bugs","Following the journey of using Claude Code to implement substantial changes to a personal website, from planning to execution and troubleshooting.","../images/thumbnails/ep06.png","OxHCfE1bFBs",6,[22],[25,290],[446,450,453,456,459],{"text":447,"tools":448},"Cursor with Claude can quickly identify and fix complex bugs in web applications",[134,449],"Claude",{"text":451,"tools":452},"The Vinyl Viewer bug occurred because the click handler used the original data array instead of the filtered array",[134,449],{"text":454,"tools":455},"Claude was able to diagnose the issue without requiring extensive prompting",[449],{"text":457,"tools":458},"Cursor provides a more integrated experience than standard chat interfaces for coding tasks",[134],{"text":460,"tools":461},"AI assistants can help debug code even on projects that haven't been maintained for months",[134,449],[463,464,468],{"name":134,"url":149,"description":150,"featured":54},{"name":465,"url":466,"description":467,"featured":54},"Vinyl Viewer GitHub Repository","https://github.com/jasonhand/vinyl-viewer","Source code for the vinyl record collection viewer application",{"name":469,"url":470,"description":471,"featured":54},"Vinyl Viewer Live Demo","https://jasonhand.github.io/vinyl-viewer/","Live demonstration of the vinyl record collection application",[473,476,480,484,488,492,496,500,504,508],{"title":474,"url":475,"timestamp":70},"Introduction to using Claude Code for website updates","https://youtu.be/OxHCfE1bFBs?t=0",{"title":477,"url":478,"timestamp":479},"Introducing the Vinyl Viewer weekend project","https://youtu.be/OxHCfE1bFBs?t=42","00:00:42",{"title":481,"url":482,"timestamp":483},"Discovering the search functionality bug with Frank Zappa records","https://youtu.be/OxHCfE1bFBs?t=118","00:01:58",{"title":485,"url":486,"timestamp":487},"Setting up the Cursor environment and connecting to the project","https://youtu.be/OxHCfE1bFBs?t=170","00:02:50",{"title":489,"url":490,"timestamp":491},"Describing the bug precisely to Claude","https://youtu.be/OxHCfE1bFBs?t=240","00:04:00",{"title":493,"url":494,"timestamp":495},"Sharing the index and script.js files with Claude","https://youtu.be/OxHCfE1bFBs?t=368","00:06:08",{"title":497,"url":498,"timestamp":499},"Claude identifies the filtered data array issue","https://youtu.be/OxHCfE1bFBs?t=429","00:07:09",{"title":501,"url":502,"timestamp":503},"Applying Claude's code fix to the script file","https://youtu.be/OxHCfE1bFBs?t=490","00:08:10",{"title":505,"url":506,"timestamp":507},"Investigating why the fix didn't work and making adjustments","https://youtu.be/OxHCfE1bFBs?t=782","00:13:02",{"title":509,"url":510,"timestamp":511},"Testing again with the new build and confirming the fix works","https://youtu.be/OxHCfE1bFBs?t=954","00:15:54","Ever have that one bug that's been mocking you for months? Jason's Vinyl Viewer app has been serving up the wrong album details whenever someone clicks on search results—Frank Zappa fans were getting Taylor Swift instead. After ten months of digital musical chairs, Jason finally enlists Cursor and Claude to play detective. What they uncover is a classic case of array confusion: the search works perfectly, but the click handler is stuck in the past, referencing the original data instead of the filtered results. Watch a ten-month headache dissolve in minutes when AI meets persistent debugging.","src/content/episodes/ep06.mdx","4a8c9b631b60bd37","ep06.mdx","ep07",{"id":516,"data":518,"body":590,"filePath":591,"digest":592,"legacyId":593,"deferredRender":104},{"title":519,"description":520,"heroImg":521,"videoId":522,"episodeNumber":523,"date":19,"author":20,"participants":524,"tags":525,"takeaways":527,"resources":544,"jumpTo":552,"summary":590,"featured":54,"transcriptAvailable":104},"Using Cursor and Claude to Fix CSS Layout Issues","A practical debugging session using Cursor IDE and Claude to identify and fix complex search functionality bugs in a record management system.","../images/thumbnails/ep07.png","9V5QlhpqBbw",7,[22],[119,290,526],"debugging",[528,531,535,538,541],{"text":529,"tools":530},"Cursor with Claude can quickly identify and fix CSS positioning issues",[134,449],{"text":532,"tools":533},"When fixing one CSS issue, be mindful of how it may affect other elements (z-index conflicts)",[534],"CSS",{"text":536,"tools":537},"AI assistants can provide detailed explanations of CSS problems and their solutions",[134,449],{"text":539,"tools":540},"Testing after each code change is crucial to catch unexpected side effects",[134],{"text":542,"tools":543},"CSS fixes often require multiple iterations to fully resolve all related issues",[534],[545,546,547,551],{"name":134,"url":149,"description":150,"featured":54},{"name":469,"url":470,"description":471,"featured":54},{"name":548,"url":549,"description":550,"featured":54},"Ignite Karaoke GitHub Repository","https://github.com/jasonhand/ignite-karaoke","Source code for the Ignite Karaoke presentation application",{"name":465,"url":466,"description":467,"featured":54},[553,556,560,564,567,571,575,578,582,586],{"title":554,"url":555,"timestamp":70},"Introduction to the bug hunting session in Vinyl Viewer","https://youtu.be/9V5QlhpqBbw?t=0",{"title":557,"url":558,"timestamp":559},"Introduction to the Ignite Karaoke project","https://youtu.be/9V5QlhpqBbw?t=119","00:01:59",{"title":561,"url":562,"timestamp":563},"Explaining the concept and functionality of Ignite Karaoke","https://youtu.be/9V5QlhpqBbw?t=182","00:03:02",{"title":565,"url":566,"timestamp":491},"Demonstrating the image display issue with gap at top","https://youtu.be/9V5QlhpqBbw?t=240",{"title":568,"url":569,"timestamp":570},"Setting up the project in Cursor","https://youtu.be/9V5QlhpqBbw?t=308","00:05:08",{"title":572,"url":573,"timestamp":574},"Explaining the CSS positioning problem to Claude","https://youtu.be/9V5QlhpqBbw?t=419","00:06:59",{"title":576,"url":577,"timestamp":166},"Implementing first CSS changes to fix the gap","https://youtu.be/9V5QlhpqBbw?t=540",{"title":579,"url":580,"timestamp":581},"Addressing the z-index issue affecting button clickability","https://youtu.be/9V5QlhpqBbw?t=662","00:11:02",{"title":583,"url":584,"timestamp":585},"Final CSS adjustments for footer link functionality","https://youtu.be/9V5QlhpqBbw?t=843","00:14:03",{"title":587,"url":588,"timestamp":589},"Final testing and confirming all issues are fixed","https://youtu.be/9V5QlhpqBbw?t=904","00:15:04","Sometimes the most frustrating bugs are the ones staring you right in the face. Jason's Ignite Karaoke app has a glaring gap at the top of every image that's been driving him crazy, plus buttons that refuse to be clicked. Armed with Cursor and Claude, he dives into a classic CSS debugging adventure where fixing one problem creates three new ones. Watch as they navigate the treacherous waters of z-index conflicts, margin mishaps, and the delicate dance of making elements play nicely together. It's a masterclass in why CSS is both beautiful and maddening.","src/content/episodes/ep07.mdx","ff48d6b98a126ac7","ep07.mdx","ep08",{"id":594,"data":596,"body":658,"filePath":659,"digest":660,"legacyId":661,"deferredRender":104},{"title":519,"description":597,"heroImg":598,"videoId":599,"episodeNumber":600,"date":19,"author":20,"participants":601,"tags":602,"takeaways":603,"resources":622,"jumpTo":626,"summary":657,"featured":54,"transcriptAvailable":104},"A step-by-step walkthrough of diagnosing and resolving complicated CSS layout issues with the help of Cursor's AI-powered assistance and Claude.","../images/thumbnails/ep08.png","-yNJmVCR-nM",8,[22],[119,290,526,25],[604,607,610,613,616,619],{"text":605,"tools":606},"Cursor with Claude effectively diagnoses and fixes complex CSS positioning issues",[134,449],{"text":608,"tools":609},"Fixing one CSS issue may create other problems due to dependencies between elements",[534],{"text":611,"tools":612},"Z-index conflicts are a common challenge when styling overlapping web elements",[534],{"text":614,"tools":615},"CSS debugging often requires multiple iterations to resolve all related issues",[534],{"text":617,"tools":618},"AI assistants can provide detailed explanations of CSS problems and solutions",[134,449],{"text":620,"tools":621},"Testing after each change is crucial to catch unintended side effects",[134],[623,624,625],{"name":134,"url":149,"description":150,"featured":54},{"name":548,"url":549,"description":550,"featured":54},{"name":465,"url":466,"description":467,"featured":54},[627,630,632,635,638,640,643,646,649,653],{"title":628,"url":629,"timestamp":70},"Introduction to fixing CSS problems in the Ignite Karaoke project","https://youtu.be/-yNJmVCR-nM?t=0",{"title":557,"url":631,"timestamp":331},"https://youtu.be/-yNJmVCR-nM?t=120",{"title":633,"url":634,"timestamp":158},"Explaining the concept of Ignite Karaoke and its features","https://youtu.be/-yNJmVCR-nM?t=180",{"title":636,"url":637,"timestamp":491},"Demonstrating the CSS gap issue with image display","https://youtu.be/-yNJmVCR-nM?t=240",{"title":568,"url":639,"timestamp":338},"https://youtu.be/-yNJmVCR-nM?t=300",{"title":572,"url":641,"timestamp":642},"https://youtu.be/-yNJmVCR-nM?t=420","00:07:00",{"title":644,"url":645,"timestamp":166},"Implementing first CSS changes to fix the space issue","https://youtu.be/-yNJmVCR-nM?t=540",{"title":647,"url":648,"timestamp":170},"Implementing z-index changes to fix button interactions","https://youtu.be/-yNJmVCR-nM?t=720",{"title":650,"url":651,"timestamp":652},"Adding final CSS fixes for footer links","https://youtu.be/-yNJmVCR-nM?t=840","00:14:00",{"title":654,"url":655,"timestamp":656},"Discussing image loading and potential dead links","https://youtu.be/-yNJmVCR-nM?t=960","00:16:00","Round two of the CSS debugging chronicles! Jason returns to his Ignite Karaoke project for another battle with layout demons. This time, it's not just the mysterious gap at the top of images—it's a full-scale war against z-index conflicts that are making his buttons completely unclickable. Watch as he and Claude tag-team their way through overlapping elements, positioning nightmares, and the age-old question: 'Why does fixing one CSS property break three others?' It's like debugging inception—every solution reveals a deeper problem.","Round two of the CSS debugging chronicles! Jason returns to his Ignite Karaoke project for another battle with layout demons. This time, it's not just the mysterious gap at the top of images—it's a full-scale war against z-index conflicts that are making his buttons completely unclickable. Watch as he and Claude tag-team their way through overlapping elements, positioning nightmares, and the age-old question: \"Why does fixing one CSS property break three others?\" It's like debugging inception—every solution reveals a deeper problem.","src/content/episodes/ep08.mdx","d04b3002cdc1e0d7","ep08.mdx","ep09",{"id":662,"data":664,"body":743,"filePath":744,"digest":745,"legacyId":746,"deferredRender":104},{"title":665,"description":666,"heroImg":667,"videoId":668,"episodeNumber":669,"date":19,"author":20,"participants":670,"tags":671,"takeaways":672,"resources":694,"jumpTo":710,"summary":743,"featured":54,"transcriptAvailable":104},"From GTC to Website Building with AI Tools","Insights from NVIDIA's GTC conference and how the latest AI advancements can be applied to website development using various AI tools and techniques.","../images/thumbnails/ep09.png","IW9GjOzoFAw",9,[22,23],[25],[673,677,680,683,686,690],{"text":674,"tools":675},"The AI industry is shifting from curiosity to practical implementation, with GTC attendance growing to over 25,000 people",[676],"NVIDIA GTC",{"text":678,"tools":679},"Many organizations are concerned with hallucination detection, security, and cost management as they move AI projects to production",[307],{"text":681,"tools":682},"Claude Code can efficiently help build websites and web applications with features like feedback forms and API integrations",[295],{"text":684,"tools":685},"AI tools like Claude Code can resolve long-standing bugs and improve UI/UX in existing projects",[295],{"text":687,"tools":688},"The concept of \"wallet attacks\" (competitors trying to exhaust your API quotas) is an emerging concern in AI deployment",[689],"API Management",{"text":691,"tools":692},"Serverless functions can help overcome CORS limitations when building web applications that integrate with third-party APIs",[300,693],"Serverless",[695,697,701,702,703,706],{"name":295,"url":696,"description":315,"featured":54},"https://claude.ai/code",{"name":698,"url":699,"description":700,"featured":54},"Windsurf IDE","https://winder.ai/","AI-powered development environment",{"name":548,"url":549,"description":550,"featured":54},{"name":465,"url":466,"description":467,"featured":54},{"name":307,"url":704,"description":705,"featured":54},"https://www.datadoghq.com/","Monitoring and analytics platform for cloud applications",{"name":707,"url":708,"description":709,"featured":54},"NVIDIA GTC Conference","https://www.nvidia.com/en-us/gtc/","NVIDIA's annual GPU Technology Conference",[711,714,717,720,723,726,730,733,736,739],{"title":712,"url":713,"timestamp":70},"Introduction and catching up since GTC conference","https://youtu.be/IW9GjOzoFAw?t=0",{"title":715,"url":716,"timestamp":331},"Jason's experience attending 15+ sessions at GTC","https://youtu.be/IW9GjOzoFAw?t=120",{"title":718,"url":719,"timestamp":491},"Physical AI applications at GTC: robots and autonomous vehicles","https://youtu.be/IW9GjOzoFAw?t=240",{"title":721,"url":722,"timestamp":162},"Jason's experience at the Datadog booth and common concerns","https://youtu.be/IW9GjOzoFAw?t=360",{"title":724,"url":725,"timestamp":345},"Wallet attacks and API cost management concerns","https://youtu.be/IW9GjOzoFAw?t=480",{"title":727,"url":728,"timestamp":729},"Demonstrating the new website with feedback form","https://youtu.be/IW9GjOzoFAw?t=600","00:10:00",{"title":731,"url":732,"timestamp":430},"Discussing improvements to the Ignite Karaoke project","https://youtu.be/IW9GjOzoFAw?t=780",{"title":734,"url":735,"timestamp":652},"Showcase of the improved Vinyl Viewer application","https://youtu.be/IW9GjOzoFAw?t=840",{"title":737,"url":738,"timestamp":174},"Demonstrating the enhanced A Call of Cats adoption application","https://youtu.be/IW9GjOzoFAw?t=900",{"title":740,"url":741,"timestamp":742},"Wrapping up and plans for next episode","https://youtu.be/IW9GjOzoFAw?t=1020","00:17:00","Fresh from NVIDIA's GTC conference where 25,000 developers gathered to see where AI is heading next, Jason and Ryan bring back field reports from the trenches of production AI. The conference buzz revealed a new worry keeping developers up at night: \"wallet attacks\"—competitors deliberately triggering your AI APIs to drain your budget. Between tales of robots learning to navigate warehouses and autonomous vehicles taking over highways, Jason showcases the fruits of his own AI-assisted labor: a complete website overhaul featuring a working feedback form, finally-fixed UI bugs, and search functionality that actually works. It's proof that while the world dreams of AI taking over, sometimes the real victory is just getting your CSS to behave.","src/content/episodes/ep09.mdx","0df539a26a1c7550","ep09.mdx","ep10",{"id":747,"data":749,"body":837,"filePath":838,"digest":839,"legacyId":840,"deferredRender":104},{"title":750,"description":751,"heroImg":752,"videoId":753,"episodeNumber":754,"date":19,"author":20,"participants":755,"tags":756,"takeaways":757,"resources":782,"jumpTo":804,"summary":837,"featured":54,"transcriptAvailable":104},"First Look at Windsurf & Model Context Protocol (MCP)","An in-depth look at Windsurf IDE compared to Cursor, exploring AI code editor features, the Model Context Protocol (MCP), and effective project planning approaches.","../images/thumbnails/ep10.png","SwQwRsHVjM4",10,[23],[25],[758,763,766,769,773,778],{"text":759,"tools":760},"Windsurf offers a free tier with the Cascade model, providing capable AI assistance for code completion and project planning",[761,762],"Windsurf","Cascade",{"text":764,"tools":765},"Creating a detailed Project Requirements Document (PRD) before coding leads to higher quality AI output",[761,134],{"text":767,"tools":768},"Different AI coding tools have different \"ergonomics\" that may suit different workflows",[761,134],{"text":770,"tools":771},"Using multiple AI assistants in parallel can produce better results through comparing approaches",[772],"AI Assistants",{"text":774,"tools":775},"Model Context Protocol (MCP) is an emerging standard for connecting AI tools with external services like maps, Kubernetes, and more",[776,777],"MCP","Anthropic",{"text":779,"tools":780},"AI models tend to have an \"attention span\" limit of around 30-45 minutes before context degradation",[781],"AI Models",[783,786,788,792,796,800],{"name":698,"url":784,"description":785,"featured":54},"https://podium.video/windsurf","Podium's AI-powered code editor",{"name":134,"url":149,"description":787,"featured":54},"AI-powered code editor with Claude integration",{"name":789,"url":790,"description":791,"featured":54},"Model Context Protocol (MCP)","https://www.anthropic.com/news/mcp","Anthropic's protocol for connecting AI models to tools",{"name":793,"url":794,"description":795,"featured":54},"LangChain","https://langchain.com/","Framework for building applications with LLMs",{"name":797,"url":798,"description":799,"featured":54},"Lang Graph","https://github.com/langchain-ai/langgraph","Framework for building stateful, multi-actor applications with LLMs",{"name":801,"url":802,"description":803,"featured":54},"TRIZ Methodology","https://www.triz.org/triz","Creative problem-solving methodology mentioned in the episode",[805,808,811,814,817,820,823,826,829,833],{"title":806,"url":807,"timestamp":70},"Introduction and overview of Windsurf IDE","https://youtu.be/SwQwRsHVjM4?t=0",{"title":809,"url":810,"timestamp":331},"Discussing proof of concept vs. production development","https://youtu.be/SwQwRsHVjM4?t=120",{"title":812,"url":813,"timestamp":491},"Signing up for Windsurf AI features and free plan limitations","https://youtu.be/SwQwRsHVjM4?t=240",{"title":815,"url":816,"timestamp":338},"Creating a new project and opening with Windsurf's chat mode","https://youtu.be/SwQwRsHVjM4?t=300",{"title":818,"url":819,"timestamp":162},"Demonstrating intelligent code completion in Python","https://youtu.be/SwQwRsHVjM4?t=360",{"title":821,"url":822,"timestamp":345},"Using Product Requirements Documents (PRD) for planning","https://youtu.be/SwQwRsHVjM4?t=480",{"title":824,"url":825,"timestamp":729},"Different AI assistance modes and context windows","https://youtu.be/SwQwRsHVjM4?t=600",{"title":827,"url":828,"timestamp":656},"Introduction to MCP (Model Context Protocol)","https://youtu.be/SwQwRsHVjM4?t=960",{"title":830,"url":831,"timestamp":832},"Comparing WindSurf, Cursor and other AI editors","https://youtu.be/SwQwRsHVjM4?t=1200","00:20:00",{"title":834,"url":835,"timestamp":836},"Conclusion and plans for future episodes","https://youtu.be/SwQwRsHVjM4?t=1920","00:32:00","The AI code editor wars are heating up, and Windsurf just entered the ring with some interesting moves. Ryan takes this Cursor competitor for a test drive, discovering that different AI assistants have distinctly different \"personalities\" and workflows. From the importance of writing detailed Project Requirements Documents (they're like love letters to your AI coding partner) to the emerging Model Context Protocol that promises to connect AI tools to everything from Kubernetes to your coffee machine, this episode explores how the developer tooling landscape is evolving at breakneck speed. Plus, why your AI assistant might start forgetting things after 45 minutes of coding together.","src/content/episodes/ep10.mdx","3f5237bc9c27ae07","ep10.mdx","ep11",{"id":841,"data":843,"body":924,"filePath":925,"digest":926,"legacyId":927,"deferredRender":104},{"title":844,"description":845,"heroImg":846,"videoId":847,"episodeNumber":848,"date":19,"author":20,"participants":849,"tags":850,"takeaways":851,"resources":875,"jumpTo":890,"summary":923,"featured":54,"transcriptAvailable":104},"Exploring Llama 4, OpenRouter, and Model Comparison Tools","A hands-on exploration of Meta's Llama 4 model and its massive context window, along with testing various AI models using comparison platforms like OpenRouter and LM Arena.","../images/thumbnails/ep11.png","DkooO8M0Xn8",11,[22,23],[119,26,118],[852,857,861,864,867,870],{"text":853,"tools":854},"Llama 4 features a massive 10+ million token context window, potentially revolutionizing how we work with large documents and complex instructions",[855,856],"Llama 4","Meta",{"text":858,"tools":859},"Despite large context windows, RAG (Retrieval Augmented Generation) remains valuable for cost efficiency and performance optimization",[860,855],"RAG",{"text":862,"tools":863},"Expanded context windows enable more comprehensive guardrails and detailed system prompts in production applications",[855],{"text":865,"tools":866},"Even the latest AI models still struggle with certain types of knowledge, particularly specialized programming techniques and niche factual information",[781],{"text":868,"tools":869},"AI hallucinations remain a concern, particularly for factual questions, as demonstrated by the incorrect musician information",[781],{"text":871,"tools":872},"Tools like OpenRouter and LM Arena provide valuable ways to compare different models for specific use cases",[873,874],"OpenRouter","LM Arena",[876,880,883,886],{"name":877,"url":878,"description":879,"featured":54},"Llama 4 on HuggingFace","https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct","Try Meta's latest language model",{"name":873,"url":881,"description":882,"featured":54},"https://openrouter.ai/","Platform for comparing and routing between multiple AI models",{"name":874,"url":884,"description":885,"featured":54},"https://lmarena.ai/","Interactive tool for blind comparison testing of language models",{"name":887,"url":888,"description":889,"featured":54},"DeepSeek","https://deepseek.ai/","AI model mentioned in the episode comparisons",[891,894,898,901,904,907,910,913,916,920],{"title":892,"url":893,"timestamp":70},"Introduction and discussion about Llama 4's weekend release","https://youtu.be/DkooO8M0Xn8?t=0",{"title":895,"url":896,"timestamp":897},"Exploring Llama 4 on Hugging Face","https://youtu.be/DkooO8M0Xn8?t=60","00:01:00",{"title":899,"url":900,"timestamp":331},"Discussion about Llama 4's 10+ million token context window","https://youtu.be/DkooO8M0Xn8?t=120",{"title":902,"url":903,"timestamp":491},"Benefits of large context windows for guardrails and PRDs","https://youtu.be/DkooO8M0Xn8?t=240",{"title":905,"url":906,"timestamp":338},"Testing Llama 4 with basic questions","https://youtu.be/DkooO8M0Xn8?t=300",{"title":908,"url":909,"timestamp":345},"Testing Llama 4 with specific knowledge questions","https://youtu.be/DkooO8M0Xn8?t=480",{"title":911,"url":912,"timestamp":174},"Introduction to model comparison tools: OpenRouter","https://youtu.be/DkooO8M0Xn8?t=900",{"title":914,"url":915,"timestamp":182},"Introduction to LM Arena for model comparison","https://youtu.be/DkooO8M0Xn8?t=1260",{"title":917,"url":918,"timestamp":919},"Comparing models on music knowledge","https://youtu.be/DkooO8M0Xn8?t=1380","00:23:00",{"title":921,"url":922,"timestamp":186},"Discovering LunarCall, a surprising new model","https://youtu.be/DkooO8M0Xn8?t=1440","Ten million tokens. That's not a typo—Meta just dropped Llama 4 with a context window so massive it could swallow entire codebases for breakfast. Jason and Ryan dive headfirst into this technical marvel, testing whether such an enormous memory span might finally make RAG systems obsolete. But here's the plot twist: even with superhuman context capabilities, the latest models still stumble on basic questions about musicians and specialized programming knowledge. Watch them put Llama 4 through its paces alongside comparison platforms like OpenRouter and LM Arena, only to discover an unknown model called LunarCall quietly outperforming the giants. Sometimes the most interesting discoveries happen in the footnotes of technology.","In this episode, Jason and Ryan explore the freshly released Llama 4 model from Meta, which was just released over the weekend. They dive into its capabilities, testing it on Hugging Face, and discuss its groundbreaking 10+ million token context window. The conversation covers whether such a massive context window might eliminate the need for RAG (Retrieval Augmented Generation) and how it could simplify prompt engineering by allowing for more detailed system prompts and guardrails. They also explore two model comparison platforms—OpenRouter and LM Arena—which allow users to test and compare different AI models side by side. During their exploration, they discover a lesser-known model called LunarCall that surprisingly outperforms others on a specific test. This episode provides valuable insights into the rapidly evolving landscape of AI models and practical tools for comparing their performance.","src/content/episodes/ep11.mdx","6f6b4b2c65b3f284","ep11.mdx","ep12",{"id":928,"data":930,"body":1019,"filePath":1020,"digest":1021,"legacyId":1022,"deferredRender":104},{"title":931,"description":932,"heroImg":933,"videoId":934,"episodeNumber":935,"date":19,"author":20,"participants":936,"tags":937,"takeaways":939,"resources":964,"jumpTo":986,"summary":1018,"featured":54,"transcriptAvailable":104},"Cursor Rules, Firebase Studio, and the Evolving IDE Landscape","An exploration of AI Cursor Rules in modern development environments, Google's new Firebase Studio cloud-based IDE, and the evolving landscape of AI-powered development tools across major cloud providers.","../images/thumbnails/ep12.png","EursDsj4dCk",12,[22,23],[119,26,118,938],"firebase",[940,943,946,950,956,960],{"text":941,"tools":942},"Cursor Rules and project requirements documents (PRDs) are becoming essential for maintaining context in AI-assisted development",[134,761],{"text":944,"tools":945},"Tools like Cursor and WindSurf implement Cursor Rules differently, but both recognize their importance in combating \"AI amnesia\"",[134,761],{"text":947,"tools":948},"Creating rule files can feel like toil, but they dramatically improve the quality and consistency of AI-generated code",[949],"Cursor Rules",{"text":951,"tools":952},"Major cloud providers (Google, Microsoft, Amazon) are each developing their own AI-powered development environments",[953,954,955],"Firebase Studio","Azure AI Studio","Bedrock Studio",{"text":957,"tools":958},"Firebase Studio integrates with Google's Gemini model to provide code analysis, suggestions, and other AI-powered features",[953,959],"Gemini",{"text":961,"tools":962},"API key management and security are crucial considerations when working with AI development environments",[963],"API Security",[965,968,970,974,978,982],{"name":953,"url":966,"description":967,"featured":54},"https://firebase.google.com/products/studio","Google's new cloud-based IDE powered by Gemini",{"name":134,"url":149,"description":969,"featured":54},"AI-powered code editor with support for Cursor Rules",{"name":971,"url":972,"description":973,"featured":54},"WindSurf","https://www.windsurf.io/","Another AI-powered IDE with context management features",{"name":975,"url":976,"description":977,"featured":54},"Simon Wardley's Blog","https://blog.gardeviance.org/","Resources on effective rule creation for AI tools",{"name":979,"url":980,"description":981,"featured":54},"GenKit","https://genkit.dev/","Google's TypeScript toolkit for AI-powered web applications",{"name":983,"url":984,"description":985,"featured":54},"Bolt","https://bolt.new/","App building platform mentioned for future exploration",[987,990,993,996,999,1002,1005,1008,1011,1014],{"title":988,"url":989,"timestamp":70},"Introduction and recap of previous LLAMA 4 discussion","https://youtu.be/EursDsj4dCk?t=0",{"title":991,"url":992,"timestamp":897},"Updates to the AI Tools Lab website","https://youtu.be/EursDsj4dCk?t=60",{"title":994,"url":995,"timestamp":158},"Introduction to the importance of Cursor Rules in AI tools","https://youtu.be/EursDsj4dCk?t=180",{"title":997,"url":998,"timestamp":491},"Comparing Cursor and WindSurf approaches to context management","https://youtu.be/EursDsj4dCk?t=240",{"title":1000,"url":1001,"timestamp":338},"Discussion of \"AI amnesia\" and the DRY principle","https://youtu.be/EursDsj4dCk?t=300",{"title":1003,"url":1004,"timestamp":642},"Repositories of Cursor Rules and Simon Wardley's contributions","https://youtu.be/EursDsj4dCk?t=420",{"title":1006,"url":1007,"timestamp":170},"Introduction to Google Cloud Next and Firebase Studio","https://youtu.be/EursDsj4dCk?t=720",{"title":1009,"url":1010,"timestamp":652},"Exploring the Firebase Studio interface","https://youtu.be/EursDsj4dCk?t=840",{"title":1012,"url":1013,"timestamp":186},"Comparing cloud provider AI development environments","https://youtu.be/EursDsj4dCk?t=1440",{"title":1015,"url":1016,"timestamp":1017},"Conclusion and preview of future topics","https://youtu.be/EursDsj4dCk?t=2460","00:41:00","AI amnesia is real, and it's costing developers hours of repeated instructions. Jason and Ryan tackle the growing problem of AI assistants that forget everything between sessions, exploring how Cursor Rules and detailed project docs are becoming the antidote to starting from scratch every time. They dive into Google's new Firebase Studio—part code editor, part AI playground—and compare it to the growing ecosystem of cloud-based development environments from Microsoft, Amazon, and others. It's a glimpse into a future where your development environment knows as much about your project as you do, assuming you can teach it to remember.","In this episode, Jason Hand and Ryan MacLean explore two key topics in AI development workflows: the importance of Cursor Rules in AI-powered IDEs and Google's new Firebase Studio. They begin with a recap of their previous discussion on LLAMA 4 and model comparison tools like LM Arena. The conversation then shifts to the critical role of Cursor Rules and project requirement documents in AI coding environments like Cursor and WindSurf, highlighting how these help combat \"AI amnesia\" by preserving context between sessions and reducing repetitive instructions. They discuss different approaches to maintaining context, including ChatGPT's memory features versus explicit Cursor Rules, and how developers are finding solutions to the \"Don't Repeat Yourself\" challenge when working with AI.\r\n\r\nIn the second part, they explore Firebase Studio, a newly announced cloud-based IDE from Google that integrates with Gemini models. They test its capabilities by importing an existing project—a simple dog breed viewer app—and discuss the interface, API key management, and potential use cases. They compare Firebase Studio with similar offerings from Microsoft (Azure AI Studio) and Amazon (Bedrock Studio), noting that cloud providers are increasingly building their own AI-powered development environments. Throughout their exploration, they reflect on important considerations for developers, including security practices, the need for proper monitoring, and the balance between ease of use and deliberate planning in AI application development.","src/content/episodes/ep12.mdx","f1646a89d51bf603","ep12.mdx","ep13",{"id":1023,"data":1025,"body":1117,"filePath":1118,"digest":1119,"legacyId":1120,"deferredRender":104},{"title":1026,"description":1027,"heroImg":1028,"videoId":1029,"episodeNumber":1030,"date":19,"author":20,"participants":1031,"tags":1032,"takeaways":1035,"resources":1061,"jumpTo":1081,"summary":1116,"featured":54,"transcriptAvailable":104},"Exploring Bolt: Rapid App Development with AI-Powered Templates","Explore Bolt, an AI-powered development tool that enables rapid app creation through templates and natural language prompts, perfect for prototyping and concept visualization.","../images/thumbnails/ep13.png","hc-hKcoP3Pw",13,[22,23],[1033,1034],"bolt","ai-development",[1036,1039,1042,1048,1051,1054,1057],{"text":1037,"tools":1038},"Bolt provides a template-based approach to rapidly build web and mobile applications",[983],{"text":1040,"tools":1041},"It's particularly useful for prototyping and \"vibe coding\" - quickly visualizing concepts",[983],{"text":1043,"tools":1044},"The tool works with multiple frameworks including React, Next.js, and Expo",[983,1045,1046,1047],"React","Next.js","Expo",{"text":1049,"tools":1050},"Users can download their code and continue development in their preferred IDE",[983],{"text":1052,"tools":1053},"While it may not be ideal for production-grade applications, it excels at exploration and prototyping",[983],{"text":1055,"tools":1056},"Screenshot-based programming allows for quickly recreating interfaces from images",[983],{"text":1058,"tools":1059},"Bolt offers both hosted and open-source versions for different use cases",[983,1060],"Bolt DIY",[1062,1066,1070,1074,1078],{"name":1063,"url":1064,"description":1065,"featured":54},"Bolt Website","https://bolt.new","The hosted version of the Bolt AI-powered development tool",{"name":1067,"url":1068,"description":1069,"featured":54},"Bolt DIY (Open Source Version)","https://bolt.diy","Free offline version that can connect to various AI models",{"name":1071,"url":1072,"description":1073,"featured":54},"Expo Framework","https://expo.dev","Mobile app development framework supported by Bolt",{"name":1075,"url":1076,"description":1077,"featured":54},"Supabase","https://supabase.com","Database solution mentioned in the discussion",{"name":873,"url":1079,"description":1080,"featured":54},"https://openrouter.ai","Service for accessing various AI models",[1082,1085,1088,1092,1096,1099,1102,1105,1108,1112],{"title":1083,"url":1084,"timestamp":70},"Introduction and catching up on AI developments","https://youtu.be/hc-hKcoP3Pw?t=0",{"title":1086,"url":1087,"timestamp":897},"Reviewing previous conversations about AI coding tools","https://youtu.be/hc-hKcoP3Pw?t=60",{"title":1089,"url":1090,"timestamp":1091},"Exploring the AI-tools-lab.com website features","https://youtu.be/hc-hKcoP3Pw?t=128","00:02:08",{"title":1093,"url":1094,"timestamp":1095},"Introduction to Bolt and its template-based approach","https://youtu.be/hc-hKcoP3Pw?t=253","00:04:13",{"title":1097,"url":1098,"timestamp":162},"Building an app with Bolt using Astro framework","https://youtu.be/hc-hKcoP3Pw?t=360",{"title":1100,"url":1101,"timestamp":729},"Creating a Japanese translation app with Expo","https://youtu.be/hc-hKcoP3Pw?t=600",{"title":1103,"url":1104,"timestamp":174},"Troubleshooting API integration and translation features","https://youtu.be/hc-hKcoP3Pw?t=900",{"title":1106,"url":1107,"timestamp":182},"Demonstrating screenshot-based programming in Bolt","https://youtu.be/hc-hKcoP3Pw?t=1260",{"title":1109,"url":1110,"timestamp":1111},"Exploring deployment options and Netlify integration","https://youtu.be/hc-hKcoP3Pw?t=1470","00:24:30",{"title":1113,"url":1114,"timestamp":1115},"Discussion on security considerations for generated apps","https://youtu.be/hc-hKcoP3Pw?t=1710","00:28:30","\"Vibe coding\" might sound like tech bro nonsense, but Ryan's onto something with Bolt—a browser-based AI tool that turns half-formed ideas into working prototypes faster than you can explain them to a human developer. Watch him build a Japanese translation app complete with pronunciation guides, all through casual conversation with an AI that actually understands what he wants. Sure, the result isn't production-ready, but that's missing the point. This is about capturing lightning in a bottle—those fleeting moments of inspiration that usually evaporate by the time you open your IDE. Sometimes the best code is the code that exists.","In this conversation, Ryan MacLean and Jason Hand explore Bolt, a browser-based AI-powered development tool for quickly building web and mobile applications. Ryan demonstrates how Bolt enables developers to start with templates and build functioning apps through natural language prompts. The tool shines in its ability to create rapid prototypes or what has been termed \"vibe coding\" - allowing users to quickly visualize concepts before committing to deeper development. They examine a translation app Ryan built that converts English to Japanese text with Furigana pronunciation guides, highlighting both Bolt's capabilities and limitations. While the app encountered some implementation challenges, it demonstrated Bolt's strength in quickly exploring frameworks and approaches. The discussion compares Bolt to other AI coding tools like Cursor, Claude Code, and Windsurf, noting that Bolt is particularly effective for initial prototyping but users may want to download and transfer projects to more robust IDEs for production refinement.","src/content/episodes/ep13.mdx","ab2df2aed18df866","ep13.mdx","ep14",{"id":1121,"data":1123,"body":1226,"filePath":1227,"digest":1228,"legacyId":1229,"deferredRender":104},{"title":1124,"description":1125,"heroImg":1126,"videoId":1127,"episodeNumber":1128,"date":1129,"author":20,"participants":1130,"tags":1131,"takeaways":1133,"resources":1158,"jumpTo":1187,"summary":1225,"featured":54,"transcriptAvailable":104},"Claude 3.7 Sonnet Plugins: AI Integration with Gmail, Drive and Calendar","Discover how Claude 3.7 Sonnet integrates with Gmail, Google Drive and Calendar to transform everyday G Suite usage with AI-powered insights and recommendations.","../images/thumbnails/ep14.png","TbacJ7HdE6Q",14,"2025-04-28T00:00:00.000Z",[23],[290,1132,118],"plugins",[1134,1140,1143,1146,1149,1152,1155],{"text":1135,"tools":1136},"Claude 3.7 Sonnet integrates with Gmail, Google Drive, and Calendar through simple OAuth authentication",[449,1137,1138,1139],"Gmail","Google Drive","Calendar",{"text":1141,"tools":1142},"The AI can analyze massive email volumes (3.5+ million emails) and generate personalized interactive dashboards",[449,1137],{"text":1144,"tools":1145},"Claude creates customized email filter recommendations with ready-to-use filter language",[449,1137],{"text":1147,"tools":1148},"The system generates different insights on subsequent runs, showing varied approaches to inbox management",[449],{"text":1150,"tools":1151},"Integration provides practical tools for email organization through AI-powered visualization and actionable recommendations",[449,1137],{"text":1153,"tools":1154},"Integration with Google Drive includes security recommendations for sensitive data",[449,1138],{"text":1156,"tools":1157},"Calendar management integration can adapt to different personality types and scheduling preferences",[449,1139],[1159,1163,1167,1171,1175,1179,1183],{"name":1160,"url":1161,"description":1162,"featured":54},"Claude 3.7 Sonnet (Pro plan)","https://claude.ai","Anthropic's AI assistant with new plugin capabilities",{"name":1164,"url":1165,"description":1166,"featured":54},"Boomerang for Gmail","https://www.boomeranggmail.com/","Email management tool mentioned as comparison",{"name":1168,"url":1169,"description":1170,"featured":54},"Unroll.me","https://unroll.me/","Email unsubscription service referenced in discussion",{"name":1172,"url":1173,"description":1174,"featured":54},"Zapier","https://zapier.com/","Automation platform for connecting apps",{"name":1176,"url":1177,"description":1178,"featured":54},"IFTTT (If This Then That)","https://ifttt.com/","Automation platform for connecting services",{"name":1180,"url":1181,"description":1182,"featured":54},"Notion Mail","https://www.notion.so/","Email integration with Notion mentioned in discussion",{"name":1184,"url":1185,"description":1186,"featured":54},"Enneagram Institute","https://www.enneagraminstitute.com/","Information about personality types used in calendar management demo",[1188,1191,1194,1197,1200,1203,1206,1209,1212,1215,1218,1222],{"title":1189,"url":1190,"timestamp":70},"Introduction to Claude Desktop plugins and OAuth connection process","https://youtu.be/TbacJ7HdE6Q?t=0",{"title":1192,"url":1193,"timestamp":897},"Overview of prompts and interactive artifacts in Claude","https://youtu.be/TbacJ7HdE6Q?t=60",{"title":1195,"url":1196,"timestamp":331},"Demonstrating Gmail integration and inbox analysis","https://youtu.be/TbacJ7HdE6Q?t=120",{"title":1198,"url":1199,"timestamp":158},"Reviewing Ryan's email volume and Claude's analysis dashboard","https://youtu.be/TbacJ7HdE6Q?t=180",{"title":1201,"url":1202,"timestamp":491},"Email management recommendations and filter suggestions","https://youtu.be/TbacJ7HdE6Q?t=240",{"title":1204,"url":1205,"timestamp":338},"Different results from multiple runs of the inbox analysis","https://youtu.be/TbacJ7HdE6Q?t=300",{"title":1207,"url":1208,"timestamp":162},"Downloadable TSX files and source code access","https://youtu.be/TbacJ7HdE6Q?t=360",{"title":1210,"url":1211,"timestamp":642},"Discussion of Google Drive integration and security recommendations","https://youtu.be/TbacJ7HdE6Q?t=420",{"title":1213,"url":1214,"timestamp":345},"Making email organization fun again","https://youtu.be/TbacJ7HdE6Q?t=480",{"title":1216,"url":1217,"timestamp":166},"Claude for Work and enterprise applications","https://youtu.be/TbacJ7HdE6Q?t=540",{"title":1219,"url":1220,"timestamp":1221},"Calendar management based on Enneagram personality types","https://youtu.be/TbacJ7HdE6Q?t=660","00:11:00",{"title":1223,"url":1224,"timestamp":652},"Discussion of Notion Mail and emerging tool integrations","https://youtu.be/TbacJ7HdE6Q?t=840","3.5 million emails. That's not a typo—that's Ryan's actual inbox, and Claude just volunteered to make sense of it all. Watch Claude 3.7 Sonnet dive headfirst into years of digital chaos, emerging with interactive React dashboards, personalized filter recommendations, and somehow maintaining its sanity throughout. This isn't just another plugin demo; it's proof that AI can tackle the kind of overwhelming data scenarios that would send most humans straight to therapy. When your email assistant starts giving you actionable insights about your own communication patterns, you know we've crossed into genuinely useful territory.","In this discussion, Ryan demonstrates new plugin integrations for Claude Desktop, particularly focusing on how Claude 3.7 Sonnet connects with Gmail, Google Drive, and Calendar through OAuth authentication. Ryan walks through the process of integrating these tools and showcases various practical applications that transform everyday G Suite usage. The most impressive feature demonstrated is Claude's ability to analyze Ryan's inbox (containing over 3.5 million emails) and generate interactive React-based dashboards with personalized recommendations for inbox management, complete with visualization of email patterns, customized filter suggestions, and actionable checklists.","src/content/episodes/ep14.mdx","82eb2270897ea792","ep14.mdx","ep15",{"id":1230,"data":1232,"body":1327,"filePath":1328,"digest":1329,"legacyId":1330,"deferredRender":104},{"title":1233,"description":1234,"heroImg":1235,"videoId":1236,"episodeNumber":1237,"date":1129,"author":20,"participants":1238,"tags":1239,"takeaways":1242,"resources":1268,"jumpTo":1279,"summary":1326,"featured":54,"transcriptAvailable":104},"AI Tools in Action: Exploring Sora Image Generation and Lovable App Builder","Explore the latest developments in AI tools with Jason Hand and Ryan MacLean as they test image generation with Sora and app building with Lovable.","../images/thumbnails/ep15.png","DcnbH45lfkU",15,[22,23],[1240,1241,205,1034],"lovable","sora",[1243,1247,1250,1254,1257,1261,1265],{"text":1244,"tools":1245},"AI image generation has significantly improved, especially for text rendering in images",[1246],"Sora",{"text":1248,"tools":1249},"Sora can now create images with professional-looking fonts, proper kerning, and layout",[1246],{"text":1251,"tools":1252},"Lovable is a full-stack development tool similar to Bolt, allowing rapid app creation",[1253,983],"Lovable",{"text":1255,"tools":1256},"The free tier of Lovable offers only five interactions per day",[1253],{"text":1258,"tools":1259},"Lovable provides intuitive interfaces, error correction features, and GitHub integration",[1253,1260],"GitHub",{"text":1262,"tools":1263},"Generative AI quality has improved to the point where many outputs no longer trigger the \"AI slop\" response",[1264],"AI Generation",{"text":1266,"tools":1267},"Supabase is highlighted as a valuable database solution that integrates well with app-building tools",[1075],[1269,1272,1275,1277],{"name":1246,"url":1270,"description":1271,"featured":54},"https://openai.com/sora","OpenAI's text-to-image and video generation model",{"name":1253,"url":1273,"description":1274,"featured":54},"https://lovable.dev","Full-stack application builder with AI assistance",{"name":983,"url":1064,"description":1276,"featured":54},"Similar AI-powered app development tool discussed in previous episodes",{"name":1075,"url":1076,"description":1278,"featured":54},"Database solution mentioned as integrating well with these tools",[1280,1283,1287,1290,1293,1296,1300,1304,1307,1311,1315,1319,1322],{"title":1281,"url":1282,"timestamp":70},"Introduction and recap of previous episodes","https://youtu.be/DcnbH45lfkU?t=0",{"title":1284,"url":1285,"timestamp":1286},"Discussion of AI-generated images for website thumbnails","https://youtu.be/DcnbH45lfkU?t=107","00:01:47",{"title":1288,"url":1289,"timestamp":338},"Examining Sora's image generation capabilities and examples","https://youtu.be/DcnbH45lfkU?t=300",{"title":1291,"url":1292,"timestamp":166},"Looking at 3D cartoon cat renderings from Sora","https://youtu.be/DcnbH45lfkU?t=540",{"title":1294,"url":1295,"timestamp":729},"Discussing the quality of AI-generated images","https://youtu.be/DcnbH45lfkU?t=600",{"title":1297,"url":1298,"timestamp":1299},"Introduction to Lovable app building tool","https://youtu.be/DcnbH45lfkU?t=738","00:12:18",{"title":1301,"url":1302,"timestamp":1303},"Exploring Lovable's full stack engineering claims","https://youtu.be/DcnbH45lfkU?t=885","00:14:45",{"title":1305,"url":1306,"timestamp":742},"Building a travel notebook app with Lovable","https://youtu.be/DcnbH45lfkU?t=1020",{"title":1308,"url":1309,"timestamp":1310},"Examining Lovable's code editor and GitHub integration","https://youtu.be/DcnbH45lfkU?t=1410","00:23:30",{"title":1312,"url":1313,"timestamp":1314},"Testing the WYSIWYG editor in Lovable","https://youtu.be/DcnbH45lfkU?t=1830","00:30:30",{"title":1316,"url":1317,"timestamp":1318},"Building and fixing errors in the travel notebook app","https://youtu.be/DcnbH45lfkU?t=2100","00:35:00",{"title":1320,"url":1321,"timestamp":1017},"Reviewing Ryan's weather dashboard app","https://youtu.be/DcnbH45lfkU?t=2460",{"title":1323,"url":1324,"timestamp":1325},"Final thoughts and takeaways","https://youtu.be/DcnbH45lfkU?t=2850","00:47:30","Remember when AI-generated images looked like they were made by drunk robots? Those days are officially over. Jason shows off Sora's latest party trick: creating professional thumbnails with actual readable text and proper typography—no more wonky letters that look like they survived a blender accident. But the real show starts when they fire up Lovable to build full-stack apps in real-time. Watch Jason attempt a travel notebook while Ryan crafts a weather dashboard, both racing against the cruel tyranny of free-tier limitations (spoiler: five interactions go fast when you're having this much fun). It's a masterclass in how AI tools have quietly crossed the line from \"impressive tech demo\" to \"actually useful.\"","In this episode, Jason Hand and Ryan MacLean explore recent developments in AI tools, focusing on image generation with Sora and app building with Lovable. They begin by discussing Jason's experience using Sora to create images for website thumbnails, noting the significant improvement in AI's ability to generate images with text. Both hosts are impressed by how Sora can now produce professional-looking fonts with proper kerning and layout, a capability that wasn't possible until recently. They examine various images Jason created, including Y2K aesthetic thumbnails and 3D cartoon renderings of cats, acknowledging that generative AI has reached a point where many outputs no longer trigger the 'AI slop' response they previously discussed. The conversation then shifts to Lovable, a full-stack development tool similar to Bolt (which they discussed in a previous episode). They explore Lovable's capabilities by building applications - Jason attempts to create a travel notebook app while Ryan builds a weather dashboard. Throughout their hands-on testing, they highlight Lovable's intuitive interface, error correction features, and ability to quickly generate functional applications with minimal input. They discuss limitations of the free tier (which offers only five interactions per day), the GitHub integration options, and how these tools might fit into a developer's workflow. The hosts conclude by reflecting on their evolving perspectives on generative AI tools, with Jason admitting he's warming up to some AI-generated content now that the quality has improved significantly, and both acknowledging Supabase as a valuable database solution that integrates well with these development tools.","src/content/episodes/ep15.mdx","77525631feec068f","ep15.mdx","ep16",{"id":1331,"data":1333,"body":1430,"filePath":1431,"digest":1432,"legacyId":1433,"deferredRender":104},{"title":1334,"description":1335,"heroImg":1336,"videoId":1337,"episodeNumber":1338,"date":1339,"author":20,"participants":1340,"tags":1341,"takeaways":1346,"resources":1365,"jumpTo":1385,"summary":1429,"featured":54,"transcriptAvailable":104},"Enhancing CSS Editing with LLMs: Using Puppeteer for Visual Context","Ryan demonstrates how to leverage Puppeteer's screenshot capabilities through MCP to provide visual context for LLMs, creating a virtuous cycle for CSS editing and design improvements.","../images/thumbnails/ep16.png","duMkcV7d_wo",16,"2025-04-30T00:00:00.000Z",[23],[1342,1343,1344,1345],"puppeteer","mcp","gemini","css",[1347,1352,1355,1358,1362],{"text":1348,"tools":1349},"Using visual context through screenshots helps LLMs make better CSS editing decisions than relying on text alone",[1350,1351],"Puppeteer","LLMs",{"text":1353,"tools":1354},"Puppeteer integration with LLMs creates a virtuous feedback cycle for quickly iterating on design changes",[1350,776],{"text":1356,"tools":1357},"The MCP (Model Control Protocol) server is essential for allowing LLMs to interact with local development environments",[776,1350],{"text":1359,"tools":1360},"Working in a test branch provides a safe environment for experimenting with AI-suggested CSS changes",[1361,534],"Git",{"text":1363,"tools":1364},"Despite requiring manual approval for screenshots, the workflow with Gemini 2.5 Pro is fast enough to create an efficient development experience",[959,1350],[1366,1369,1373,1377,1381],{"name":1350,"url":1367,"description":1368,"featured":54},"https://pptr.dev/","Headless browser automation library for taking screenshots of websites",{"name":1370,"url":1371,"description":1372,"featured":54},"Model Control Protocol (MCP)","https://github.com/google/model-control-protocol","Protocol for connecting AI models to external tools like Puppeteer",{"name":1374,"url":1375,"description":1376,"featured":54},"Gemini 2.5 Pro","https://ai.google.dev/gemini","Google's LLM used in the demonstration for CSS suggestions",{"name":1378,"url":1379,"description":1380,"featured":54},"PHP local server","https://www.php.net/manual/en/features.commandline.webserver.php","Used to serve static website files locally for testing",{"name":1382,"url":1383,"description":1384,"featured":54},"CSS documentation","https://developer.mozilla.org/en-US/docs/Web/CSS","Mozilla's comprehensive guide to CSS properties and syntax",[1386,1389,1393,1397,1401,1404,1407,1410,1413,1417,1421,1425],{"title":1387,"url":1388,"timestamp":70},"Introduction to editing CSS with LLMs","https://youtu.be/duMkcV7d_wo?t=0",{"title":1390,"url":1391,"timestamp":1392},"Challenges with CSS complexity and versioning","https://youtu.be/duMkcV7d_wo?t=45","00:00:45",{"title":1394,"url":1395,"timestamp":1396},"Examining the AI tools lab website and its extensive CSS","https://youtu.be/duMkcV7d_wo?t=75","00:01:15",{"title":1398,"url":1399,"timestamp":1400},"Introduction to using Puppeteer for visual context","https://youtu.be/duMkcV7d_wo?t=105","00:01:45",{"title":1402,"url":1403,"timestamp":404},"Setting up PHP to serve the static website locally","https://youtu.be/duMkcV7d_wo?t=150",{"title":1405,"url":1406,"timestamp":158},"First attempt at querying without Puppeteer enabled","https://youtu.be/duMkcV7d_wo?t=180",{"title":1408,"url":1409,"timestamp":491},"Enabling Puppeteer in the MCP server settings","https://youtu.be/duMkcV7d_wo?t=240",{"title":1411,"url":1412,"timestamp":408},"Dealing with screenshot approval requirements","https://youtu.be/duMkcV7d_wo?t=270",{"title":1414,"url":1415,"timestamp":1416},"Getting CSS suggestions based on the screenshot","https://youtu.be/duMkcV7d_wo?t=330","00:05:30",{"title":1418,"url":1419,"timestamp":1420},"Testing CSS changes in a safe test branch","https://youtu.be/duMkcV7d_wo?t=390","00:06:30",{"title":1422,"url":1423,"timestamp":1424},"Handling stalled screenshots and retrying","https://youtu.be/duMkcV7d_wo?t=435","00:07:15",{"title":1426,"url":1427,"timestamp":1428},"Reviewing the implemented header style changes","https://youtu.be/duMkcV7d_wo?t=465","00:07:45","CSS debugging just got a superpower upgrade. Ryan cracks the code on one of AI development's biggest frustrations: how do you explain visual problems to a model that can't see? His solution is elegantly simple yet revolutionary—hook up Puppeteer to take screenshots and feed them directly to Gemini 2.5 Pro, creating the first AI assistant that actually knows what your website looks like. Watch him turn the tedious cycle of \"describe the problem, get generic advice, repeat\" into a lightning-fast feedback loop where AI suggestions are based on actual visual evidence. It's like having a design partner who never gets tired of your CSS experiments.","In this presentation, Ryan explores a practical approach to editing CSS with Large Language Models (LLMs), focusing on creating a virtuous cycle of design improvements. He highlights the challenges of working with CSS, particularly for developers familiar with older versions who may struggle with modern CSS syntax and styles. Ryan points out that CSS can be complex, with styles defined in multiple locations, making it difficult to track changes and understand their impact across large codebases that may contain thousands of lines of code spread across numerous files.\r\n\r\nRyan demonstrates an innovative solution using Puppeteer through an MCP (Model Control Protocol) server to take screenshots of local websites. This approach allows the LLM to see the visual representation of the site, providing crucial context for making informed CSS recommendations. Throughout the demonstration, Ryan shows how to set up and configure the MCP server, start a local PHP server to host the test site, and use Gemini 2.5 Pro to suggest and implement CSS changes. Despite some workflow challenges such as needing to approve screenshot captures manually, Ryan emphasizes the speed advantages of this approach, noting that the quick feedback cycle creates an efficient workflow that almost mimics real-time browser editing but with AI assistance. The demonstration concludes with a successful modification to the header styling, illustrating the potential of this visual-context approach to AI-assisted CSS editing.","src/content/episodes/ep16.mdx","be933b80f267149b","ep16.mdx","ep17",{"id":1434,"data":1436,"body":1526,"filePath":1527,"digest":1528,"legacyId":1529,"deferredRender":104},{"title":1437,"description":1438,"heroImg":1439,"videoId":1440,"episodeNumber":1441,"date":1442,"author":20,"participants":1443,"tags":1444,"takeaways":1448,"resources":1469,"jumpTo":1488,"summary":1525,"featured":54,"transcriptAvailable":104},"The State of AI 2025: Exploring Developer Tools, Models, and Industry Trends","Jason and Ryan analyze the State of AI 2025 report, examining AI tool popularity, user pain points, and how tools like Google's Notebook LM help synthesize information from multiple sources.","../images/thumbnails/ep17.png","AcPDrBKy_Uw",17,"2025-04-29T00:00:00.000Z",[22,23],[1445,1446,290,1447],"stateofai","notebooklm","chatgpt",[1449,1453,1456,1460,1464],{"text":1450,"tools":1451},"ChatGPT remains the dominant AI model with Claude gaining rapid popularity, but there's a wide ecosystem of AI tools that many developers are still discovering",[1452,449],"ChatGPT",{"text":1454,"tools":1455},"The biggest pain points for AI users remain hallucinations/inaccuracies and context limitations, though these issues are being addressed with newer model versions that offer expanded context windows",[781],{"text":1457,"tools":1458},"Local model deployment is more common than expected (46% of respondents), likely driven by data privacy concerns rather than cost or performance considerations",[1459],"Local Models",{"text":1461,"tools":1462},"Despite concerns about AI-generated code quality, most developers (40%) report being happy with the current state of AI tools for web development, with only 10% being unhappy",[1463],"AI Development Tools",{"text":1465,"tools":1466},"According to DORA research, while generative AI provides individual productivity gains, it may actually have negative impacts on software delivery at organizational levels, suggesting challenges in team integration",[1467,1468],"DORA","Generative AI",[1470,1474,1478,1482,1486],{"name":1471,"url":1472,"description":1473,"featured":54},"The State of AI 2025 Report by Msty.ai","https://2025.stateofai.dev/en-US/","Comprehensive survey results about AI tool usage discussed throughout the episode",{"name":1475,"url":1476,"description":1477,"featured":54},"TL;DR Newsletter","https://tldr.tech/","Tech newsletter where the hosts discovered the State of AI report",{"name":1479,"url":1480,"description":1481,"featured":54},"DORA Report on Generative AI Impact","https://dora.dev/","Research suggesting that generative AI may have negative impacts on software delivery at organizational levels",{"name":1483,"url":1484,"description":1485,"featured":54},"Google's Notebook LM","https://notebooklm.google.com/","Tool demonstrated for synthesizing information from multiple sources",{"name":873,"url":881,"description":1487,"featured":54},"Service mentioned in relation to Cline for accessing multiple AI models",[1489,1492,1496,1499,1503,1507,1510,1513,1517,1521],{"title":1490,"url":1491,"timestamp":70},"Introduction and report identification","https://youtu.be/AcPDrBKy_Uw?t=0",{"title":1493,"url":1494,"timestamp":1495},"Report source and Msty.ai background","https://youtu.be/AcPDrBKy_Uw?t=85","00:01:25",{"title":1497,"url":1498,"timestamp":158},"Demographics of survey respondents","https://youtu.be/AcPDrBKy_Uw?t=180",{"title":1500,"url":1501,"timestamp":1502},"Popular AI model providers and user comments","https://youtu.be/AcPDrBKy_Uw?t=335","00:05:35",{"title":1504,"url":1505,"timestamp":1506},"Exploring IDE tools and lesser-known options","https://youtu.be/AcPDrBKy_Uw?t=536","00:08:56",{"title":1508,"url":1509,"timestamp":170},"IDE pain points and monetary considerations","https://youtu.be/AcPDrBKy_Uw?t=720",{"title":1511,"url":1512,"timestamp":178},"Coding assistants and tools comparison","https://youtu.be/AcPDrBKy_Uw?t=1080",{"title":1514,"url":1515,"timestamp":1516},"AI usage patterns and application types","https://youtu.be/AcPDrBKy_Uw?t=1350","00:22:30",{"title":1518,"url":1519,"timestamp":1520},"Code refactoring needs and quality issues","https://youtu.be/AcPDrBKy_Uw?t=1650","00:27:30",{"title":1522,"url":1523,"timestamp":1524},"Satisfaction with AI tools and psychological impact","https://youtu.be/AcPDrBKy_Uw?t=2040","00:34:00","What happens when 4,000 developers spill the tea on their AI tool usage? Jason and Ryan dive into the State of AI 2025 report, uncovering surprising truths about the tools actually winning hearts and minds. Spoiler alert: it's not just ChatGPT ruling the world—there's a whole underground ecosystem of AI tools most people have never heard of. But here's the plot twist that'll keep you up at night: while AI is making individual developers more productive, the DORA report suggests it might actually be making teams slower. Watch them dissect this paradox while discovering Google's Notebook LM, a tool that's quietly revolutionizing how we synthesize information from multiple sources. Sometimes the most important insights hide in the footnotes of progress.","In this engaging conversation, Jason Hand and Ryan MacLean dive into 'The State of AI 2025' report published by Msty.ai, analyzing the current landscape of AI tools, models, and developer preferences. They explore the comprehensive report which surveyed over 4,000 respondents, examining demographics, popular model providers, and developer pain points when using AI tools. The discussion highlights the dominance of tools like ChatGPT, Claude, and Microsoft Copilot, while also discovering lesser-known tools such as Phind, Qwen, Zed, and Void, which sparked curiosity about the rapidly expanding AI tooling ecosystem. Throughout their conversation, they reflect on how these tools have transformed their own workflows, particularly for code generation, summarization, and research purposes.\r\n\r\nWhat makes this discussion particularly valuable is the candid assessment of both the strengths and limitations of current AI models. They discuss common pain points including hallucinations, context limitations, and code quality issues, while noting that many of these problems are being addressed as models continue to improve. The duo examines how AI is impacting development workflows at different scales, from individual developers to team-wide adoption, referencing the DORA report which suggests that generative AI might actually have negative impacts on software delivery at organizational levels despite individual productivity gains. The conversation concludes with an exploration of Google's Notebook LM tool, which they demonstrate as a powerful resource for synthesizing information from multiple sources, highlighting the evolving landscape of AI tools designed to help knowledge workers manage and make sense of abundant information.","src/content/episodes/ep17.mdx","5ae7225de93ccb68","ep17.mdx","ep20",{"id":1530,"data":1532,"body":1617,"filePath":1618,"digest":1619,"legacyId":1620,"deferredRender":104},{"title":1533,"description":1534,"heroImg":1535,"videoId":1536,"episodeNumber":1537,"date":1538,"author":20,"participants":1539,"tags":1540,"takeaways":1542,"resources":1563,"jumpTo":1584,"summary":1616,"featured":54,"transcriptAvailable":104},"YOLO Coding: Migrating from Static HTML to Astro with AI Tools","In this episode, Ryan MacLean shares his weekend experiment with 'YOLO Mode' (You Only Live Once) in AI-assisted coding, where he migrated the ai-tools-lab.com website from static HTML to Astro. Ryan discusses his approach of using multiple AI models with Model Context Protocol (MCP) tools, particularly highlighting how he combined Gemini 2.5 Pro's multimodal capabilities with Claude Sonnet 3.7's web search functionality to tackle different aspects of the project.","../images/thumbnails/ep20.png","qgTu6hv6Hys",20,"2025-05-05T00:00:00.000Z",[23],[1342,1343,1344,290,1541],"astro",[1543,1547,1551,1554,1558],{"text":1544,"tools":1545},"AI 'YOLO Mode' can significantly accelerate website migrations, but requires constant human supervision to prevent security risks and unwanted changes",[772,1546],"YOLO Mode",{"text":1548,"tools":1549},"Combining different AI models (like Gemini 2.5 Pro for multimodal tasks and Claude Sonnet 3.7 for web searches) creates a more effective development workflow",[959,449,1550],"Multimodal AI",{"text":1552,"tools":1553},"Model Context Protocol (MCP) tools like Puppeteer and Sequential Thinking in Windsurf enable AI to interact with websites and execute multi-step processes",[776,1350,761],{"text":1555,"tools":1556},"AI models struggle with large files (like CSS) and special formats (like Base64), requiring workarounds or alternative approaches",[781,534,1557],"Base64",{"text":1559,"tools":1560},"Long AI sessions face context window limitations; creating checkpoints and to-do lists helps maintain progress across multiple sessions",[1561,1562],"AI Context","Project Management",[1564,1568,1572,1576,1580],{"name":1565,"url":1566,"description":1567,"featured":54},"AI Tools Lab Website","https://ai-tools-lab.com","The website that was migrated from static HTML to Astro",{"name":1569,"url":1570,"description":1571,"featured":54},"Astro Documentation","https://astro.build","Static site generator used for the migration",{"name":1573,"url":1574,"description":1575,"featured":54},"Context7 Documentation Repository","https://context7.ai","Tool for accessing documentation within AI workflows",{"name":1577,"url":1578,"description":1579,"featured":54},"Vitest Testing Framework","https://vitest.dev","Testing framework mentioned for automated testing",{"name":1581,"url":1582,"description":1583,"featured":54},"Puppeteer MCP","https://github.com/puppeteer/puppeteer","Model Context Protocol tool for browser automation",[1585,1588,1591,1594,1597,1600,1603,1606,1609,1613],{"title":1586,"url":1587,"timestamp":70},"Introduction and YOLO Mode Coding","https://www.youtube.com/watch?v=qgTu6hv6Hys?t=0",{"title":1589,"url":1590,"timestamp":897},"Overview of the HTML to Astro Migration Project","https://www.youtube.com/watch?v=qgTu6hv6Hys?t=60",{"title":1592,"url":1593,"timestamp":158},"Visual Comparison Challenges and CSS Issues","https://www.youtube.com/watch?v=qgTu6hv6Hys?t=180",{"title":1595,"url":1596,"timestamp":338},"Switching Between AI Models for Different Tasks","https://www.youtube.com/watch?v=qgTu6hv6Hys?t=300",{"title":1598,"url":1599,"timestamp":642},"Setting Up MCPs in Windsurf (Puppeteer and Sequential Thinking)","https://www.youtube.com/watch?v=qgTu6hv6Hys?t=420",{"title":1601,"url":1602,"timestamp":1221},"Safety Concerns with AI Auto-Approving Commands","https://www.youtube.com/watch?v=qgTu6hv6Hys?t=660",{"title":1604,"url":1605,"timestamp":174},"Memory Management and Context Windows","https://www.youtube.com/watch?v=qgTu6hv6Hys?t=900",{"title":1607,"url":1608,"timestamp":178},"Using Context7 for Documentation Access","https://www.youtube.com/watch?v=qgTu6hv6Hys?t=1080",{"title":1610,"url":1611,"timestamp":1612},"Maintaining To-Do Lists and Progress Tracking","https://www.youtube.com/watch?v=qgTu6hv6Hys?t=1320","00:22:00",{"title":1614,"url":1615,"timestamp":190},"Final Thoughts on AI-Assisted Site Migration","https://www.youtube.com/watch?v=qgTu6hv6Hys?t=1620","When Ryan decides to migrate an entire website framework over a weekend using \"YOLO Mode\" AI coding, you know you're in for a wild ride. Armed with multiple AI models, MCP tools, and a dangerous amount of confidence, he transforms the AI Tools Lab site from static HTML to Astro—while learning the framework on the fly. Watch him juggle Gemini 2.5 Pro's visual capabilities, Claude's web search prowess, and Puppeteer screenshots to pull off what should have taken weeks in just a few days. The results aren't perfect, but they're functional, and the learning curve is steep enough to give anyone vertigo. Sometimes the best way to learn is to jump off the cliff and build your wings on the way down.","In this episode, Ryan MacLean shares his weekend experiment with 'YOLO Mode' (You Only Live Once) in AI-assisted coding, where he migrated the ai-tools-lab.com website from static HTML to Astro. Ryan discusses his approach of using multiple AI models with Model Context Protocol (MCP) tools, particularly highlighting how he combined Gemini 2.5 Pro's multimodal capabilities with Claude Sonnet 3.7's web search functionality to tackle different aspects of the project. Ryan explains the challenges he faced, including models struggling with large CSS files and Base64-encoded graphics, and reveals his workflow using Puppeteer and Sequential Thinking MCPs in Windsurf to compare and migrate the site effectively. \r\n\r\nThroughout the conversation, Ryan emphasizes the importance of vigilant oversight when allowing AI tools to execute commands, especially around version control and API keys. He demonstrates how to set up MCPs in Windsurf, add Context7 for documentation access, and use to-do lists to checkpoint progress across lengthy AI sessions. Despite some visual discrepancies in the migrated site, Ryan found the process incredibly educational, allowing him to simultaneously learn Astro, improve his testing methodology with Vitest, automate deployments with Netlify, and enhance his work with Claude. Jason Hand, who initially suggested using AI for the migration, expresses excitement about how quickly they've been able to move from a static HTML site to a more maintainable content management system using these AI-powered development approaches.","src/content/episodes/ep20.mdx","78bf4b74431437cc","ep20.mdx","ep24",{"id":1621,"data":1623,"body":1703,"filePath":1704,"digest":1705,"legacyId":1706,"deferredRender":104},{"title":1624,"description":1625,"heroImg":1626,"videoId":1627,"episodeNumber":1628,"date":1629,"author":20,"participants":1630,"tags":1631,"takeaways":1632,"resources":1648,"jumpTo":1661,"summary":1702,"featured":54,"transcriptAvailable":104},"Streamlining AI Report Analysis: Figma AI 2025 Insights","The video discusses the challenges of keeping up with numerous 'State Of' or report PDFs, focusing on a specific AI report by Figma concerning the state of AI in 2025. Ryan MacLean explains how these reports, while informative, can be overwhelming due to their volume and the effort required to distill critical conclusions. Using the Claude Desktop app on Mac OS, Ryan demonstrates uploading and summarizing this AI report to draw meaningful insights efficiently.","../images/thumbnails/ep24.png","h9a-J2x-iog",24,"2025-05-05",[23],[290,1445,118],[1633,1636,1639,1642,1645],{"text":1634,"tools":1635},"**Efficiently summarizing large reports** can save time and reveal essential insights",[290],{"text":1637,"tools":1638},"Tools like **Claude can help create visual aids** such as infographics for presenting data",[290],{"text":1640,"tools":1641},"**Critical analysis and comparison** of reports can uncover unique insights and trends",[290],{"text":1643,"tools":1644},"**Effective data presentation** in professional settings requires clarity and precision",[290],{"text":1646,"tools":1647},"**Integrating findings from multiple reports** provides a comprehensive view of industry trends",[290],[1649,1653,1657],{"name":1650,"url":1651,"description":1652,"featured":54},"Figma AI Report 2025","https://www.figma.com/reports/ai-2025/","Figma's comprehensive report on the state of AI in 2025, focusing on design and development trends",{"name":1654,"url":1655,"description":1656,"featured":54},"McKinsey 'The State of AI: How organizations are rewiring to capture value' Report","https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai","McKinsey's analysis of how organizations are implementing AI to capture business value",{"name":1658,"url":1659,"description":1660,"featured":54},"XB Software Generative AI in Software Development: 2024 Impact and 2025 Predictions","https://xbsoftware.com/blog/ai-in-software-development/","Industry report on the impact of generative AI in software development with future predictions",[1662,1666,1670,1674,1678,1682,1686,1690,1694,1698],{"title":1663,"url":1664,"timestamp":1665},"Introduction to Report Analysis","https://youtu.be/h9a-J2x-iog?t=0","0:00",{"title":1667,"url":1668,"timestamp":1669},"Challenges of Multiple Reports","https://youtu.be/h9a-J2x-iog?t=20","0:20",{"title":1671,"url":1672,"timestamp":1673},"Using Claude Desktop for Summarization","https://youtu.be/h9a-J2x-iog?t=40","0:40",{"title":1675,"url":1676,"timestamp":1677},"Importance of Critical Analysis","https://youtu.be/h9a-J2x-iog?t=60","1:00",{"title":1679,"url":1680,"timestamp":1681},"Comparing Figma with Other Reports","https://youtu.be/h9a-J2x-iog?t=80","1:20",{"title":1683,"url":1684,"timestamp":1685},"Infographic Creation and Adjustments","https://youtu.be/h9a-J2x-iog?t=100","1:40",{"title":1687,"url":1688,"timestamp":1689},"Professional Data Presentation","https://youtu.be/h9a-J2x-iog?t=120","2:00",{"title":1691,"url":1692,"timestamp":1693},"Key Findings from AI Reports","https://youtu.be/h9a-J2x-iog?t=140","2:20",{"title":1695,"url":1696,"timestamp":1697},"Integrating Multiple Perspectives","https://youtu.be/h9a-J2x-iog?t=160","2:40",{"title":1699,"url":1700,"timestamp":1701},"Final Thoughts and Advice","https://youtu.be/h9a-J2x-iog?t=180","3:00","Report fatigue is real. Between Figma's AI insights, McKinsey's business analysis, and every tech company's 'State of' document, keeping up feels like drinking from a fire hose. Ryan demonstrates how Claude Desktop can be your secret weapon against information overload, turning dense PDFs into digestible insights and even generating infographics for professional presentations. But here's the catch: while AI can summarize anything, knowing which questions to ask and how to synthesize multiple perspectives still requires human judgment. It's not just about processing information faster—it's about processing it smarter.","The video discusses the challenges of keeping up with numerous \"State Of\" or report PDFs, focusing on a specific AI report by Figma concerning the state of AI in 2025. Ryan explains how these reports, while informative, can be overwhelming due to their volume and the effort required to distill critical conclusions. Using the Claude Desktop app on Mac OS, Ryan demonstrates uploading and summarizing this AI report to draw meaningful insights efficiently. Key elements such as important observations, citations, and resource links are highlighted as part of a critical approach to understanding various perspectives and comparing them to other reports like one from McKinsey, enabling a comprehensive understanding of AI trends. Despite the advantage of having auto-generated summaries, Ryan emphasizes the need for detailed exploration of reports and cautious presentation of data in professional settings.\r\n\r\nFurthermore, Ryan highlights the usefulness of tools like Claude for creating infographics from report data, which is crucial for effectively communicating findings in boardroom settings. Highlighting specific data points, such as the percentage of companies planning increased AI investments by 2025, illustrates the potential impact of AI proliferation. Ryan stresses the importance of context by comparing multiple reports and integrating findings, thus providing a holistic view of the AI landscape. This method allows users to discern discrepancies or blind spots in data interpretation, ensuring more robust conclusions.","src/content/episodes/ep24.mdx","898434290c737be5","ep24.mdx","ep26",{"id":1707,"data":1709,"body":1797,"filePath":1798,"digest":1799,"legacyId":1800,"deferredRender":104},{"title":1710,"description":1711,"heroImg":1712,"videoId":1713,"episodeNumber":1714,"date":1715,"author":20,"participants":1716,"tags":1717,"takeaways":1722,"resources":1739,"jumpTo":1759,"summary":1796,"featured":54,"transcriptAvailable":104},"Automating Content Transformation with N8N and Generative AI","In this video, Jason Hand discusses his innovative use of automation tools, specifically N8N, to enhance productivity in AI content transformation. He details the process of creating workflows that automate various tasks related to AI Tools Lab projects he works on. Initially, he describes a workflow designed to generate a set of artifacts from a video and its transcript. This involves creating episode images, moving files, and utilizing agents for content manipulation. However, Jason shifts the focus to additional utility from the content by sending follow-up questions to interview guests, capturing their answers in Airtable, and using this data to produce more content.","../images/thumbnails/ep26.png","0jCd_Rcyl3I",26,"2025-05-07",[22],[1718,1719,1720,1721],"n8n","automation","airtable","workflow",[1723,1726,1729,1732,1736],{"text":1724,"tools":1725},"**N8N automation** can significantly streamline workflow processes in content transformation",[1718],{"text":1727,"tools":1728},"Using **Airtable for tracking and managing data** from interviews enhances the content's depth and accuracy",[1720],{"text":1730,"tools":1731},"**Automation can help maintain consistency** and quality in content output through structured frameworks",[1718,1720],{"text":1733,"tools":1734},"**Experimenting with different AI models** can offer insights into performance and cost-effectiveness",[1735,290],"openai",{"text":1737,"tools":1738},"**Continual workflow adjustments** are crucial to meet evolving project needs and technological advancements",[1718],[1740,1744,1748,1752,1756],{"name":1741,"url":1742,"description":1743,"featured":54},"N8N Automation Tool","https://n8n.io/","Open-source workflow automation tool for connecting apps and automating tasks",{"name":1745,"url":1746,"description":1747,"featured":54},"Airtable","https://airtable.com/","Cloud collaboration service that combines the features of a database with a spreadsheet",{"name":1749,"url":1750,"description":1751,"featured":54},"OpenAI Models","https://openai.com/","AI models and API services for various applications including content generation",{"name":1753,"url":1754,"description":1755,"featured":54},"Astro Markdown","https://astro.build/","Static site generator with built-in markdown support for content management",{"name":1138,"url":1757,"description":1758,"featured":54},"https://www.google.com/drive/","Cloud storage service for file storage and collaboration",[1760,1763,1766,1769,1772,1776,1780,1784,1788,1792],{"title":1761,"url":1762,"timestamp":1665},"Introduction to N8N and AI Tools Lab","https://youtu.be/0jCd_Rcyl3I?t=0",{"title":1764,"url":1765,"timestamp":1677},"Automating Content transformation","https://youtu.be/0jCd_Rcyl3I?t=60",{"title":1767,"url":1768,"timestamp":1689},"Leveraging Airtable for Data Management","https://youtu.be/0jCd_Rcyl3I?t=120",{"title":1770,"url":1771,"timestamp":1701},"Generating Interview Questions","https://youtu.be/0jCd_Rcyl3I?t=180",{"title":1773,"url":1774,"timestamp":1775},"Processing Guest Responses","https://youtu.be/0jCd_Rcyl3I?t=240","4:00",{"title":1777,"url":1778,"timestamp":1779},"Drafting Blog Posts from Interviews","https://youtu.be/0jCd_Rcyl3I?t=300","5:00",{"title":1781,"url":1782,"timestamp":1783},"Image Generation and Customization","https://youtu.be/0jCd_Rcyl3I?t=360","6:00",{"title":1785,"url":1786,"timestamp":1787},"Integration with Google Drive","https://youtu.be/0jCd_Rcyl3I?t=420","7:00",{"title":1789,"url":1790,"timestamp":1791},"Exploring AI Models and Tools","https://youtu.be/0jCd_Rcyl3I?t=480","8:00",{"title":1793,"url":1794,"timestamp":1795},"Planning Future Workflow Enhancements","https://youtu.be/0jCd_Rcyl3I?t=540","9:00","What if every piece of content you create could automatically spawn ten more pieces of related content? Jason unveils his secret weapon: N8N workflows that transform a single video into an entire content ecosystem. Watch him demonstrate how automation can extract maximum value from interviews by generating follow-up questions, capturing guest responses in Airtable, and spinning everything into new articles, summaries, and insights. It's content multiplication through intelligent automation—the kind of workflow that makes you wonder why you ever did any of this manually.","In this video, Jason Hand discusses his innovative use of automation tools, specifically N8N, to enhance productivity in AI content transformation. He details the process of creating workflows that automate various tasks related to AI Tools Lab projects he works on. Initially, he describes a workflow designed to generate a set of artifacts from a video and its transcript. This involves creating episode images, moving files, and utilizing agents for content manipulation. However, Jason shifts the focus to additional utility from the content by sending follow-up questions to interview guests, capturing their answers in Airtable, and using this data to produce more content.\r\n\r\nJason elaborates on the automated systems that manage these tasks, including workflows that generate interview questions, send them to guests, and integrate their responses back into Airtable. From there, another system drafts a blog post combining transcript data and guest insights, stored in Google Drive, alongside a hero image. He demonstrates how tweaks, such as avoiding text in images, are addressed through prompt adjustments. Further efforts involve exploring different AI models like Gemini 2.0 and managing ongoing content requirements with markdown files in Astro. Through his walkthrough, Jason highlights the potential for automation in streamlining content production workflows.","src/content/episodes/ep26.mdx","cd45602cd188c510","ep26.mdx","ep27",{"id":1801,"data":1803,"body":1888,"filePath":1889,"digest":1890,"legacyId":1891,"deferredRender":104},{"title":1804,"description":1805,"heroImg":1806,"videoId":1807,"episodeNumber":1808,"date":1809,"author":20,"participants":1810,"tags":1812,"takeaways":1817,"resources":1833,"jumpTo":1849,"summary":1887,"featured":54,"transcriptAvailable":104},"Exploring Coding Efficiency: Utilizing Tmux and Claude Code for AI-Powered Ray Tracing","In this video, Jason Hand and Scott Gerring dive into the benefits and innovations surrounding coding tools like Tmux, Helix, and particularly Claude Code. Scott shares his journey of embracing new technologies that allow programmers to guide AI in developing complex projects such as ray tracing without manually altering the code. He explains how these tools can integrate seamlessly into a programmer's existing setup by utilizing terminal multiplexers like Tmux to enhance productivity.","../images/thumbnails/ep27.png","qCW1n79Thgo",27,"2025-05-08",[22,1811],"Scott Gerring",[1813,1814,1815,1816],"tmux","claude-code","terminal","helix",[1818,1821,1824,1827,1830],{"text":1819,"tools":1820},"**Embrace new technologies** like terminal-based editing tools that increase productivity",[1813,1816],{"text":1822,"tools":1823},"**Claude Code facilitates complex project completion** through effective use of AI",[1814],{"text":1825,"tools":1826},"**Creating an elaborate setup** leads to better management of large projects",[1813,1814],{"text":1828,"tools":1829},"Using **detailed project logs** can assist in identifying errors and improving workflow",[1814],{"text":1831,"tools":1832},"The utility of **test coverage checks** helps maintain code reliability during development",[1814],[1834,1838,1842,1845],{"name":1835,"url":1836,"description":1837,"featured":54},"Tmux Official Page","https://github.com/tmux/tmux/wiki","Terminal multiplexer for splitting windows and managing sessions",{"name":1839,"url":1840,"description":1841,"featured":54},"Helix Editor","https://github.com/helix-editor/helix","A post-modern text editor built with Rust",{"name":295,"url":1843,"description":1844,"featured":54},"https://www.anthropic.com/claude","AI-powered coding assistant from Anthropic",{"name":1846,"url":1847,"description":1848,"featured":54},"Rust Test Coverage","https://doc.rust-lang.org/cargo/commands/cargo-test.html","Information on testing and code coverage in Rust projects",[1850,1853,1857,1860,1864,1868,1872,1875,1879,1883],{"title":1851,"url":1852,"timestamp":1665},"Introduction","https://youtu.be/qCW1n79Thgo?t=0",{"title":1854,"url":1855,"timestamp":1856},"Enthusiasm for New Tools","https://youtu.be/qCW1n79Thgo?t=13","0:13",{"title":1858,"url":1859,"timestamp":1677},"Transitioning from VS Code","https://youtu.be/qCW1n79Thgo?t=60",{"title":1861,"url":1862,"timestamp":1863},"Introduction to Tmux","https://youtu.be/qCW1n79Thgo?t=94","1:34",{"title":1865,"url":1866,"timestamp":1867},"Setting Up Development Environment","https://youtu.be/qCW1n79Thgo?t=165","2:45",{"title":1869,"url":1870,"timestamp":1871},"Using Claude Code","https://youtu.be/qCW1n79Thgo?t=245","4:05",{"title":1873,"url":1874,"timestamp":1779},"Project Exploration with Ray Tracing","https://youtu.be/qCW1n79Thgo?t=300",{"title":1876,"url":1877,"timestamp":1878},"Problem Solving With Prompts","https://youtu.be/qCW1n79Thgo?t=405","6:45",{"title":1880,"url":1881,"timestamp":1882},"Test Coverage Verification Practices","https://youtu.be/qCW1n79Thgo?t=510","8:30",{"title":1884,"url":1885,"timestamp":1886},"Examination of Program Output","https://youtu.be/qCW1n79Thgo?t=630","10:30","Scott Gerring just ditched VS Code for something that sounds like it came from the 1990s—and he's having the time of his life. Meet the terminal purist who's building ray tracers with Claude Code while living entirely inside tmux and Helix. Watch Scott demonstrate how stripping away the GUI actually enhances his AI-powered development workflow, creating a surprisingly efficient partnership between old-school terminal tools and cutting-edge AI assistance. Sometimes the future of coding looks a lot like going back to basics, just with smarter help.","In this video, Jason Hand and Scott Gerring dive into the benefits and innovations surrounding coding tools like Tmux, Helix, and particularly Claude Code. Scott shares his journey of embracing new technologies that allow programmers to guide AI in developing complex projects such as ray tracing without manually altering the code. He explains how these tools can integrate seamlessly into a programmer's existing setup by utilizing terminal multiplexers like Tmux to enhance productivity.\r\n\r\nScott further elaborates on using Claude Code within his workflow, allowing for an automated yet structured approach where high-level prompts guide the AI's coding process. The emphasis is on the importance of creating a thorough conceptual framework before letting AI execute tasks autonomously. Using real-time interaction with these tools, Scott highlights their effectiveness in handling complex queries in large code bases while saving time and elevating project complexity with minimal human supervision.","src/content/episodes/ep27.mdx","53f51b40ee33f455","ep27.mdx","ep28",{"id":1892,"data":1894,"body":1979,"filePath":1980,"digest":1981,"legacyId":1982,"deferredRender":104},{"title":1895,"description":1896,"heroImg":1897,"videoId":1898,"episodeNumber":1899,"date":1900,"author":20,"participants":1901,"tags":1903,"takeaways":1907,"resources":1925,"jumpTo":1940,"summary":1978,"featured":54,"transcriptAvailable":104},"Exploring eBPF with AI Tools: Insights and Applications","In this session, Jason Hand and Scott Mabe delve into the intriguing world of eBPF (Extended Berkeley Packet Filter) and its integration with AI tools for learning and application development. The discussion begins with Scott explaining his approach to learning new technologies through experimentation, using eBPF as a case in point.","../images/thumbnails/ep28.png","BuPf-qAzTJI",28,"2025-05-08T00:00:00.000Z",[22,1902],"Scott Mabe",[1904,1447,1905,1906],"ebpf","github-copilot","system-monitoring",[1908,1912,1915,1918,1922],{"text":1909,"tools":1910},"eBPF allows deep interaction with OS kernels, providing significant control over hardware resources.",[1911],"eBPF",{"text":1913,"tools":1914},"Generative AI tools like ChatGPT can aid non-developers in scripting tasks rapidly.",[1452],{"text":1916,"tools":1917},"Datadog utilizes eBPF for enhancing system observability in various products.",[1911,307],{"text":1919,"tools":1920},"AI tooling expedites coding by providing a basis upon which developers can build further.",[1452,1921],"GitHub Copilot",{"text":1923,"tools":1924},"Learning through hands-on experimentation fosters deeper understanding than theoretical study alone.",[1911,1452],[1926,1930,1934,1937],{"name":1927,"url":1928,"description":1929,"featured":54},"eBPF Official Documentation","https://ebpf.io/","Official documentation and resources for eBPF technology",{"name":1931,"url":1932,"description":1933,"featured":54},"eBPF Overview - Datadog Knowledge Center","https://www.datadoghq.com/knowledge-center/ebpf/","Comprehensive guide to eBPF and its applications in observability",{"name":1452,"url":1935,"description":1936,"featured":54},"https://chat.openai.com/chat","AI assistant used for generating eBPF monitoring scripts",{"name":1921,"url":1938,"description":1939,"featured":54},"https://github.com/features/copilot","AI-powered code completion tool used for debugging and code assistance",[1941,1943,1947,1950,1954,1958,1962,1966,1970,1974],{"title":1851,"url":1942,"timestamp":70},"https://youtu.be/BuPf-qAzTJI?t=0",{"title":1944,"url":1945,"timestamp":1946},"Learning about eBPF","https://youtu.be/BuPf-qAzTJI?t=41","00:00:41",{"title":1948,"url":1949,"timestamp":331},"Overview of Operating System Kernel Interaction","https://youtu.be/BuPf-qAzTJI?t=120",{"title":1951,"url":1952,"timestamp":1953},"Use Cases of eBPF at Datadog","https://youtu.be/BuPf-qAzTJI?t=225","00:03:45",{"title":1955,"url":1956,"timestamp":1957},"Generative AI in Coding Demonstration","https://youtu.be/BuPf-qAzTJI?t=298","00:04:58",{"title":1959,"url":1960,"timestamp":1961},"Initial Coding Challenges and Solutions","https://youtu.be/BuPf-qAzTJI?t=350","00:05:50",{"title":1963,"url":1964,"timestamp":1965},"Exploring Various Tools Related to eBPF","https://youtu.be/BuPf-qAzTJI?t=426","00:07:06",{"title":1967,"url":1968,"timestamp":1969},"Exploration of Networking Capabilities via eBPF Programs","https://youtu.be/BuPf-qAzTJI?t=549","00:09:09",{"title":1971,"url":1972,"timestamp":1973},"Discussion on Presentation Focused on Promoting eBPF","https://youtu.be/BuPf-qAzTJI?t=611","00:10:11",{"title":1975,"url":1976,"timestamp":1977},"Encouragements About Learning With AI Tools","https://youtu.be/BuPf-qAzTJI?t=670","00:11:10","What happens when you combine kernel-level programming with AI assistance? Scott Mabe takes Jason on a deep dive into eBPF—the technology that lets you hook directly into the Linux kernel without crashing your entire system. From Datadog's production monitoring tools to cybersecurity student exercises, eBPF is quietly powering some of the most critical infrastructure on the planet. Watch Scott use ChatGPT and GitHub Copilot to build real eBPF programs that monitor sensitive system files, proving that even the most low-level systems programming can benefit from AI assistance. It's equal parts educational and slightly terrifying when you realize how much power these tools put at your fingertips.","In this session, Jason Hand and Scott Mabe delve into the intriguing world of eBPF (Extended Berkeley Packet Filter) and its integration with AI tools for learning and application development. The discussion begins with Scott explaining his approach to learning new technologies through experimentation, using eBPF as a case in point.\r\n\r\nThey explore how eBPF interacts intimately with the operating system kernel, allowing users significant control over hardware for tasks such as memory access and network management. The conversation touches on Datadog's use of eBPF for enhancing observability through Universal Service Monitoring, Cloud Network Monitoring, and security tools. Scott shares an anecdote about encouraging cybersecurity students to learn about eBPF by looking it up on their phones during events.\r\n\r\nThe dialogue transitions into a demonstration where Scott uses generative AI tools like ChatGPT to write a program monitoring changes to crucial Linux files like the shadow file, which is critical for user privilege configurations. Despite initial coding challenges resolved via GitHub Copilot, this process underscores the value of these AI tools in developing functional scripts swiftly without extensive manual research or coding expertise. Both participants acknowledge the iterative nature of using large language models across multiple platforms to achieve workable solutions while emphasizing that although not perfect initially, these technologies significantly expedite development processes by offering foundational code quickly.","src/content/episodes/ep28.mdx","f46a899378bdfd31","ep28.mdx","ep29",{"id":1983,"data":1985,"body":2089,"filePath":2090,"digest":2091,"legacyId":2092,"deferredRender":104},{"title":1986,"description":1987,"heroImg":1988,"videoId":1989,"episodeNumber":1990,"date":1991,"author":20,"participants":1992,"tags":1993,"takeaways":1996,"resources":2015,"jumpTo":2026,"summary":2088,"featured":54,"transcriptAvailable":104},"Building a Lissajous Animation Using Gemini 2.5 Pro","In this episode, Jason Hand and Ryan MacLean explore the capabilities of Gemini 2.5 Pro, demonstrating its impressive features through hands-on examples including creating interactive mathematical visualizations and discussing its enhanced context handling capabilities.","../images/thumbnails/ep29.png","UPC03_FD0-I",29,"2025-05-12T00:00:00.000Z",[22,23],[1344,1034,1994,1995],"coding","visualization",[1997,2000,2003,2006,2009,2012],{"text":1998,"tools":1999},"Gemini 2.5 Pro features a **million token context window**, enabling better handling of large projects without context loss.",[1374],{"text":2001,"tools":2002},"The model demonstrates improved **context caching**, maintaining coherence across extended interactions and development sessions.",[1374],{"text":2004,"tools":2005},"Real-time **code generation capabilities** are showcased through interactive mathematical visualizations created in under 30 seconds.",[1374],{"text":2007,"tools":2008},"The model excels at understanding and implementing **complex mathematical concepts** like Lissajous figures with proper physics.",[1374],{"text":2010,"tools":2011},"Integration potential with **educational tools** is highlighted through interactive demos that blend math, science, and programming.",[1374],{"text":2013,"tools":2014},"**Free research preview** access makes advanced AI capabilities accessible for experimentation and learning.",[1374],[2016,2018,2022],{"name":1374,"url":1375,"description":2017,"featured":54},"Google's latest AI model with enhanced capabilities and million token context window",{"name":2019,"url":2020,"description":2021,"featured":54},"Lissajous Figures","https://en.wikipedia.org/wiki/Lissajous_curve","Mathematical background on the visualization patterns demonstrated in the episode",{"name":2023,"url":2024,"description":2025,"featured":54},"Google AI Studio","https://aistudio.google.com/","Web interface for accessing and experimenting with Gemini models",[2027,2030,2034,2038,2042,2045,2049,2053,2057,2061,2064,2068,2072,2076,2080,2084],{"title":2028,"url":2029,"timestamp":70},"Introduction to AI Discussion","https://youtu.be/UPC03_FD0-I?t=0",{"title":2031,"url":2032,"timestamp":2033},"Gemini 2.5 Pro Overview","https://youtu.be/UPC03_FD0-I?t=30","00:00:30",{"title":2035,"url":2036,"timestamp":2037},"Context Window and Caching Features","https://youtu.be/UPC03_FD0-I?t=47","00:00:47",{"title":2039,"url":2040,"timestamp":2041},"Large Project Handling Experience","https://youtu.be/UPC03_FD0-I?t=95","00:01:35",{"title":2043,"url":2044,"timestamp":483},"Lissajous Figure Introduction","https://youtu.be/UPC03_FD0-I?t=118",{"title":2046,"url":2047,"timestamp":2048},"Mathematical Visualization Demo","https://youtu.be/UPC03_FD0-I?t=129","00:02:09",{"title":2050,"url":2051,"timestamp":2052},"Oscilloscope Connection","https://youtu.be/UPC03_FD0-I?t=189","00:03:09",{"title":2054,"url":2055,"timestamp":2056},"Code Generation Prompt","https://youtu.be/UPC03_FD0-I?t=211","00:03:31",{"title":2058,"url":2059,"timestamp":2060},"Model Thinking Process","https://youtu.be/UPC03_FD0-I?t=248","00:04:08",{"title":2062,"url":2063,"timestamp":338},"Generated Code Review","https://youtu.be/UPC03_FD0-I?t=300",{"title":2065,"url":2066,"timestamp":2067},"Interactive Demo Showcase","https://youtu.be/UPC03_FD0-I?t=333","00:05:33",{"title":2069,"url":2070,"timestamp":2071},"Speed Test - Second Generation","https://youtu.be/UPC03_FD0-I?t=387","00:06:27",{"title":2073,"url":2074,"timestamp":2075},"29.6 Second Code Generation","https://youtu.be/UPC03_FD0-I?t=433","00:07:13",{"title":2077,"url":2078,"timestamp":2079},"Version Comparison","https://youtu.be/UPC03_FD0-I?t=453","00:07:33",{"title":2081,"url":2082,"timestamp":2083},"Export and Integration Options","https://youtu.be/UPC03_FD0-I?t=541","00:09:01",{"title":2085,"url":2086,"timestamp":2087},"Educational Applications Discussion","https://youtu.be/UPC03_FD0-I?t=629","00:10:29","Google's Gemini 2.5 Pro just turned Jason into a mathematical visualization wizard in under 30 seconds. Watch him conjure up a fully interactive Lissajous figure animation—complete with adjustable parameters and hypnotic patterns—using nothing but conversational prompts. Ryan shares his experience wrestling with the model's million-token context window on large projects, discovering that this AI doesn't just remember everything you've done—it actually gets better at helping you as sessions progress. It's like having a coding partner with perfect memory and a PhD in applied mathematics who never gets tired of your experimental ideas.","In this episode, Jason Hand and Ryan MacLean delve into the capabilities of Gemini 2.5 Pro, a state-of-the-art AI model released by Google. The discussion begins with an overview of their personal experiences experimenting with the model, highlighting its impressive features such as a million token context window and effective context caching which significantly aids in handling large projects like the AI Tools Lab site. Ryan shares his prior engagement with the model's coding functionalities, appreciating its capacity to manage broader scopes without issues unlike previous models. The conversation takes a hands-on turn as Jason demonstrates creating an animated Lissajous Figure using Gemini 2.5 Pro by generating HTML, JavaScript, and CSS code that enables user-interaction through adjustable variables. This practical application not only showcases the model's computational speed—producing sophisticated outputs in seconds—but also illustrates its potential as an educational tool blending math, science, and programming. As they wrap up, both express enthusiasm about future explorations into similar mathematical visualizations using Gemini 2.5 Pro.","src/content/episodes/ep29.mdx","2d5cbc35c76cb692","ep29.mdx","ep30",{"id":2093,"data":2095,"body":2199,"filePath":2200,"digest":2201,"legacyId":2202,"deferredRender":104},{"title":2096,"description":2097,"heroImg":2098,"videoId":2099,"episodeNumber":2100,"date":2101,"author":20,"participants":2102,"tags":2104,"takeaways":2107,"resources":2129,"jumpTo":2141,"summary":2198,"featured":54,"transcriptAvailable":104},"Maximizing AI with Cursor: Building MCP Servers for Seamless Workflow","Whitney Lee shares her journey of building an MCP (Model Context Protocol) server designed to automate engineering journal entries. Learn how she evolved from experimenting with basic Cursor capabilities to developing a robust tool that captures Git commits, AI chat history, and terminal commands to enhance developer documentation and reflection.","../images/thumbnails/ep30.png","z45LjlhyGyE",30,"2025-05-23T00:00:00.000Z",[2103,22],"Whitney Lee",[1343,119,1034,2105,2106],"developer-tools","documentation",[2108,2111,2115,2120,2123,2126],{"text":2109,"tools":2110},"Start with **raw AI tools** to understand their capabilities before adding extensions or plugins.",[134],{"text":2112,"tools":2113},"Create **preference files** and workflows to maintain consistency across AI interactions and reduce repetitive instructions.",[134,2114],"Memory MCP",{"text":2116,"tools":2117},"Use **MCP servers** like Memory, Context 7, and Taskmaster to solve specific workflow problems systematically.",[2114,2118,2119],"Context 7","Taskmaster",{"text":2121,"tools":2122},"Implement **test-driven development** and anti-hallucination rules when working with AI to ensure code quality.",[134,449],{"text":2124,"tools":2125},"Build **engineering journals** that automatically capture Git commits, AI chats, and terminal commands for better project tracking.",[776,1361],{"text":2127,"tools":2128},"Apply **zero-trust principles** to AI development - always verify outputs and pit different LLMs against each other.",[134,449,1452],[2130,2133,2137],{"name":134,"url":2131,"description":2132,"featured":54},"https://www.cursor.so/","AI-powered code editor for enhanced development workflow",{"name":2134,"url":2135,"description":2136,"featured":54},"Taskmaster MCP","https://mcpmarket.com/server/task-master","Project management and task breakdown tool for AI workflows",{"name":2138,"url":2139,"description":2140,"featured":54},"Context 7 MCP","https://github.com/upstash/context7","Real-time documentation and context retrieval for development",[2142,2145,2149,2152,2155,2158,2161,2164,2168,2172,2175,2178,2182,2186,2190,2194],{"title":2143,"url":2144,"timestamp":70},"Introduction and Welcome","https://youtu.be/z45LjlhyGyE?t=0",{"title":2146,"url":2147,"timestamp":2148},"Weekend Vibe Coding with Cursor","https://youtu.be/z45LjlhyGyE?t=24","00:00:24",{"title":2150,"url":2151,"timestamp":331},"Spider Demo App Showcase","https://youtu.be/z45LjlhyGyE?t=120",{"title":2153,"url":2154,"timestamp":158},"Challenges with Raw Cursor","https://youtu.be/z45LjlhyGyE?t=180",{"title":2156,"url":2157,"timestamp":162},"MCP Server Solutions","https://youtu.be/z45LjlhyGyE?t=360",{"title":2159,"url":2160,"timestamp":345},"Engineering Journal Vision","https://youtu.be/z45LjlhyGyE?t=480",{"title":2162,"url":2163,"timestamp":166},"Conversational Prompt Technique","https://youtu.be/z45LjlhyGyE?t=540",{"title":2165,"url":2166,"timestamp":2167},"Test-Driven Development with AI","https://youtu.be/z45LjlhyGyE?t=809","00:13:29",{"title":2169,"url":2170,"timestamp":2171},"Zero Trust AI Principles","https://youtu.be/z45LjlhyGyE?t=880","00:14:40",{"title":2173,"url":2174,"timestamp":174},"MCP Server Architecture","https://youtu.be/z45LjlhyGyE?t=900",{"title":2176,"url":2177,"timestamp":742},"Journal Entry Structure","https://youtu.be/z45LjlhyGyE?t=1020",{"title":2179,"url":2180,"timestamp":2181},"Automated Summaries and Reflections","https://youtu.be/z45LjlhyGyE?t=1123","00:18:43",{"title":2183,"url":2184,"timestamp":2185},"Learning Python with AI","https://youtu.be/z45LjlhyGyE?t=1258","00:20:58",{"title":2187,"url":2188,"timestamp":2189},"Manual Reflection Features","https://youtu.be/z45LjlhyGyE?t=1328","00:22:08",{"title":2191,"url":2192,"timestamp":2193},"AI Prompt-Based Functions","https://youtu.be/z45LjlhyGyE?t=1364","00:22:44",{"title":2195,"url":2196,"timestamp":2197},"Future Development Plans","https://youtu.be/z45LjlhyGyE?t=1715","00:28:35","Whitney Lee's weekend 'vibe coding' session just escalated into building the engineering journal of the future. What started as casual experimentation with Cursor spiraled into creating an MCP server that automatically captures Git commits, AI conversations, and terminal commands to generate reflective journal entries. Watch someone with a Kubernetes background tackle app development for the first time in years, discovering that the real magic isn't just in the code—it's in creating systems that help you think about your thinking. Sometimes the best productivity hack is building the tool that documents your own learning journey.","In this in-depth conversation, Whitney Lee shares how a weekend of \"vibe coding\" with Cursor spiraled into building her own MCP (Model Context Protocol) server—designed to automate the creation of engineering journal entries from Git commits, AI chats, and terminal commands.\r\n\r\nWith a background in Kubernetes and platform engineering—but not recent app development—Whitney walks through the creative and technical decisions behind her playful demo app and the real problem it helped her solve: tracking her technical progress and decisions with context, clarity, and reflection.\r\n\r\nShe explores:\r\n\r\n- Why she started with raw Cursor and deliberately held off on using MCP tools\r\n- The specific challenges she encountered—like lack of memory, unclear documentation sourcing, and staying on task\r\n- How tools like Taskmaster, Memory, and Context 7 helped address those issues\r\n- Her vision for a journaling MCP server that automatically generates daily, weekly, and monthly summaries—complete with tone, milestones, terminal history, and reflections\r\n- How she designed and validated the architecture using AI-driven dialogue, test-driven development, and zero-trust principles\r\n\r\nThis episode offers a real-world look at how AI tooling can support—not replace—human thinking, and how to shape those tools into something genuinely useful and sustainable.","src/content/episodes/ep30.mdx","f2626bd87926212d","ep30.mdx","ep31",{"id":2203,"data":2205,"body":2256,"filePath":2257,"digest":2258,"legacyId":2259,"deferredRender":104},{"title":2206,"description":2207,"heroImg":2208,"videoId":2209,"episodeNumber":2210,"date":2211,"author":20,"participants":2212,"tags":2213,"takeaways":2214,"resources":2229,"jumpTo":2234,"summary":2254,"featured":54,"transcriptAvailable":104,"transcriptContent":2255},"Building client-side URL-based state apps using Claude 4 and Lovable","Jason Hand and Ryan MacLean chat and demonstrate practical uses of Claude and Lovable in coming up with and building on ideas very quickly .. daily .. almost as a personal challenge.","../images/thumbnails/ep31.png","EPZn3gidiS8",31,"2025-06-04T22:32:17.000Z",[22,23],[290,1240,1034,2105,118],[2215,2218,2221,2224,2226],{"text":2216,"tools":2217},"Using AI like Claude and Lovable can act as a notebook or **second brain** for capturing fleeting ideas.",[449,1253],{"text":2219,"tools":2220},"These tools reduce **cognitive load** by allowing users to store thoughts efficiently without overburdening mental resources.",[449,1253],{"text":2222,"tools":2223},"Free plans available in these apps offer enough functionality to spark creativity through **limitations**.",[449,1253],{"text":2225},"Rapid development frameworks allow you to transform high-level project concepts into **workable prototypes** quickly.",{"text":2227,"tools":2228},"Accessibility of such technology **democratizes problem-solving**, making it easier for non-developers to innovate solutions.",[449,1253],[2230,2232],{"name":449,"url":1161,"description":2231,"featured":54},"AI assistant for coding, writing, and problem-solving",{"name":1253,"url":1273,"description":2233,"featured":54},"AI-powered rapid application development platform",[2235,2238,2242,2246,2250],{"title":2236,"url":2237,"timestamp":70},"Intro & Morning Routines","https://youtu.be/EPZn3gidiS8?t=000",{"title":2239,"url":2240,"timestamp":2241},"Cognitive Load Management","https://youtu.be/EPZn3gidiS8?t=500","00:08:20",{"title":2243,"url":2244,"timestamp":2245},"Challenges with Traditional Coding","https://youtu.be/EPZn3gidiS8?t=1000","00:16:40",{"title":2247,"url":2248,"timestamp":2249},"Developing Practical Apps","https://youtu.be/EPZn3gidiS8?t=2000","00:33:20",{"title":2251,"url":2252,"timestamp":2253},"Final Thoughts on Leveraging AI","https://youtu.be/EPZn3gidiS8?t=3000","00:50:00","What if your morning coffee routine could include building entire web applications? Jason reveals his daily ritual of using Claude and Lovable as a \"butterfly net\" for fleeting ideas—capturing those ephemeral thoughts that usually vanish before the caffeine kicks in. Watch him demonstrate client-side URL-based state management in apps built in minutes, not hours. It's part creative exercise, part technical challenge, and entirely addictive. When the barrier between idea and implementation becomes this thin, the question isn't whether you can build it—it's whether you should stop yourself from building everything.","[00:00:00] **Jason Hand:** I have this routine now. Pretty much every morning I wake up outside, drink a cup of coffee or two and read through my emails and different mailing lists and stuff that I'm on.\nAnd occasionally I'll get like an idea. And I'll just immediately switch over to Claude, or, it's usually Claude, but something and. And then just like jam out, like a quick prompt and see if I can get something going as almost like a notebook for me. Like a placeholder. I might not be able to finish it right now in the next cup of coffee.\n[00:00:28] **Ryan MacLean:** Oh yeah. You see you're touching on something that's a big thing for me. Are you using it kinda like Evernote? You've got a bunch of projects in the mix or what have you. \n[00:00:35] **Jason Hand:** I'm just using it as a second brain 'cause I don't trust my own love that you know, same. I. I don't mean that to sound like \n[00:00:42] **Ryan MacLean:** No, I hear you though.\nIf you're working on two or three projects, it's difficult to have the context in your head of the, a lot of \n[00:00:46] **Jason Hand:** ideas just, they come and go. Yeah. And it's just the truth. And I guess that at this point in my life, I've learned like my own little hacks to capture 'em, like butterfly net, it's oh, that's a good one.\nI gotta get it. And I put 'em wherever I can that I know, I know where I'll find them. [00:01:00] And that's what these are, that's what these are turning into, at least when it comes to solving small little problems or doing something that like helps with a hobby. Or, which is like one of some of the stuff I've been working on right.\nOr recently is the summer is here and it's its time to get out and go see your friends and do fun stuff on the weekends and absolutely. Music festivals and just all kinds of fun stuff. And, but unfortunately we all are busy people and we have families and things and it's hard to like schedule time together.\nSo it's a common problem. \n[00:01:32] **Ryan MacLean:** Now there's, before you show us the app I get a quick question, like, how long is this session for you? Because for me to code generally, and I'm talking about maybe pre 2020 brain, it, that's a two to five hour at least process. It takes a long time for me to get into I don't wanna say the zone, but get into the working area where I've got my docs on one screen.\nIt's got probably a command line and an open code editor that'll take me, maybe not two hours, it'll take me at least an hour. To get up to speed to where I was before. And then feel like I'm actually doing some work again. [00:02:00] How long does it take you? Because it feels five minutes for me now if I'm just opening up a, like a Claude session.\n[00:02:05] **Jason Hand:** What I'm actually finding I'm doing unintentionally is I'm using like Claude's free plan. And I'm also been playing around with Lovable, but staying on their free plan. Of course there's limitations for both. Claude has like usage token window yeah. Limits that are they flex, based on like demand.\nAnd you'll run out. Especially like I've started really I told you before we were recording, I, I started really enjoying Astro because we've migrated our site and like I'm learning Astro. So now like a lot of my projects, I want them to be Astro projects. Gotcha. 'cause it just gives me so much flexibility and so many things you can do with it.\nAnd but that's a lot of code. It certainly can be. Yeah. Agreed. I'm running out of I'm basically burning through the free stuff that they give you, whether it's the token limits on Claude, i'm not able to get more than maybe five back and forth conversations. Or prompts and responses.\nWhich isn't all that different from Lovable. You get five and I've been treating it like a challenge. It's not often [00:03:00] it'll get a zero shot. A lot of times the app is functional, it'll do what you said, but it's not what I have in my mind yet.\nBut if I can get there in five, like I, have with Lovable or until I run out of tokens on Claude, and they'll give you more every five hours by the way. But, I don't know. That's kinda my morning challenge. It's like how I've started to like boot up in the morning. \n[00:03:19] **Ryan MacLean:** Is that like half hour of work or an hour of work?\nYeah. Sorry to put a number on it. \n[00:03:23] **Jason Hand:** Yeah, I would say it's probably half hour to 60 minutes or so, and I don't know, some of that's also mixed. I, IGI bounce back and forth between reading stuff and maybe even also like doing a little research on something I just learned about. It's usually no more than 90 minutes of total time.\n[00:03:40] **Ryan MacLean:** That's amazing to me. I'm pulling out the soapbox here just a little bit. 'cause I feel like this to me is like, when I used to play video games, I would sit for, I don't know, it felt like 18 to 20 hours at a time. These days I might have 10 minutes for a video game. And the term for that is called game snacking.\nAnd this feels to me like code snacking or dev snacking. I don't need to pin a term on it, but it does [00:04:00] feel like a different way of coding that feels it. It scratches that same itch but in a much shorter timeframe. And it feels can come back to it a lot easier than I used to be able to.\n[00:04:08] **Jason Hand:** It does. And that itch is oh, I wonder if I can solve that problem that I now have. Yeah. And here's another problem I have, I like to go stand up paddle boarding. And there's a ton of really great bodies of water around for me to go, when I can. But the weather is like the main thing that depends on if it's good conditions.\nYou don't want it to be windy. Depending on if you're planning on being in the water's too cold. There's just stuff that you wanna know about. So I tried to build a little app that uses open , meteorological data that's out there and do that.\nAnd it was just like that was a problem I was trying to solve in that moment. I wanted to go paddle boarding. I wasn't sure where I wanted to go and because I've done this enough times to know that I've got 90 minutes to spare, right? Lemme just see if I can solve this. In a fun way and learn something along the way.\nAnd usually what happens is if it doesn't work, it's just a toss out, I just toss it back. \n[00:04:56] **Ryan MacLean:** Throwaway code, yeah. Whatever. \n[00:04:57] **Jason Hand:** Yep. And I learned, definitely learned something in [00:05:00] that time. And then, but if it turns out to be good or something's, I want to continue on this and I have the time to continue on it, whether it's immediately or later, I can then drop it into Cursor is what I've been doing Right.\nSo that's just turned into my workflow lately. Just get a bunch of ideas going and then ones that actually have some legs, I take 'em to the next level.\nOr lately sharing them a little bit more with some others and just trying to get some feedback. \n[00:05:25] **Ryan MacLean:** Yeah. Yeah. So is your spitball approach primarily Lovable or Claude free? Is that, those are your tools that you start with. \n[00:05:31] **Jason Hand:** Yeah, right now it's Claude's probably my go-to where I reach first to just get that like I said, notepad type of thing, get something going.\nBut Lovable has been like, I would say. Definitely number two, but the thing that's fun about that there's this term that I had to look up because when I started trying to figure out what I wanted to build here, I knew that I didn't want to have a real big architecture. I don't want like a backend like database and yeah. Cloud [00:06:00] storage, I didn't really want that's not how much, how obsessed I am about solving my own problems.\nAnd also, I don't know, lately I'm just so fed up with being tracked by all of the different tracking. I. \n[00:06:12] **Ryan MacLean:** I don't think you're alone. I'm seeing a renewed interest in, in, not using Facebook and not using a lot of the social media apps, but trying to figure out what we can get it done on your own.\n[00:06:21] **Jason Hand:** Yeah. It just really, it bums me out every time I see. So a cool new tool that I, I want to go try and it, you have to sign in with an email address, right? And create profile and stuff. And I was like. You don't always need that. That's not always the functionality that you have to have just to get the job done.\nAnd that's what I was trying to do here with this app is like I was saying it's summertime and there's things to do and people to see and I wanted to create something like, it's a calendar. Oh, this is cool, that thank you. That allows me to choose days that I'm gonna be, am I going to see the bear naked lady?\nI know that man. Yeah. Maybe I'll say I am gonna see that. And the reason why it New Red Rocks is there, is I've got these custom calendars that I Oh, cool. Hold it to display so we can put the Red Rocks [00:07:00] calendars in there. The main ones I'm actually the most interested in is all the bluegrass festivals that happen in Colorado.\nThis will show those, and if I say I'm gonna be at this yes, I'm attending that and that, and then done. And I would go through and just make all my selections right. And actually I'm logged (in air quotes). As you in this, okay, so I just sat here and said I don't want to have this profile thing and user set up, but there is that kind of functionality.\nIt turns out you can do that in the URL. Gotcha. And I think we've known that, or I've known that forever, but I've never really set out to build something that operates that way. \n[00:07:31] **Ryan MacLean:** Yeah. I'm only in there using UTM codes and things like that so what else can you put in that? 'cause I love playing with UTM codes.\nSomebody will send me a link and I'll change the referral or what have you, just to play around and see what they're doing. \n[00:07:41] **Jason Hand:** Yeah, there's, you're basically so what's weird is here I'll actually finish making my selections here. When you. Make all your selections and then you go into the results.\nWe can see all the days where, it's a good, it's a good day for you and I to get together. Both of us are available on June [00:08:00] 5th. And so I can then say, come in here and say let's get together for, dinner or something. And then hit create invite and that's gonna create a Google invite that you can put in your calendar.\nBut the real like way to share this around and get me and you to put on in our own stuff is you have to hit down on the calendar. And I'm gonna move this to where it's displayed everywhere. You just hit share. Okay. And this huge, so if I hit that, this huge pull up the notepad here.\nLink. Oh, wow. Is what gets generated. Okay. So I don't know if you can see that, \n[00:08:33] **Ryan MacLean:** but I can Yeah. \n[00:08:34] **Jason Hand:** Make it a little bigger. So that's the URL, right? With all this encoded. Oh, I see what's \n[00:08:39] **Ryan MacLean:** going. So it's saying true for certain dates. I can parse this a bit. \n[00:08:42] **Jason Hand:** Yeah. encoded. So there's users, there's user Id name, there's Jason, and the dates that I've selected, it's not exactly human readable, but this is like the temporary database that we're basically handing back and forth.\nAnd building on, if like I, I make some changes, I need to then create a new link and pass it [00:09:00] back to you, and that'll be up to date. And then if you make some changes, you'll have to pass it back to me. But we can bookmark these and save 'em, turn 'em into hyperlinks to actually create state almost.\nYou know what I mean? Like I could say my, what I, my selections last week were this URL, but my selections this week are this URL. So you can create like a re like a history, if you wanted. Great. Anyway, it just really got me thinking about all the ways that you could use this type of data storage.\nAnd so this has been the app that I've been working on the most since we last got together. But then I put together this other one, which is related, but I did it on Lovable. You'll see that. I see that. Yeah. \n[00:09:35] **Ryan MacLean:** Yeah. But it looks the same. \n[00:09:37] **Jason Hand:** It I made it look the same. Okay. I told it like, let's use the styling even though it's over unLovable.\nAnd one day I'll probably give it a real domain, but. Yeah. One of the other challenges, yeah, I think for me and my friend groups, and again, probably literally everybody, is when you're going doing fun stuff, sometimes you get together and you all chip in on expenses and you're trying to figure out later like how to split costs, or maybe you have a big dinner date and there's [00:10:00] 10 of you.\nSplitting costs is just always a headache. So I, that was something else I wanted to, solve for Oh, I like that. APIs and IPAs. Yeah. Perfect. And then of course there's, I'm not gonna put my Vimo in, but there, if I did, you could then send me stuff. But there's tools. There's like SplitWise that could handle this.\nThere's Doodle.com which can handle like the calendar stuff, but again, I don't want to go log in and give them all my. Email information. Yeah, I think we were looking \n[00:10:28] **Ryan MacLean:** at Doodle the other day. It's changed hands a few times, so I worry about where that data's being used. Yeah. Is my thing. And then people in the US use, is it Cash App or Venmo that I think are splitting stuff.\nBut then as a Canadian, I don't use either of those. So this is, yeah, it's constantly a concern for me. \n[00:10:41] **Jason Hand:** Exactly. And now I'm gonna put this up. Already in, in GitHub, and so go. Just deploy this somewhere yourself, and you don't have to use those tools. \n[00:10:51] **Ryan MacLean:** Oh, that's \n[00:10:51] **Jason Hand:** cool. So anyway I was just kinda like making up numbers here, but put you in here and put myself in here.\nYou can also change the colors pretty much anything that you wanna change can be stored in the [00:11:00] URL and it's pretty fun. So yeah, I owe you $10.50 and we could say maybe there's one other person, maybe Rick was gonna join us or something. And then, so we're gonna actually split that three ways now.\nSo there's three people for two expenses. Now Rick just owes you 22 and me, Jason, or me a dollar. Gotcha. So if we \n[00:11:22] **Ryan MacLean:** had supper two nights in a row and I paid one night, you paid the other night kind of thing, this would definitely solve that. Yeah, exactly. And then if Rick came along for both and didn't pay anything sort of thing.\n[00:11:31] **Jason Hand:** Yeah. If as long, assuming you like, just waited till the end to tally it all up. You just put in your stuff. And again, you can share this around, like I put in my amount and then I'll like text it to you and you put in your amount. Anyway, I just got, I told you the other day in chat I've become obsessed with trying to find other little apps.\nI can make that, that do this, but. DASH is upon us in that, but \n[00:11:51] **Ryan MacLean:** yeah, our internal event is taking up a lot of time. I do wonder though, have you tried making these apps in multiple places or do you typically just use because you're using two different types here. I guess I [00:12:00] wondering about the rubric or how you, what that thought process is.\nOr is it just you reach for the one that's closer and try it out and Yeah. And see how far you can go? \n[00:12:07] **Jason Hand:** I guess I was saying I usually start with. A Claude, right? But one thing that I did realize in this most recent session with Lovable, with this the Split Something app is, lemme get in here to, oh, it's down here.\nPlease forget that they're right down here. \n[00:12:23] **Ryan MacLean:** A paddle weather whisperer. I like these names. I can figure out what it's trying to do. Yeah, we can come back to \n[00:12:27] **Jason Hand:** that one. \n[00:12:27] **Ryan MacLean:** The self weather tracker. \n[00:12:30] **Jason Hand:** So the deal with this is, I told you that I started in Lovable, but you only get five wishes, so you can only do thing five times and then, but one of the neat things, I guess it's neat for me, at least in this situation, is that you can push it up into GitHub okay?\nAnd just create a new repo. From right here. So I like that idea. 'cause if it's a, if I like where this is headed I do want to get it into GitHub pretty soon because from there I'm going to probably play with it in multiple places. So I hadn't really taken advantage of [00:13:00] that intentionally until now.\nAnd as you can see over here on the left, once I put it up into GitHub, I then pulled it up into Cursor, started doing things over there and it. Automatically all I was doing was just making some read changes to the README initially, but it automatically noticed the changes in the repo. \n[00:13:18] **Ryan MacLean:** That's cool.\n[00:13:19] **Jason Hand:** And I could then review the changes over here and see it. And then another thing observation here about this whole process is just because, I guess now I have a better understanding of how Lovable works. It's not going to just redeploy the app. Now that it's in GitHub and you've pushed code back in, there isn't some sort of automation, continuous, like CI/CD build.\nThat just happens, right? Then you still gotta come back into Lovable and then there'll be a, an option up there to, I think it's, I don't think it's Publish and it's like redeploy or re- something \n[00:13:51] **Ryan MacLean:** Refresh or something like that. Yeah. Okay. \n[00:13:52] **Jason Hand:** Exactly. 'cause no, it sees that the code has changed and at that point now it's deployed obviously onto Lovable infrastructure and the app and everything [00:14:00] will work through the URL, that's been the process for these few is I'll start in the cheap sections or, in the, in the free stuff if I like where it's headed, let's get it into GitHub. And then from there I usually bring it down into Cursor and if things are really not going the direction I want them to, I get out Claude Code and because it Gotcha.\nIt just seems to like. Read my mind and do exactly what I'm, I need it to, but I try not to always default to that. Like I, I like. Understanding all of them. \n[00:14:30] **Ryan MacLean:** Yeah. This feels like a rapid application development framework of some sort. Even though it, on your end, it might feel like you're cooking spaghetti and throwing it at the wall.\nIt's the fact that you can try different ideas this quickly and iterate that fast, even if you have to go to GitHub and then refresh a page. To me is a benefit because as someone who doesn't do front end, this would be me asking a team to do something, waiting a week or two, and then seeing what they come back with only to realize my actual architecture was wrong or the premise that I had come up with wrong or the [00:15:00] framework I was using or wrong that the idea was wrong.\nThere's something fundamentally wrong with my idea. Yeah. Not with their code, but like with the instructions I've given them \n[00:15:08] **Jason Hand:** and some of them like have been. They just they exposed to me how complex this might be. And I have to decide, do I want to go that right way? This sounds fun, but like I need to stay in this quick ideas, like just what are the little things that have been bugging me that I can just solve, and let's move on.\nI'll save the complex ones for later when things have, evolved. And also I've run out of small problems. Okay. But at least I got 'em documented and I can come back to 'em. \n[00:15:41] **Ryan MacLean:** The other thing that sticks out to me is in a pre gen AI world, and let's say it's 2019 or maybe 2018. For me at least I might write the ideas down, but I definitely would not have done anything.\nSo I'd have a list of 20 ideas, maybe 30 at the end of a couple weeks of working [00:16:00] on something. And chances are I may have spitballed on one of them, maybe two. If that though, to be fair, \n[00:16:06] **Jason Hand:** yeah. I have to yeah. Acknowledge the privilege that I have to sit Yeah, exactly. Sit outside on my front porch and just drink coffee and, ideate and read and learn and build and then start my day kinda off like that way. And then I, and then I take. \n[00:16:20] **Ryan MacLean:** Yeah. The promise of remote work was on the beach with your, Mai Tai, what have you. Oh, that, stuff like I, listen I worked remote and that still wasn't a reality for me.\nThere was still stuff that you I needed a bit more access. This does feel like a. I don't wanna say lone wolf, but something that you can do solo pretty easily without too much interaction, and then go back to a team and say, Hey I played around with this on the weekend. It looks like there's a new feature in Astro version five called, I don't know, component collections or, so something like that.\nI forget what they're called, but some collections that we can use as a result. Let's try that. Here's an example. Let's not use this, but here's an example that I got with Lovable or Bolt or Claude or what have you. That to me is [00:17:00] incredibly valuable because again, as someone who doesn't do a lot of front end it, it's amazing for me to be able to try that stuff out.\nSo I, I think what I was looking for is some sort of other methodologies so you're saying five tries is generally when you'll stop you'll try a different tool. It's not time-based. It's more about what can you get done for free with a couple iterations or up to five iterations.\nThen you'll pick up either Claude Code or if it's really serious Cursor is what it sounds like, and then you'll work from there and get. Like a human in the loop and another person to give you your feedback and then settle the features. Does that encompass? Yeah, \n[00:17:29] **Jason Hand:** and you know what?\nNow that you say that out loud, \n[00:17:34] **Ryan MacLean:** sorry to rationalize it, but this sounds awesome. I just need friends, I think is the only thing. So what I, \n[00:17:38] **Jason Hand:** what but what it is, basically what I'm doing is like exactly what I do with like songwriting. Oh yeah. Is gotta, when the. Look, we're not always in the right head space for things.\nAnd so when you are, you gotta jump on it. And that's that's what I'm, that's what those 90 minutes or whatever, it's, yeah, it changes, but that's what that is for me. It's collection, it's creation and collection time. And I've figured out I can use that [00:18:00] as like just getting ideas to bubble up.\nAnd then use the time that I have to see if I can make some sort of progress. And it's just a phased approach, like you have, I have. A hundred ideas. I get 'em down to five. Yeah. From there I get 'em down to two and then we go, do, we do the next thing. And that the fact that we can all do that now.\nYeah. The. There's gonna be a lot of people solving their problems, which I think is awesome. Which \n[00:18:24] **Ryan MacLean:** brings me to my next question. This is ma may I've got a solution, but I dunno what you're doing, but my brain feels like it's a squirrel and I'll look the other way and something grabs my attention all the time, especially now that we're, ramping up to an internal conference.\nI've got a little bit less time than usual. I'm babysitting some dogs, my own dogs, let's be honest. But if they got any health problems or something like that, I might be dealing with them for a second, then come back to the computer and traditionally like that. And one two minute change of not looking at something would mean when I came back it would take me about 15 minutes to ramp up to what I was like, maybe not that bad, maybe about five minutes.\nThese days though, it feels like I can just type continue and [00:19:00] continue on. That being said, there's sometimes when I change tools that I really miss not having that context from whatever chat session I had. Sometimes I'll copy that out and do I might say the prompt or the system prompt or what have you.\nA-P-R-D-I think we talked about before. I've been using todos a lot these days, but how are you keeping that context between maybe different days or if you're handing off to a different person or a different tool? What does that look like for you? Because todo is my answer and I, I don't think it's the best, but that's all I've got right now.\n[00:19:27] **Jason Hand:** Yeah. I think for these, I don't believe I'm using. To do. Let me, \n[00:19:34] **Ryan MacLean:** And for those listening, I'm literally just talking about like a todo markdown file with check boxes in it. This is as sophisticated as I've gotten at this point in time. \n[00:19:42] **Jason Hand:** I've got a Claude file.\nOkay. Okay. Like a CLAUDE.md, because it had, I did bring it into Claude Code at some point. \n[00:19:49] **Ryan MacLean:** Okay. And does Claude Code do that by default? Having only played with it once? I didn't notice.\n[00:19:53] **Jason Hand:** It's a good question. I don't remember if I act, if I prompted it to make this. Okay. I think it created, its on its own 'cause there's not a [00:20:00] lot here.\nInteresting. I wanna say it probably, yeah I don't know if I remember exactly when that was created, but that's all I've gotten. Really in here, I do have a roadmap file that I like started that was gonna be like my to-do. \n[00:20:14] **Ryan MacLean:** That's a good one. Yeah. When you're thinking down the road for other features or what have you.\nOkay. \n[00:20:18] **Jason Hand:** Yeah. And actually I did that, like the first version of it is here.\nI do have, like I said, there, there's a CLAUDE.md file in here, but it's really small. I think it was created automatically. I don't remember asking it to do that. But my roadmap file is like my similar to, to do but really meant to be like feature requests. So the first version I had of this, I sent out to some folks.\nThey came back and told me, it'd be great if I could send it out to multiple groups of people and keep that somehow still straight. Like some are my like music friends and some are family and like, how do I like visually see that? At first I was like, I dunno if I can do that without having some sort of backend like state management.\nAnd then the same with also getting granular down to the [00:21:00] time, like what specific time, not just what day. Yeah. But the more I was like thinking about it, I was like, I think it, it's just another. It's just another number, just another like variable to be stored in the URL. I don't know why we can't do that.\nSo I can actually check this off. I did that. And that's pretty much all I've done so far. I haven't gotten probably more than four hours total time into this. \n[00:21:23] **Ryan MacLean:** That's pretty good too. If you think about the actual amount of work that you've done versus the output that's. Yeah, that's actually pretty incredible.\nI \n[00:21:29] **Jason Hand:** was really impressed with the you know what, I might actually be able to pull up the first one. It gave me the zero shot. Let's see. You can see all the stuff. Colorado su standup paddleboard location app. Oh I made a little wordle game. A bluegrass themed Wordle. You like \n[00:21:52] **Ryan MacLean:** Wordle? That's amazing.\nI do, in fact, like Wordle I'm enamored in with the fact that you can resume your state by just opening the same [00:22:00] URL again. Yeah. I think is what I really likem. \n[00:22:02] **Jason Hand:** I've got a really nice what do you call it, telescope, like deep space telescope. Not deep space, but like a good telescope. Yeah. Yeah. And I wanted to see if I could.\nFigure, find something, build something that helped me, choose which day and time I should go. Go look at stuff. Didn't make very far on that one.\n[00:22:18] **Ryan MacLean:** I'm loving this list of ideas, like each one. So each session is a new idea. I guess one of my problems with Claude is that my brain is just all over the place, so I'll end up putting three or four ideas into the same thing and then it gets confused halfway through it.\nWe'll change my weather app into a translation app just 'cause of the way that I started talking to it. So I've gotta be careful to split that stuff out. But it looks like you've you've already learned that. \n[00:22:38] **Jason Hand:** Yeah. It is a good way to compartmentalize things. And you know me to go back, I completely forgot if the word wordle thing, and yeah, so that's another one. And it's actually, it works. So I gotta go back and kinda tinker with that. Very cool. But this was the first conversation I had. So let's see, make this a little bigger. Wanna build a web app to help me find dates where multiple people are available on the same day, [00:23:00] like doodle.com, but only the date, not the time is important.\nWant users to see a counter view, select all the dates and. States blocked. The app will then show all the best options for dates where the most people are available. \n[00:23:12] **Ryan MacLean:** I gotta say, this is the worst project definition I've ever seen. This is a Jira ticket. You know what I mean? This is one of those ones where you're like, ah, it's that project manager.\nLike really? \n[00:23:23] **Jason Hand:** Sometimes an idea is just, but that is \n[00:23:24] **Ryan MacLean:** fantastic. The fact that you can run with that and just a, like a natural human language way of speaking to a an engineer is phenomenal, right? You don't like, I need it done by Wednesday. It's a large t-shirt size. I, I realize you're also busy on these other things, but this is a priority two.\nSo please prioritize it. Okay. Appropriately. This is fantastic. It removes all that headache of overhead of dealing with an engineering team. At the same time, you can do this while doing other things like drinking your coffee. This phenomenal to me. \n[00:23:52] **Jason Hand:** It just \n[00:23:53] **Ryan MacLean:** helps me \n[00:23:53] **Jason Hand:** get some ideas, \n[00:23:54] **Ryan MacLean:** Even this first iteration that you're showing me here, I guess it says V two, but this looks pretty good.\n[00:23:59] **Jason Hand:** It [00:24:00] does, yeah. Does what it. Is supposed to do that. This \n[00:24:03] **Ryan MacLean:** is a really good rapid application development tool, which a couple \n[00:24:06] **Jason Hand:** things here, and then we look at the results and yeah, that's all three people are available. That's phenomenal. So that's what it got like on shot one. \n[00:24:14] **Ryan MacLean:** Yeah.\nOr zero. This is great. The way that it can create React apps that are just in a sidebar and Claude I, I think is fantastic. Be it in, in, in web or desktop or even the iOS app. I've noticed is, it's actually pretty neat to me just to visualize the idea that I hadn't realized, oh, no, that's actually.\nYou know what, why would you do that? Like you, you don't need the times of the day. Actually what I need is the date. And then realizing that's your feature set and going back to the well to get more, that, that's fantastic. I think the key is that you can get that result out there quickly and then iterate the problem with me.\nI guess I. Past me prior to 2022 would be that I just wouldn't get started. 'cause it was so hard to get started. Yeah. And now it's no, I can get started on five or six different things and then pick the best out of them instead of just sitting there worried about how much time this [00:25:00] gonna take and not doing anything or over planning.\nThat is really cool. I. \n[00:25:03] **Jason Hand:** I do not like to waste time. And finally, I feel like I'm not wasting time by just exploring something. There used to be so many different things I'd wanna do with raspberry pies and Oh, don't get me started. I \n[00:25:14] **Ryan MacLean:** got 12. Yeah. Don't get started. Absolutely. And I just, I \n[00:25:16] **Jason Hand:** know that I'll get I don't know, days in and realize this isn't working and.\nAnd I have this like a dread, this like feeling that washes over me. I'm like, that was a waste of time. And I just out like that's time is like the one thing I do not waste.\n[00:25:31] **Ryan MacLean:** That is really cool. Listen I learned a lot from your process. I've been using. Bolt a lot and Claude Desktop and ChatGPT to a lesser extent.\nBut those are the three sort of tools that I use. I will say every time I've used Lovable I get Lovable results. And I hate to say that 'cause it's funny, but it's absolutely true is that I do enjoy my time in that app and it feels if we're still voting with our wallet it's almost time to stop the Bolt subscription and maybe move over to the Lovable.\nIt is where I'm at, but I have paid for Claude and it [00:26:00] wasn't cheap. I do feel like I'm getting my money out of it, and that's. That's not just like Claude sonnet for coding as an API key, but also the actual chat app. I do like it. I do pay for ChatGPT, but I've noticed myself using it less and less primarily because I'm using Claude for coding and I get more value out of coding than I do talking to ChatGPT about random things.\nIt's not my search engine. It doesn't do that yet for me. I don't know if it does for you.\n[00:26:25] **Jason Hand:** Occasionally I'll start there on some things, but yeah, it's not, that's not why I'm the same with you. Like most of the stuff I've been wanting to do lately is solve my own problems. And I don't want to just, yeah.\nI could go use Doodle and I love Doodle. I've used it for years. That's what we've used. It's worked fine. I just wanted to make something else. It's a solvable problem that I can take care of myself now. Yeah. \n[00:26:44] **Ryan MacLean:** That solve your own problems, that citizen developer thing to me is very exciting.\nThat means like the amount of people who can code seems to have increased. I'm bringing down a bar. I think here I'm lowering the bar for more people to start coding because I know it's difficult to say what the total addressable market is for developers out [00:27:00] there, but I do feel like this is.\nIt feels like it's exponentially growing as a result of making these tools more accessible. \n[00:27:06] **Jason Hand:** Yep. More equitable. Just more \n[00:27:08] **Ryan MacLean:** totally agree. \n[00:27:09] **Jason Hand:** Yeah. That's probably about all the time we have to talk today, so that was awesome. \n[00:27:15] **Ryan MacLean:** Yeah. Thank you very much for showing us what you've been up to. \n[00:27:17] **Jason Hand:** Yeah. It's been fun.\nKind of, finding time. Usually, like I said in the morning to, to work on it. 'cause as soon as I close the iPad and go, go up to my office, it's been DASH. \n[00:27:26] **Ryan MacLean:** Yeah, that's what happens this time of year. Yeah, for sure.\n[00:27:28] **Jason Hand:** But I'm DASH is closing is, we're almost here, so a week away.\nOnce, once we get through that, then we can we have a lot of plans we wanna make with the, with this program and what we're doing here, so \n[00:27:37] **Ryan MacLean:** Absolutely. \n[00:27:38] **Jason Hand:** It'd be nice to be able to focus on that. And anyway, thanks Ryan and no thank you. That was awesome. We'll talk to you on the next one.\nAll right. Bye \n[00:27:46] **Ryan MacLean:** folks.","Jason Hand and Ryan MacLean chat and demonstrate practical uses of Claude and Lovable in coming up with and building on ideas very quickly .. daily .. almost as a personal challenge. Jason shares his morning routine of using these tools almost as a \"second brain\" or notebook to capture fleeting ideas that come during his morning coffee time outdoors and how turning to tools like Claude or Lovable feels like using a butterfly net to capture ideas, storing them for later exploration, dissection, or problem-solving. \r\n\r\nThey discuss their tendencies to juggle multiple projects simultaneously and the challenges that accompany keeping track of all those ideas without losing context. They highlight how AI allows them to quickly kickstart projects they might otherwise only conceptualize in traditional notepads or task managers. \r\n\r\nJason details his personal approach of using free plans on Claude.ai and Lovable.dev, strategically working within usage limits as a daily challenge. This habit not only sparks creativity and idea capturing mechanism, but also aids him in solving real-life problems through simple applications he has built like [**\"See Ya There\"**](https://seeyathere.netlify.app/) and [**\"Split Sumthin\"**](https://color-coded-budget-buddy.lovable.app/) to help organize friend gatherings at bluegrass festivals or to split expenses with others, but without the hassle of logging into or registering for a service with his Gmail account. These problems shouldn't require a user to give up their personal information to solve a problem. \r\n\r\nJason also points out how such accessible tools reduce initial complexity barriers, allowing him to rapidly prototype solutions that he can later refine or abandon based on effectiveness—thus paralleling themes familiar in songwriting processes where ideas are synthesized before being fleshed out.","src/content/episodes/ep31.mdx","37624da81d15fed6","ep31.mdx","ep32",{"id":2260,"data":2262,"body":2327,"filePath":2329,"digest":2330,"legacyId":2331,"deferredRender":104},{"title":2263,"description":2264,"heroImg":2265,"videoId":2266,"episodeNumber":2267,"date":2268,"author":20,"participants":2269,"tags":2270,"takeaways":2273,"resources":2296,"jumpTo":2310,"summary":2327,"featured":54,"transcriptAvailable":104,"transcriptContent":2328},"Claude Code findings with Rust and TypeScript through Ray Tracing projects","In this candid engineering chat, Datadog developer advocate Scott Gerring walks Jason Hand through his latest experiments with Anthropic's Claude Code assistant. Gerring shows off a ray-traced teapot scene that Claude generated almost entirely on its own.","../images/thumbnails/ep32.png","MD7L1HdCpX0",32,"2025-06-11T18:42:35.000Z",[22,1811],[1814,2271,2272],"typescript","rust",[2274,2278,2281,2286,2291],{"text":2275,"tools":2276},"Generative coding assistants like Claude Code can produce surprisingly correct, compiler-validated architecture when given clear conversational guidance",[295,2277],"Rust",{"text":2279,"tools":2280},"AI tools also invent highly 'creative' bugs—unsafe globals, mutex bottlenecks, missing epsilon offsets—that require domain expertise to detect",[295,2277],{"text":2282,"tools":2283},"For rote tasks (type definitions, data mapping, API clients, refactors) Claude saves hours, especially in TypeScript and Astro projects",[295,2284,2285],"TypeScript","Astro",{"text":2287,"tools":2288},"Complex build or tooling changes (e.g., JavaScript module systems, Rust compiler internals) remain fragile; human review and testing are essential",[2289,2277,2290],"JavaScript","Testing",{"text":2292,"tools":2293},"Multi-modal workflows—hand-written drafts, observability data, shared context stores—hint at a future where AI augments the entire software lifecycle, not just code editing",[2294,2295],"AI Development","Workflow Tools",[2297,2299,2303,2306],{"name":295,"url":1161,"description":2298,"featured":54},"Anthropic's AI coding assistant",{"name":2300,"url":2301,"description":2302,"featured":54},"Datadog DevHub","https://devhub.datadoghq.com","Integration and extensibility hub for Datadog platform",{"name":2304,"url":1570,"description":2305,"featured":54},"Astro static-site framework","Modern static site builder for fast websites",{"name":2307,"url":2308,"description":2309,"featured":54},"Supernote e-ink writing tablets","https://www.supernote.com","Digital writing tablets for handwritten notes",[2311,2314,2317,2320,2323],{"title":2312,"url":2313,"timestamp":70},"Intro & recap of previous experiments","https://youtu.be/MD7L1HdCpX0?t=0",{"title":2315,"url":2316,"timestamp":897},"Ray-traced teapots generated by Claude Code","https://youtu.be/MD7L1HdCpX0?t=60",{"title":2318,"url":2319,"timestamp":642},"Creative bugs – static globals & unsafe Rust","https://youtu.be/MD7L1HdCpX0?t=420",{"title":2321,"url":2322,"timestamp":656},"DevHub ETL, Astro, and Claude's TypeScript wins","https://youtu.be/MD7L1HdCpX0?t=960",{"title":2324,"url":2325,"timestamp":2326},"Lessons learned, handwriting workflows & wrap-up","https://youtu.be/MD7L1HdCpX0?t=1680","00:28:00","In this candid engineering chat, Datadog developer advocate Scott Gerring walks Jason Hand through his latest experiments with Anthropic's Claude Code assistant. Gerring shows off a ray-traced teapot scene that Claude generated almost entirely on its own. By conversationally prescribing high-level architecture and letting the model write the Rust, he ended up with clean, compiler-checked interfaces for materials, impressive Lambertian shading and glass refractions, and a working multithreaded renderer—all things that would have sounded like science-fiction two years ago. Yet the demo also exposes Claude's more comedic failure modes: a 'random' axis picker implemented as a global static counter wrapped in an unsafe block, a crippling global mutex that turns a progress bar into a five-times performance penalty, and subtle rendering artifacts caused by omitting the classic ray-origin epsilon offset. Beyond graphics, Gerring describes using Claude Code as a pragmatic coding mule. It rapidly scaffolded a TypeScript ETL pipeline that ingests Datadog integration metadata into the new DevHub site powered by Astro, complete with strongly-typed schemas and a bespoke GitHub API client. The assistant excelled at mechanical mapping and refactoring chores that normally burn hours of human focus, but it stumbled when asked to wire up Jest unit-tests—introducing brittle module-system changes that broke the entire build. At the bleeding edge, Claude still falters on Rust compiler internals for architectural linting, reminding us that engineers must recognise success criteria and domain pitfalls before blindly shipping AI-generated code. The pair close by musing about shared organisational context windows, multi-modal workflows like handwriting drafts on a Supernote then piping PDFs through Claude for flawless transcription, and the exciting potential of Datadog's new MCP for autonomous incident remediation. The through-line: lean on generative AI for the repetitive drudgery, but keep seasoned intuition—plus good observability—at the helm.","[00:00:00] **Jason Hand:** I heard you've you've been doing a little bit more with some of the stuff we talked about.\n[00:00:04] **Scott Gerring:** I think, the main thing we talked about last was I.\nKind of my fancy terminal stuff. It's not that fancy really, but I think lots of people who haven't spent much time in the terminal before are probably quite interested in that. And then Claude Code was the thing that I was using that was novel in there. But as part of that whole thing, the whole thing, I've been building with Claude and using the terminal and thinking about programming and generative AI and whatnot.\nA lot recently, probably like everyone who's programming, I would say I have some observations and some other things and bits of code that went well and bits of code that didn't go well and so on that are probably interesting to look at. I think, \n[00:00:39] **Jason Hand:** maybe you can pull up your screen here and show us the next level of understanding that you've come to with a lot of these things.\n[00:00:47] **Scott Gerring:** Yeah . I'll show you my teapots first really quickly because as I say, still very into the teapots. I'll just quickly switch desktops here for a second. This is the output that we're getting out of this thing that I've built with a ray [00:01:00] tracer. With code, it looks about right. It's very noisy because that's what, ray trace renders look like when you don't run them for ages, and I don't have days and days to wait for my shiny teapots, but it's it's roughly okay.\nAnd I the whole thing I did with it was, Hey, Claude Code, go and build this thing. And I gave it advice about how to build it based on my knowledge of how to build these things. So I was very prescriptive with it, but only conversationally, and I left the code completely alone. Until it got to the point where I had my shiny teapots and then I went and had a bit of a poke around to see what fun things I could find.\nAnd there's a mix of stuff that went really well. I think, obviously the teapots came out the end, which is effectively magic. I think if you, if. I told someone two years ago, a computer program could write other computer programs for you and they'd be pretty decent. They'd be very surprised about that and stuff.\nThat's like pretty horrible and gross, but like discoverable and fixable, I would say. \n[00:01:50] **Jason Hand:** Yeah. I, another thing too, you, it took what we talked about in the recording and then you did a brown bag for our team internally and everybody loved it. And [00:02:00] you had made a comment or there was a section in your presentation about just the grossness of the code and \n[00:02:05] **Scott Gerring:** Yeah, I get strange, I said like strange guttural reactions to things sometimes, but it's, I think it's the creativity of some of the failure modes I guess.\nBut it was also really interesting, the bag, I thought, because obviously our colleague Rory. Also did half the brown bag and he was also talking about generative ai. And we basically we built two completely different things. Like I built this ray racer and he built a system for auditing Kubernetes control plan actions, as I recall.\n[00:02:32] **Jason Hand:** And. \n[00:02:33] **Scott Gerring:** The domain was very different, but the conclusions at the end were very similar about when you can use it effectively when you can't. And I thought that was really interesting. And it comes back to what you were saying about the community call. Lots of people are playing with this stuff and everyone ends up with the same Yeah, very similar opinions about it.\n[00:02:47] **Jason Hand:** Exactly. It feels to me like we've all, we're all taking our time and taking turns, like entering this new mysterious world that we don't really understand, everything around and we're all just reaching for the edges, reaching [00:03:00] for the walls. What, how far can I go before like I'm in danger?\nOr how far can I go before this is not useful? You know what I mean? We're just all like very carefully exploring and then turning that around and being like, Hey, here's what I found out. \n[00:03:14] **Scott Gerring:** Pass it on. Yeah, exactly. And I think that's also the way to do it with new tools. Like you want to crash at high speed into the boundaries rather than like incrementally working out from what's safe and reasonable.\nBut yeah. Anyway, let me show you some code. Yeah. And I'll start with the positive stuff because I was very skeptical about the whole generative AI coding assistant thing to start with. I think lots of programmers have been doing it for a while. Work. But it does a lot of stuff really well, so I think it's important to focus on that rather than just getting the boot in immediately.\n[00:03:43] **Jason Hand:** Agreed. \n[00:03:44] **Scott Gerring:** This is a bit of the Ray tracer and I don't need you or everyone listening to understand what's going on too much, but the important part is that it's an interface. So it's an interface that represents [00:04:00] some material in your Ray tracer. That can reflect light, which means anything that you render, like you have a shiny piece of metal or you have some diffuse surface, it can reflect light.\nAnd this interface describes how that material reflects light. And it's really good because it's correct, right? Like it looks exactly like what you would expect this interface to look like if you go on Google, the myriad of rate racing tutorials on the internet. And the cool upshot of that is that because it's an interface and all the different materials that Claude Code went and built for me in my little toy ray tracer.\nInherit or implement this interface, they're all forced to look roughly correct. And I think because it's this compiler check thing where it gets the interface right, and then it goes and builds a bunch of code that has to force that shape. It really helps it get the materials right as well. So it's like relying on the compiler to do the compiler's job, to push it in the right direction.\nSo it starts from something that's pretty correct and then it extends out from there. So this doesn't really tell you much more, but this is a concrete example of that this is a lambertian material, which just means like a [00:05:00] diffuse surface saying it's not very reflective and it's shaped again, pretty much like what you would expect.\nBut I think because the foundational interface was right and the code follows from that. So I looked at this and I was like, oh, hey, this is exactly what I've written, would've written myself. Great job. \n[00:05:16] **Jason Hand:** Now when you say it's right, is that what you mean? It's what you would have done? Or is there objectively a right and wrong way of doing this that you can write tests around?\n[00:05:27] **Scott Gerring:** It's probably a little bit more nuanced than I made it sound. There's lots of different ways you can build Ray races, and I'm by no means an expert, right? Like I'm a hobbyist with an enthusiasm for these things. But if you go and do like a mid-tier path tracing sort of thing, you would end up with something that is very similar to this.\nSo there's not really an objective truth, but you would expect an evaluator sample and a PDF function on it, and you would expect roughly these parameters. There are variants, but it's insofar as you could be objectively right with this is. [00:06:00] So I think this is really cool. Like it's spot on.\nYou look at it, you're like, nice one. If anyone who is listening knows more about Ray Races than me and would like to tell me about subtle nuance in this please let me know because I'm always interested in letting you might be the expert, very much doubt that. But yeah, I mean that there are cool toy problem.\nCool. And there was another one of this. It's the same sort of thing. So this is for a material, it tells you how light scatters when it hits it. It's pretty similar again. And it has the same nice property where things that extend this are forced into the correct shape by virtue of it. Having got a decent interface out\nnow for the funnel ones or the ones that I think are funnel some stuff that didn't go so well. And we'll start off with this, which I have called Static Globals. And I need to explain this 'cause I think it's very creative. It's a function that's meant to pick a random axis. So X, Y, or Z, which means a random number between zero and two.\nAnd [00:07:00] generating random numbers in rust is not a hard thing to do. This isn't something that you need to have elaborate work around for, but what it's done, instead of generating a random number and you can see in its comment that it thinks maybe it should actually generate a random number, is create a global mutable static counter.\nAnd then bump it whenever somebody calls the function from any thread and return the next value. So by virtue of lots of threads calling this thing at once, it's gonna look random, but it's just an incrementing, rotating counter. And this is really funny because, if you got a graduate programmer or someone, somebody who would just started programming and said, go and build me this, there's no way that would come up with something like this.\nIt's creative in its horror. So I saw it and I was like, wow, this is really something new.\n[00:07:46] **Jason Hand:** I liken the comment that it says we'd normally use a proper random number generator, but Yeah. And then it goes on to write seven lines of code. \n[00:07:55] **Scott Gerring:** Yeah. And I really wish I had the chat history from it because I think it would've been one of those ones where it [00:08:00] reflects, like it, it would've tried to use it and it got the wrong package or something, and it was like, that doesn't seem to work time to do it this way instead.\nBut unfortunately, let's three \n[00:08:09] **Jason Hand:** force our random. \n[00:08:11] **Scott Gerring:** Yeah, and the fact that it's had to wrap this in an unsafe block is also deeply funny. This is not normally something you would see in ordinary rust code, \n[00:08:19] **Jason Hand:** Okay. Let's actually talk about that for a second. If you caught that you look at that and like almost throw up in your mouth, right?\nI don't know that I would honestly, I don't know rust well enough to spot, but I wouldn't be working in Rust. I know the dangers of being in a language that I don't understand what the gen AI's created. But let's pretend. Somebody has created something and it slipped through.\nWhat what does that set off in your mind, like alarms? \n[00:08:41] **Scott Gerring:** So in this case it's harmless. Because it ends up, I, randomness is one of those things where people take it very seriously, that something's truly random and whatnot. This is absolutely not truly random, but for the purposes of just random of picking an axis.\nAnd the axis should change a lot and look roughly random this would [00:09:00] work. But if you ran, there'll be some rust static analysis tools. You could run over rust programs to look for things that are unpleasant and most of them would fire off on the use of unsafe blocks like that. There is a massive code smell, but functionally, I don't think it's that terrible.\nIt's gonna kind of work, it's just creative and it's. Horribleness, \n[00:09:21] **Jason Hand:** maybe not the most efficient use of code. A senior person's gonna come in looking for ways to reduce lines of code.\n[00:09:27] **Scott Gerring:** Yeah. And they're also gonna be like, what were you thinking with this? I wasn't vibe that was bad for \n[00:09:35] **Jason Hand:** me.\n[00:09:35] **Scott Gerring:** It's just that it's so creative, to do it this way, it's not something that a human would really consider, I think. And I wonder if. It would be really interesting to see what caused it to not use the random number generated. 'cause there would absolutely be something like it. It tried to use it and it didn't work for Yeah.\nSome reason it's not obvious to me. And then it did this instead. \n[00:09:54] **Jason Hand:** That's an interesting point. It has caused us, you mostly now me, to pause [00:10:00] and think about the creativity of its response, and oh. You can, we can solve this problem in multiple ways. I guess we've always known that, but this is a different way.\nI've never seen, and I think at some level that has to unlock something in a person where they're like, whoa, yeah, I didn't know you could do that. Or I never thought to do it that way. You know what I mean? Like I'd live off those little mortals of, oh my God, I didn't know you do that, that it's it just keeps me moving forward.\nEven though you would never want to code like this, I think it's still a little bit of a learning revelation thing of we're just scratching the surface on stuff. \n[00:10:39] **Scott Gerring:** I absolutely, and I think it's very interesting, like it, it really makes me wonder how it's come to it, like what it's saying in the trading set or what error it encountered when it tried to do it with a random number generator that led to this.\nWhat you would expect to come outta the brain of an ordinary human programmer, which is why it really, it's really [00:11:00] jarring. But yeah I have another one that's, but would you call it \n[00:11:04] **Jason Hand:** slop? Because I think that's where that term comes \n[00:11:06] **Scott Gerring:** in. It's absolutely slop. Yeah. Okay. Because \n[00:11:09] **Jason Hand:** we look at images and video and it's just it gives you that WTF feeling where you're like, Ugh, what is this?\nYeah. That's the point of those things. At least the ones that end up on social media. This is not by design to be slop. It's just slop. And, but also it's creative, and I guess if you look at it through a squint through like an artist's view, it's creative. What are you gonna say?\n[00:11:33] **Scott Gerring:** Yeah. There's almost an aesthetic judgment in there, like I, you asked me if it was gonna work and I was like, yeah, it probably would, but it's disgusting. And that's me saying, I don't think this is good code. Based on prior exposure, but if it's gonna work, even if it's not truly random. \n[00:11:51] **Jason Hand:** Yeah.\n[00:11:52] **Scott Gerring:** Anyway, this one is interesting. In a similar way. It's also gross, but I think I can [00:12:00] explain how it's ended up at this and it's not enough to just see the snippet, to know what's going on, but basically in the Ray tracer, it built me this little progress bar on the bottom, so you, it is like a command line tool.\nYou run it. A little, a hash progress bar ticks across until it's done. And because they take hours to render, typically this is helpful to know that it's not just frozen. And I saw that and I was like, oh, that's cool. That's I like terminal stuff obviously, and this is really nice. It's great.\nAnd then while it was rendering the first time I cracked open my system monitoring stuff and I saw that it was spending like 95% of its time in the kernel. You can see like the split between user CPU time and Kernel CPU time. \nAnd the thing with normal ray traces is that they don't need to do anything with the outside world.\nThey just sit there in user space and do maths a lot until they're finished. They don't need to open file sockets, they don't need to use mu taxes, they don't need to load websites. So if you see that it's spending all this time going in and outta the kernel, then it's doing something that it shouldn't.\nYeah. So I saw that and the thing worked right? Like it [00:13:00] absolutely worked. It was just slow. But because Ray traces are also slow, it didn't really trigger me until I saw this CPU time split. So I saw that and I thought something terrible is happening in here and I wanna know what it is.\nAnd I dug around a bit and I found this. And the gist of it is that to make this little progress bar thing work, it needs to fan in from all these different worker threads that are doing rendering to one point to update a number that reflects the progress, right? If you have a million pixels in the image, you should bump it by one every pixel, and you can work out what percentage you are done.\nAnd it's done that by creating a single global mutex. So like a lock that one part of the program can hold at a time. And then every time a thread finishes rendering a single pixel, it has to lock that lock. And only one thing can hold the lock at once to increment a number by one. And the thing with that is, is that all of the threads, like you have a, I don't know, over 16 core CPUs, you probably have 32 actual threads.\nThey all spend most of the time blocked waiting [00:14:00] to hold this lock to bump a number by one. This is completely unnecessary, and it meant that the whole thing ended up spending like five times more Wow. Than it should have. \n[00:14:09] **Jason Hand:** It's \n[00:14:09] **Scott Gerring:** an expensive \n[00:14:10] **Jason Hand:** progress bar. \n[00:14:11] **Scott Gerring:** Yeah. It's crazy. And it's a funny failure mode because like I say, you don't notice it unless.\nYou, you dig into it a bit or you notice that the CPU usage is doing something funny or you have some mental model of roughly how slow it should be, which I didn't like I didn't realize that it was so much slower than what I remembered that I should look at, that it was only the CPU usage hint.\nBut the interesting thing here is I think you can see how it's got there. Rust has all these language elements that make it very hard to do things that are unsafe in kind of. Multi-processing situations. So if you have a bunch of threads and you have a piece of shared memory where you need to bump a number, for instance, you can't just share around immutable reference to this bit of memory.\nLike you can't do that in rust. It just won't let you. You can try and the compiler will just say, no, that is not allowed. Have you [00:15:00] considered using a mutex? So what I think has happened here is that it's tried to do it the naive way, which would work in other languages like Java or C or whatnot. The compiler has given it a very direct suggestion to use.\nTo use Aex and wrap it up in an arc, and then it's done it, and the thing's compiled and it's worked, so it's pretty happy. \n[00:15:20] **Jason Hand:** Do you recall, so this is all in . Claude Code. Just as a reminder that you're, that this code was generated. Do you recall which model it was using at the time?\nWas it sonnet? \n[00:15:29] **Scott Gerring:** It would've been, they just released a new one, I think, right? A week ago. I wanna \n[00:15:33] **Jason Hand:** say we, when we were chatting last, like when we recorded, I, it was probably 3.7 at the time. I think four came out just a little bit after that, but.\n[00:15:46] **Scott Gerring:** How do I do it? Model? \n[00:15:47] **Jason Hand:** Yeah. \n[00:15:48] **Scott Gerring:** So what do we have? SONET four. Yeah, it was three point something because I know came out. Yeah. \n[00:15:54] **Jason Hand:** I wanna say unless you've written, unless this code was generated within the last, like two weeks or so, or week and a [00:16:00] half, it's probably 3.7. Yeah. Okay. I've noticed differences with four.\nLike I've created some really interesting, I dunno, not super interesting, but surprisingly well built little demo apps in one or two shots. \n[00:16:17] **Scott Gerring:** Nice. \n[00:16:18] **Jason Hand:** With Claude Sonnet 4, and I can't put my finger on what's different about it, but I'm having a real high success rate. Cool. So I'd be curious to see what it did, what that model would do, \n[00:16:27] **Scott Gerring:** yeah, and this is a thing that I'm a bit sad about. We've talked about this before. I wish that. The tools themselves would write out a conversation log, because then you could just go back to it from a certain prompt, from just before when it did this, and you could say, you could just let it continue and see what happened.\nBut as it stands the production of the program, from the conversation I had with it is lost to the winds of time. Like it would be so hard to get it back into the situation to see if it was gonna do this little step here differently. \n[00:16:55] **Jason Hand:** Bringing that context through over time is a conversation we've had a few [00:17:00] times on here.\nRyan and I have chatted about it. Actually, Whitney on our team, I interviewed her last week, I wanna say two weeks ago maybe. She has been doing some work with MCP servers in Cursor and she's doing something that actually addresses exactly what you're talking about is after a session of coding.\nDuring the session of coding. And then of course anything has to be summarized afterwards. But during the like time you're coding and talking to Claude or whatever, all of that is getting captured into other. And into other files and being logged in a little bit more human readable way, not just like taking the logs from, whatever, output and console and throwing them in places, but like actually documenting what's been done, including prompts, all that kind of stuff.\nYeah, other people were thinking the same way as I worked, had so much success on. Day one, I need to bring everything that we did with me. Like whole thing needs to come with me, not just like the code. \n[00:17:55] **Scott Gerring:** Yeah. \nThere was there was a really interesting thing that I saw a few days ago.\nI'm [00:18:00] sure you saw it as well. CloudFlare published a project that they've built. I can't remember what it was exactly. It'll be something to do with network re or whatnot, something very cloud. The code was entirely built by Claude, as I recall. And they didn't just publish the code, they published all of the prompts that they used to get to the state of the code.\nSo it's a really interesting artifact 'cause it's like a big serious engineering company saying, Hey, we built this serious thing but we did it with generative ai and here's how I've been meaning to dig into it. 'cause I think it'd be very interesting. \n[00:18:30] **Jason Hand:** Yeah, I have not seen that. I'll have to look at that though.\n[00:18:32] **Scott Gerring:** Sounds I'll get through to you afterwards. \n[00:18:34] **Jason Hand:** Yeah, please do. \n[00:18:36] **Scott Gerring:** But yeah, so that one was interesting and this one here is terrifying in a. You, you were saying before, like if you saw that Rust that I showed you with the unsafe block, you wouldn't really think oh, this is terrible or whatnot, because you're not, you don't see yourself as a Rust programmer.\nYou don't have the sense for what might look unusual than Rust. Like I wouldn't have the sense for it in JavaScript, for instance, [00:19:00] this is more subtle than that. It's the same thing, but it's applied to the domain itself. So like the domain is a ray tracer, Ray tracing code has to look a certain way, do certain things.\nThis is missing something that's very important and you only know that it's missing if you've built a Ray tracer before and know what to expect here. And the gist of it is that like when you shoot array at a thing and it hits the thing, like this pencil and this glass that I handily have had handy it, it hits it and it either goes through it or it bounces off at absorbed.\nAnd if the ray trebles onwards, like if it goes through the glass and continues out the other side, you make a new ray based on how it bends through the glass. And what you need to do is make it so that the new ray starts. It doesn't have the start point at the intersection. It has to have, it has to be moved a tiny bit away from the surface along the direction of the outgoing.\nAnd the reason for that is that if you don't, because floating point maths is funny, some of the time it'll re intersect at the same point and you get weird artifacting in your output images. \n[00:19:59] **Jason Hand:** I think \n[00:19:59] **Scott Gerring:** there are probably [00:20:00] other ways of solving this, but like typically the thing to do is to just shift that new starting point of the new ray, a tiny bit along that outgoing redirection.\nOkay. And this just doesn't have that. So I saw the images, it was rendering, and I noticed that in particular for surfaces that were glass, it had this very particular artifacting in it. And I thought, okay, something unusual is happening here. And I found that it was missing that, but only because I know that it should be there.\nIf you weren't familiar with Ray tracing, you would probably just say, oh, it's just how it is, and it would be very difficult to work this out. So I think this is a heinous one because it. \n[00:20:37] **Jason Hand:** It sounds like this is a landmine that you've seen before, right? Like it's that knowledge that, that just comes up with experience, the wisdom of playing with Ray Traces.\nRay Trace. Yeah. Wisdom is a \n[00:20:47] **Scott Gerring:** strong word to use in this kind. It is.\n[00:20:49] **Jason Hand:** It's stuff that's not in the, it's not mentioned in the text, because you don't think about it. It's kinda an edge case almost. I think you \n[00:20:54] **Scott Gerring:** would, I think you would definitely see it mentioned.\nIt's a common pitfall. Yeah. But it's [00:21:00] just missed it. But I guess the point that I'm trying to make with it is that for something complex like this, or something reasonably complex, you have to understand what success looks like. Yeah. Before you let the agent rip on it, because at the end, if you can't assess whether or not it's correct or not, you have something that might be failing in a complicated way that you don't understand.\n[00:21:20] **Jason Hand:** Yep. \n[00:21:20] **Scott Gerring:** And I've really, I've picked a pathological case with this thing, right? Like you, you get an image out and the image can be broken in ways that are very subtle. It's not like a web service or something. Sure. So I appreciate that, but I still think that there's an important lesson in there about absolutely how far you can go away from what you fully understand.\n[00:21:37] **Jason Hand:** So what is it like just a couple lines of code that's missing or a function or one little variable with some math attached to it? How \n[00:21:45] **Scott Gerring:** much. A line, basically you would go new Ray I don't have all the context, but it'd be like new ray equals ray, new old start point plus [00:22:00] times tiny spelling.\n[00:22:01] **Jason Hand:** Okay. So yeah, it's just got some basic hard coded math in there that you probably used to seeing. \n[00:22:06] **Scott Gerring:** Yeah. Yeah. You just you always have the direction and the direction will probably be like one, like a unit vector. Yeah. And you just make it really small 'cause you just wanna move it a tiny bit away so it doesn't re intersect itself.\n[00:22:15] **Jason Hand:** That makes sense. \n[00:22:16] **Scott Gerring:** Yeah. Okay. Cool. So some other stuff. And now for something different DevHub, have you had a look at DevHub yet? I haven't. \n[00:22:27] **Jason Hand:** I've been in there, but I haven't really spent like good, genuine time in there. \n[00:22:30] **Scott Gerring:** So I'll show you it really quickly and I will tell you what I've used Claude code for.\nSo this is something that we've been building in the advocacy team at Datadog recently to capture all of the integration points and extensibility information for Datadog, like highlight projects from the community that are building around the platform essentially. It's pretty cool. Go have a go, have a look at it.\nIf you've before everybody go check it out. It's pretty new. It's brand spaking new. Yeah. Yeah. We're very excited about where we can take it. But so the co the code part of this, the part of it that I spent [00:23:00] a bit of time on was a ETL pipeline, like extract, transform, load for all the different data sources we have about existing integrations for Datadog, so things like the agent extensions, third party libraries.\nWe have this data in various GitHub repos. And we wanted to put everything we already had straight into DevHub, which is this big job to get it all munged into a nice format, publish it out into the static website, build for DevHub itself. And this is something where Claude Code really shines because it's mapping, it's data mapping.\nLike it's what 99% of programming is. There's heaps of examples out of everywhere. You have sample data, you have a destination schema. So I had great success just using it to color in the lines for this. So for instance, for this one here, this is the schema for content items. That end up in DevHub and I got this.\nBasically by just giving [00:24:00] it the schema from Astro, so the website folks from Datadog built and Astro ui and the content catalog with static content in it with all the different fields they need for one side. And on the other side we have all of these data sources I mentioned, like the different agent integration data sets we have and library integration data sets.\nAnd I basically just put it all in files and gave it to Claude and said Hey, can you go and write me type definitions for this for TypeScript? And I did it and it was perfect, and it saved me a whole pile of time. Nice. \n[00:24:29] **Jason Hand:** Yeah. I love Astro as you mentioned, like our team's been kinda migrating some stuff over to Astro.\nWe just migrated our site. The AI tools Labs is now an Astro site. I just migrated my personal site to an Astros site as well. So yeah, it's a, it's the new hotness. It's fun. It's nice that the models do understand Astro pretty well, which is cool. \n[00:24:50] **Scott Gerring:** Yeah, and it works really well if you have a TypeScript thing that's producing the data and then you can TypeScript it up on Astro as well. My personal blog is also built with Astro and I also migrated it about a year [00:25:00] ago, and I. \n[00:25:02] **Jason Hand:** Seems like we've got a little Astro community, Starting to, you come together here. \n[00:25:06] **Scott Gerring:** It's, I think it's I don't have such strong opinions about web development, but it seems if you want something that works well and you don't have very strong opinions about web dev it is just perfect.\nI love it. \n[00:25:15] **Jason Hand:** Yeah. It's fast. It can shrink down like images and make your site faster and make some of that better. And just what's the word? Where there's like components you can drop things in.\nModular, perhaps. Modular. That's what I'm looking for. Yeah. Yeah. It's, I love it. \n[00:25:28] **Scott Gerring:** I like it a lot \n[00:25:28] **Jason Hand:** as well. Go check out Astro. \n[00:25:30] **Scott Gerring:** Yeah, everyone get Astro. Yeah. And so a similar sort of thing part of the import pipeline has all these libraries that we have. So if you go and build an integration to Datadog, to pull metrics from some particular system that exposes metrics, maybe a fancy hardware router device for instance.\nWe would link to a GitHub repository that contains the code for that. And as part of that, we wanna pull back a pile of metadata from GitHub, when it was it last updated, how many stars does it have, and so on. And for this, I needed a GitHub client. So I [00:26:00] gave Claude code, the API document link and said, go and write me a GitHub client, please.\nAnd again it just did it. It was great. I looked at the output. I couldn't fault it. It was, if anything better documented than what I would do myself. And I think things like this that really shines, like it's such a mechanical task. It's not something that needs. Heaps of brain capacity.\nIt's not something where there's heaps of variation within what you get out of it. It's just go forth and do it. And if you're limited by the speed of your typing, it takes a bit longer than if you're not. Yep. So I was really happy with that, and I find that it's also much, much better and more consistent with things like JavaScript and TypeScript with Rust, but I suspect that's just because there's a lot more of that in the training set.\nIt also works really well for refactoring TypeScript. I found that's something that I at least don't have a good IDE for, like I don't have something, for rust or for Java or whatnot. You have the jet brains tools. You wanna move things between packages, rename them. It's a couple of mouse clicks or some keystrokes.\nIt all works very [00:27:00] well. I find that you can just go to Claude and say, Hey, I'm not quite happy with this package layout. I would like to change it like this one. Do you think this is sensible? And two, go forth and do it for me. And it does it, it takes longer than if you have really fancy refactoring tools, but it's makes something that would otherwise be painful.\nVery easy. Yeah. \n[00:27:20] **Jason Hand:** Which I think is the perfect, like use case for a lot of these things. That's where I'm using Gene A Ai I the most is just make my life easier. Do the stuff I don't really, I know needs to be done. I know it'll make life and everything else easier moving forward, but it takes time to slog to get through it.\nYeah. \n[00:27:39] **Scott Gerring:** Yeah, and a lot of these things aren't actually fun. I think there's lots of elements of programming that are inherently very creative and it's a pity to offload that to a tool also because it helps you flesh out your model of the problem you're trying to solve if you do it yourself.\nBut heaps and heaps of programming is just boring, repetitive work. That these things really shine a\n[00:27:58] **Jason Hand:** hundred [00:28:00] percent. \n[00:28:01] **Scott Gerring:** This one's a bit harder to explain. I dunno if the text I've got is gonna be very interesting. So as part of this dev hub thing it's just transforming things between different data formats, like I mentioned.\nAnd for that you really want to have tests. You want some unit tests that are like, if I put this in to the machine that does the transforming, I get this out. I'm a sensible programmer, but I don't write JavaScript or TypeScript very much, and I'm not up, up to date with the latest tooling for all of that.\nSo it's can you go and write me a unit test so I can fill in the details myself? Delegating the scaffolding of the unit test to Claude. This was an absolute mess. I, and I think it's, like I say, I'm not a frontend person. It's it's really hard for me to judge how inherently hard the problem of hooking a unit test library up to a TypeScript no JS project is, but it went down this crazy rabbit hole.\nI dunno if I captured it here, where. It kept trying to change the module [00:29:00] packaging all over the place, and because DevHub is this nested multi module thing, it was changing it at different levels. I'll change this to ES Next and I'll change this to common JS and breaking everything in like really complicated, strange ways.\nBecause JavaScript module seems to be a very complicated thing, but in the end, the test, it had a test that ran, but like everything else was completely broken. So I looked at it and I was like, you've changed this thing that seems like it's probably a big deal. Can you tell me about that? And it explained itself, but I can't get myself into a situation where I'm comfortable with what it's done or I fully understand the implications of what it's done.\nSo I just gave up on it. I said, this is outside of my skillset and you haven't convinced me that it's within your skillset. But I found it really funny because it's like you give it a small task and it makes this dramatic project wide impacting choice without really telling you about it until you notice that everything else has been broken.\nBut yeah I think also if you were, you notice those ones quickly because you [00:30:00] go and look at the change set and all these files you weren't expecting to be touched have been touched. And then it's, the blast radius is naturally limited that way for sure. These two are a bit weirder.\nI'll explain this one quickly with my words because I don't think the text will help very much. Okay. I tried to clean it up a bit before, but I just confused myself. I just published this tool on our GitHub that does architectural unit testing for rust. So you can, there, there's similar tools for Java and DotNet you can write assertions about.\nIf. I have code in the rest API package, it shouldn't be using the database package directly. Or if I have code in the database package, it shouldn't have global static variables, stuff like that. Stuff that people have in their heads when they build systems, but you don't really have a way to encode them.\nBut the interesting fact about this from a generative AI perspective is that. To build things like this in the Rust-iverse, you have to use or you don't have to. But the easiest way to do it is to use the internals of rust itself. So like the compiler internals, [00:31:00] which you can do, but it's all very gnarly and not very documented, unsurprisingly.\nIt's also unstable. So I tried initially a bit when I started with Claude and with Cursor to let it work on this project. Hey, here's a lint that limits what things in this namespace can get to it in this other namespace. It just can't it tries, it runs into the wall. It can't get interfaces, right?\nIt doesn't understand the shape of the code or how to work with it. You just have to give up basically. I think this is reasonable as well though, because it's just, there's nothing about this anywhere. It's not something that's massively present in the training set. You can try and give it the source code of the Rust Compiler for the interfaces it's trying to use, but because these files are enormous, it'll immediately fill the whole context window and then some, and that doesn't really work either.\nI think maybe you could be really clever and strip out all the new lines and the comments and that and see if it could go with that. It's the only like truly pathological case I've [00:32:00] found so far, where the tools are just not helpful at all. \n[00:32:04] **Jason Hand:** When you are running Claude Code, you know how when you load Claude Code from whichever director you're in Claude Code has like an understanding of everything below that, right? So you can always sometimes I'll realize I need to go one more level up actually and give it more context. Of like the broader project. Did you run into anything like that or did you always start in like the most top tier place to load?\nClaude Code, \n[00:32:28] **Scott Gerring:** I often do it from a level down rather than a level up in the sense that there's a few projects I'm working on where they're like Monorepo microservice. So there's this surrounding context that has, infrastructure as code files deployment stuff for Readme, and then you have a bunch of sub-services.\nThen I find that if I start Claude Code in like the directory of a subservice and I'm working on something that's only relevant to the subservice it gets us confused. 'cause then it's just, you've basically said like this is the thing you are considering. But then, for anything cross [00:33:00] cutting, you get your claude.md in the top and you explain, here are all my different services.\nIf I ask you something about this then go look there. \nYeah, it, I think about that a lot. Like what you let it see initially really shapes its perception of the world. \n[00:33:14] **Jason Hand:** It really does. Yeah. And that and I think, whether you're trying to save token usage here and there, you make decisions on what context you end up giving it, which is gonna have a direct impact to the output.\n[00:33:26] **Scott Gerring:** Yeah.\nI think I am not nearly as frugal as I should be with the token usage stuff. Yeah. I, this is a bit the curse of having something like this bundled up from a nice subscription through your employer. I think it probably also has a performance issue though. Hey, if you run Claude Code, where it's always sitting on a hundred percent context window size, I assume that makes everything much slower, and that's my perception of it as well.\n[00:33:51] **Jason Hand:** Yeah. I feel like there has to be a push in, in the direction where rather than everybody in an organization [00:34:00] all like bringing down and pushing up and bringing down and pushing up context all the time, that somehow all of us are just sharing the same context. Yeah. You know what I mean? Because we're just we're just wasting passing data back and forth.\nIt usually all sits in. In the place it always needs to be, I think, but getting it into the models, of course sending it into wherever you're sending it is the expensive part, but I feel like we, that's a problem we're gonna have to solve for because code's not getting code, bases aren't getting necessarily smaller.\n[00:34:31] **Scott Gerring:** There's lots of interesting kind of intermediate representations for query and code these days. Code QL is one where, you run it over your code base and it builds a little embedded database that kind of describes the structure of it. Syntax tree style, but abstracted a bit back from the concrete language.\nI wonder if things are gonna go in that direction rather than just jamming enormous strings into context everywhere. Being a bit fancier. Yeah, you're right. There's a lot of rediscovery effects about code just because the tools tend to [00:35:00] work primarily with big string buffers. Yeah. It seems like there's a lot of reasonably low hanging fruit there to push things in the right direction.\n[00:35:10] **Jason Hand:** MCP is a good example of, I think us all just solving the problems that we continue to, bump into. It's oh, now we need some other way to interface with all these other tools and so not us Anthropic people much smarter than me. I'm just a, I'm just a beneficiary. But , there's gonna be more of that, right?\nI just think we're gonna continue finding ways around the roadblocks that we hit. \n[00:35:30] **Scott Gerring:** Yeah, absolutely. And I think MCP also for us in the Datadog sense is really interesting because you can imagine some really cool use cases for it. For instance you, you have the situation where you have Cursor open and a unit test broken, you say.\nYou can see the broken unit test, go and fix it. With MCP, you could say, Hey, you can see this production issue. You have all this different observability data about it. Go and fix it. I think that's really cool. I haven't had much time to play with it yet, but like it could be [00:36:00] one of those things that feels very akin to magic when it works well.\n[00:36:04] **Jason Hand:** Yeah. All right. \n[00:36:06] **Scott Gerring:** Cool. Anything else you wanna share before we wrap things up? The absolute last one I have, and this isn't very interesting in comparison to the code ones, I think, is, I have this fancy writing tablet. I dunno if you have one of these. Okay. It's a SuperNote, but it's like an ola sorry, a okay.\nE ink thing you can write on. And I use it constantly now because it's I dunno. I like the tactility of it or something, but it's, yeah I write a lot for work, obviously, and I've taken to writing on this rather than typing so I can go sit outside in the hammock or whatnot and just write a little bit hammock driven development style.\nOkay. And what I've taken to doing with it is exporting the thing I've written as a PDF and giving it to either Claude code or chat GPT. As well as the context of say, my existing blog writing and saying, Hey, can you go and transcribe all of this, fix all the spelling mistakes Australian English spelling.\nThank you very much. And if anything is weird or [00:37:00] stylistically unusual about it, highlight it for me. And that works really well. It saves so much time and it fixes, like in, in the old days where you would just do. Like handwriting recognition. It fixes all of the weird little issues because your handwriting's awful, or you can't spell properly or whatnot.\nThat's awesome. It almost feels like a boring use case in comparison to everything else, oh, \n[00:37:19] **Jason Hand:** That's a, I love that. I've got something similar. I've got I forget what it's called but a little tablet that I can write on also and export PDFs out. So yeah, you might have to gimme more details on step by step what you're doing there.\nI'll try it with my stuff too \n[00:37:33] **Scott Gerring:** Yeah, absolutely. But it's so simple and unexciting, but it's just, it just works. It makes my life, I think anything that solves \n[00:37:38] **Jason Hand:** little problems for me is some of the most exciting stuff. \n[00:37:41] **Scott Gerring:** Yeah. Fair enough.\n[00:37:45] **Jason Hand:** Cool. Scott, this has been awesome. Thanks for giving us a little bit of an update on additional findings that you've come across as you experiment with Claude Code.\nI think a lot of what you have is [00:38:00] so unique to Rust which is nice. I don't get a lot of exposure to Rust, so it's good to hear some just what you're seeing and learning as you start to experiment. So I can add that to my own knowledge. I think \n[00:38:12] **Scott Gerring:** it's also, it works comparatively very well for things like TypeScript.\nSo the weird things that I like to talk about tend to be more in rust. Yeah. Cool. Yeah. Anyway, it's been a pleasure as always. Yeah. \n[00:38:23] **Jason Hand:** Thanks for thanks for getting on and talking to me and yeah, hopefully we'll do it again sometime in the near future. \n[00:38:29] **Scott Gerring:** Absolutely. A lovely day.","src/content/episodes/ep32.mdx","1eb7b3403dce10b6","ep32.mdx","ep33",{"id":2332,"data":2334,"body":2420,"filePath":2421,"digest":2422,"legacyId":2423,"deferredRender":104},{"title":2335,"description":2336,"heroImg":2337,"videoId":2338,"episodeNumber":2339,"date":2340,"author":20,"participants":2341,"tags":2342,"takeaways":2347,"resources":2374,"jumpTo":2391,"summary":2420,"featured":54,"transcriptAvailable":104},"Exploring Gemini CLI and MCP Servers for AI Development","Ryan MacLean demonstrates his workflow using Gemini CLI with MCP servers, showing how to set up sandbox environments and integrate with various AI coding tools for enhanced development productivity.","../images/thumbnails/ep33.png","xty9pdXiYH4",33,"2025-01-15T00:00:00.000Z",[22,23],[2343,2344,2345,2346],"ai-tools","cli","mcp-servers","development-workflow",[2348,2353,2357,2361,2365,2369],{"text":2349,"tools":2350},"Gemini CLI provides a sandbox environment for safe code execution with YOLO mode for experimental features",[2351,2352],"Gemini CLI","Google Gemini",{"text":2354,"tools":2355},"MCP servers can be easily integrated with Gemini CLI using keyboard shortcuts like Ctrl-T to view available tools",[2351,2356],"MCP Servers",{"text":2358,"tools":2359},"Sequential thinking in MCP allows for step-by-step problem solving and better context management",[2356,2360],"Sequential Thinking",{"text":2362,"tools":2363},"Gemini 2.5 Pro offers better context handling for larger projects compared to Flash model",[1374,2364],"Gemini Flash",{"text":2366,"tools":2367},"Memory features in Gemini CLI allow importing external rules and guidelines for consistent development",[2351,2368],"Memory Features",{"text":2370,"tools":2371},"Different AI coding tools excel at different tasks - CLI tools for quick prototypes, GUI tools for complex development",[2372,2373],"AI Coding Tools","Workflow Optimization",[2375,2379,2383,2387],{"name":2376,"url":2377,"description":2378,"featured":54},"Gemini CLI GitHub","https://github.com/google-gemini-cli","Official GitHub repository for Google's Gemini CLI tool",{"name":2380,"url":2381,"description":2382,"featured":54},"MCP (Model Context Protocol)","https://modelcontextprotocol.io/","Official documentation for the Model Context Protocol standard",{"name":2384,"url":2385,"description":2386,"featured":54},"Sequential Thinking MCP","https://github.com/modelcontextprotocol/servers","MCP server implementations including sequential thinking capabilities",{"name":2388,"url":2389,"description":2390,"featured":54},"Gemini 2.5 Pro Documentation","https://ai.google.dev/gemini-api","Official documentation for Gemini 2.5 Pro model and API",[2392,2395,2398,2401,2404,2407,2410,2413,2416],{"title":2393,"url":2394,"timestamp":70},"Introduction to AI coding workflow and tools","https://youtu.be/xty9pdXiYH4?t=0",{"title":2396,"url":2397,"timestamp":2033},"Ryan's experience with Aider and transition to Gemini CLI","https://youtu.be/xty9pdXiYH4?t=30",{"title":2399,"url":2400,"timestamp":897},"Comparison of AI coding tools: Claude Code vs Gemini CLI","https://youtu.be/xty9pdXiYH4?t=60",{"title":2402,"url":2403,"timestamp":158},"Setting up Gemini CLI with NPX and global installation","https://youtu.be/xty9pdXiYH4?t=180",{"title":2405,"url":2406,"timestamp":491},"Configuring MCP servers and sandbox environment","https://youtu.be/xty9pdXiYH4?t=240",{"title":2408,"url":2409,"timestamp":642},"Demonstrating project analysis and Gemini.md generation","https://youtu.be/xty9pdXiYH4?t=420",{"title":2411,"url":2412,"timestamp":729},"Comparing Gemini 2.5 Pro vs Flash model performance","https://youtu.be/xty9pdXiYH4?t=600",{"title":2414,"url":2415,"timestamp":178},"Memory features and importing external rules","https://youtu.be/xty9pdXiYH4?t=1080",{"title":2417,"url":2418,"timestamp":2419},"Workflow optimization and tool selection strategies","https://youtu.be/xty9pdXiYH4?t=1149","00:19:09","Ryan MacLean shares his evolving AI development workflow, transitioning from Aider to Gemini CLI and exploring the power of MCP servers. He demonstrates how to set up sandbox environments, integrate sequential thinking capabilities, and leverage memory features for consistent development practices. The episode covers practical comparisons between different AI coding tools, from command-line interfaces to GUI-based solutions, and provides insights into when to use each tool for optimal productivity. Perfect for developers looking to optimize their AI-assisted coding workflow and understand the trade-offs between different AI development tools.","src/content/episodes/ep33.mdx","807d04d18d98bcc9","ep33.mdx","ep34",{"id":2424,"data":2426,"body":2515,"filePath":2516,"digest":2517,"legacyId":2518,"deferredRender":104},{"title":2427,"description":2428,"heroImg":2429,"videoId":2430,"episodeNumber":2431,"date":2340,"author":20,"participants":2432,"tags":2434,"takeaways":2439,"resources":2467,"jumpTo":2483,"summary":2515,"featured":54,"transcriptAvailable":104},"Building Remote MCP Servers with AWS Lambda and Serverless Architecture","James Eastham demonstrates how to build and deploy remote MCP servers using AWS Lambda, showing how serverless architecture provides the perfect environment for conversational AI interfaces with proper observability and security.","../images/thumbnails/ep34.png","6kJM55AYyCg",34,[22,2433],"James Eastham",[2345,2435,2436,2437,2438],"aws-lambda","serverless","observability","ai-integration",[2440,2444,2449,2454,2458,2463],{"text":2441,"tools":2442},"Serverless architecture is ideal for remote MCP servers due to unpredictable workloads and infinite scalability",[2443,693,2356],"AWS Lambda",{"text":2445,"tools":2446},"Lambda Web Adapter enables running any web application on Lambda without traditional Lambda handlers",[2443,2447,2448],"Lambda Web Adapter","Express.js",{"text":2450,"tools":2451},"Remote MCP servers can act as API gateways, proxying requests to downstream microservices",[2356,2452,2453],"API Gateway","Microservices",{"text":2455,"tools":2456},"Datadog Lambda instrumentation provides automatic observability without code changes",[307,2443,2457],"Observability",{"text":2459,"tools":2460},"MCP servers require proper authentication and security considerations despite conversational interfaces",[2356,2461,2462],"Authentication","Security",{"text":2464,"tools":2465},"Cost considerations include double-paying for compute when proxying between serverless functions",[2443,2466,693],"Cost Optimization",[2468,2472,2475,2479],{"name":2469,"url":2470,"description":2471,"featured":54},"AWS MCP Server Samples","https://github.com/aws-samples/serverless-mcp-servers","AWS sample implementations for running MCP servers on serverless platforms",{"name":2447,"url":2473,"description":2474,"featured":54},"https://github.com/awslabs/aws-lambda-web-adapter","GitHub repository for the Lambda Web Adapter that enables running web apps on Lambda",{"name":2476,"url":2477,"description":2478,"featured":54},"MCP Remote Package","https://github.com/modelcontextprotocol/js-remote","JavaScript package for connecting to remote MCP servers",{"name":2480,"url":2481,"description":2482,"featured":54},"Datadog Lambda Instrumentation","https://docs.datadoghq.com/serverless/installation/nodejs/","Documentation for instrumenting AWS Lambda functions with Datadog",[2484,2487,2490,2493,2496,2499,2502,2505,2508,2511],{"title":2485,"url":2486,"timestamp":70},"Introduction to remote MCP servers and serverless architecture","https://youtu.be/6kJM55AYyCg?t=0",{"title":2488,"url":2489,"timestamp":331},"James explains the serverless e-commerce sample application","https://youtu.be/6kJM55AYyCg?t=120",{"title":2491,"url":2492,"timestamp":158},"Configuring Claude Desktop with remote MCP server integration","https://youtu.be/6kJM55AYyCg?t=180",{"title":2494,"url":2495,"timestamp":338},"Demonstrating conversational interface with product queries","https://youtu.be/6kJM55AYyCg?t=300",{"title":2497,"url":2498,"timestamp":166},"Exploring the Express.js MCP server implementation","https://youtu.be/6kJM55AYyCg?t=540",{"title":2500,"url":2501,"timestamp":430},"Understanding the MCP server as API gateway pattern","https://youtu.be/6kJM55AYyCg?t=780",{"title":2503,"url":2504,"timestamp":174},"Cost and performance considerations for serverless MCP servers","https://youtu.be/6kJM55AYyCg?t=900",{"title":2506,"url":2507,"timestamp":742},"Datadog observability and tracing demonstration","https://youtu.be/6kJM55AYyCg?t=1020",{"title":2509,"url":2510,"timestamp":1612},"Lambda Web Adapter explanation and benefits","https://youtu.be/6kJM55AYyCg?t=1320",{"title":2512,"url":2513,"timestamp":2514},"Final demonstration of order creation through conversational interface","https://youtu.be/6kJM55AYyCg?t=1500","00:25:00","James Eastham demonstrates the power of remote MCP servers in serverless environments, showing how AWS Lambda provides the perfect platform for conversational AI interfaces. He walks through building a complete e-commerce application with MCP integration, from Express.js implementation to Claude Desktop configuration. The episode covers practical considerations including cost optimization, security authentication, and observability with Datadog tracing. Perfect for developers interested in building conversational interfaces that integrate with existing microservices architectures and understanding the trade-offs between traditional APIs and MCP-based solutions.","src/content/episodes/ep34.mdx","b78fc69c0f3ba3a9","ep34.mdx","ep35",{"id":2519,"data":2521,"body":2609,"filePath":2610,"digest":2611,"legacyId":2612,"deferredRender":104},{"title":2522,"description":2523,"heroImg":2524,"videoId":2525,"episodeNumber":2526,"date":2340,"author":20,"participants":2527,"tags":2528,"takeaways":2531,"resources":2560,"jumpTo":2577,"summary":2609,"featured":54,"transcriptAvailable":104},"Observability and Monitoring for AI-Enabled Development","Jason Hand shares his approach to instrumenting AI-built applications with Datadog RUM, discussing the importance of monitoring fast-iterating projects and managing GitHub repositories for rapid development workflows.","../images/thumbnails/ep35.png","lPoNStvY84Y",35,[22,23],[2437,2529,2530,2346,2343],"monitoring","datadog",[2532,2537,2541,2545,2550,2556],{"text":2533,"tools":2534},"Datadog RUM (Real User Monitoring) provides easy SDK integration for basic HTML applications",[307,2535,2536],"RUM","Monitoring",{"text":2538,"tools":2539},"Observability becomes critical as AI-built apps mature and reach real users",[2457,2540],"User Analytics",{"text":2542,"tools":2543},"GitHub serves as a central repository for managing multiple AI-generated projects across devices",[1260,2544,1562],"Version Control",{"text":2546,"tools":2547},"Session replay features help understand how users interact with AI-built applications",[307,2548,2549],"Session Replay","User Experience",{"text":2551,"tools":2552},"Product analytics provide insights into user behavior and application performance",[2553,2554,2555],"Analytics","User Behavior","Performance Monitoring",{"text":2557,"tools":2558},"Public repositories encourage learning transparency while private repos protect early-stage projects",[1260,2559,1562],"Open Source",[2561,2565,2569,2573],{"name":2562,"url":2563,"description":2564,"featured":54},"Datadog Real User Monitoring","https://docs.datadoghq.com/real_user_monitoring/","Official documentation for Datadog's Real User Monitoring (RUM) feature",{"name":2566,"url":2567,"description":2568,"featured":54},"Datadog RUM SDK Setup","https://docs.datadoghq.com/real_user_monitoring/browser/","Setup guide for integrating Datadog RUM SDK into web applications",{"name":2570,"url":2571,"description":2572,"featured":54},"GitHub Best Practices","https://docs.github.com/en/get-started/quickstart","GitHub documentation for managing repositories and collaborative development",{"name":2574,"url":2575,"description":2576,"featured":54},"Session Replay Documentation","https://docs.datadoghq.com/real_user_monitoring/session_replay/","Guide to using Datadog's session replay feature for user experience analysis",[2578,2581,2585,2588,2592,2595,2599,2603,2606],{"title":2579,"url":2580,"timestamp":70},"Introduction to weekend app development and rapid iteration","https://youtu.be/lPoNStvY84Ya?t=0",{"title":2582,"url":2583,"timestamp":2584},"Ryan's approach to testing ideas and iterating on projects","https://youtu.be/lPoNStvY84Ya?t=57","00:00:57",{"title":2586,"url":2587,"timestamp":331},"Importance of observability for AI-enabled applications","https://youtu.be/lPoNStvY84Ya?t=120",{"title":2589,"url":2590,"timestamp":2591},"Setting up Datadog RUM for basic HTML applications","https://youtu.be/lPoNStvY84Ya?t=235","00:03:55",{"title":2593,"url":2594,"timestamp":642},"Demonstrating Datadog RUM setup process","https://youtu.be/lPoNStvY84Ya?t=420",{"title":2596,"url":2597,"timestamp":2598},"Analyzing user behavior and session replay features","https://youtu.be/lPoNStvY84Ya?t=535","00:08:55",{"title":2600,"url":2601,"timestamp":2602},"GitHub as central repository for multi-device development","https://youtu.be/lPoNStvY84Ya?t=576","00:09:36",{"title":2604,"url":2605,"timestamp":1221},"Managing public vs private repositories for project maturity","https://youtu.be/lPoNStvY84Ya?t=660",{"title":2607,"url":2608,"timestamp":430},"Future of Git syntax abstraction in AI development tools","https://youtu.be/lPoNStvY84Ya?t=780","Jason Hand shares his weekend app development workflow and the critical importance of observability in the AI-enabled development era. He demonstrates how to quickly instrument applications with Datadog RUM, from basic HTML files to complex React applications, and discusses the role of GitHub as a central repository for managing multiple projects across devices. The episode covers practical monitoring strategies, session replay analysis, and the balance between public learning and private development. Perfect for developers building AI-assisted applications who need to understand user behavior and maintain project organization as they rapidly iterate on ideas.","src/content/episodes/ep35.mdx","adb1cb1bcb717724","ep35.mdx","ep36",{"id":2613,"data":2615,"body":2704,"filePath":2705,"digest":2706,"legacyId":2707,"deferredRender":104},{"title":2616,"description":2617,"heroImg":2618,"videoId":2619,"episodeNumber":2620,"date":2340,"author":20,"participants":2621,"tags":2622,"takeaways":2625,"resources":2656,"jumpTo":2672,"summary":2704,"featured":54,"transcriptAvailable":104},"Test-Driven Development and Building a Lovable Clone","Ryan MacLean shares his experience with test-driven development using Claude Code, demonstrating how to build a Lovable clone with Kubernetes, monitoring, and the importance of PRDs for complex AI-assisted projects.","../images/thumbnails/ep36.png","dyOdjNiar8E",36,[22,23],[2623,1814,2624,2529,1034],"test-driven-development","kubernetes",[2626,2630,2636,2642,2647,2652],{"text":2627,"tools":2628},"Test-driven development is essential when working with LLM agents to ensure code quality and functionality",[2629,295,2290],"TDD",{"text":2631,"tools":2632},"Pre-commit hooks with automated testing help maintain code quality in AI-assisted development",[2633,2634,2635],"Git Hooks","Automated Testing","Quality Assurance",{"text":2637,"tools":2638},"PRDs (Product Requirements Documents) help guide complex AI projects and maintain context",[2639,2640,2641],"PRD","Project Planning","Context Management",{"text":2643,"tools":2644},"Context engineering is crucial for long-running AI development sessions",[2641,2645,2646],"LLM Development","Prompt Engineering",{"text":2648,"tools":2649},"Kubernetes and monitoring integration should be planned early in AI-assisted projects",[2650,2536,2651],"Kubernetes","Infrastructure",{"text":2653,"tools":2654},"Complex projects require careful scope management to avoid feature creep in AI development",[1562,2655,2294],"Scope Control",[2657,2660,2664,2668],{"name":2658,"url":696,"description":2659,"featured":54},"Claude Code Documentation","Official documentation for Claude Code IDE and development features",{"name":2661,"url":2662,"description":2663,"featured":54},"Test-Driven Development Guide","https://www.agilealliance.org/glossary/tdd/","Comprehensive guide to Test-Driven Development methodology",{"name":2665,"url":2666,"description":2667,"featured":54},"Git Pre-commit Hooks","https://pre-commit.com/","Framework for managing pre-commit hooks for code quality",{"name":2669,"url":2670,"description":2671,"featured":54},"Kubernetes Documentation","https://kubernetes.io/docs/","Official Kubernetes documentation for container orchestration",[2673,2676,2680,2684,2688,2692,2696,2700],{"title":2674,"url":2675,"timestamp":70},"Introduction to weekend development and AI tool standardization","https://youtu.be/dyOdjNiar8E?t=0",{"title":2677,"url":2678,"timestamp":2679},"Ryan's experience with Claude Code as a third hand for development","https://youtu.be/dyOdjNiar8E?t=34","00:00:34",{"title":2681,"url":2682,"timestamp":2683},"Test-driven development approach with LLM agents","https://youtu.be/dyOdjNiar8E?t=94","00:01:34",{"title":2685,"url":2686,"timestamp":2687},"Creating a Lovable clone project with Kubernetes and monitoring","https://youtu.be/dyOdjNiar8E?t=155","00:02:35",{"title":2689,"url":2690,"timestamp":2691},"Challenges of scope management in AI-assisted development","https://youtu.be/dyOdjNiar8E?t=260","00:04:20",{"title":2693,"url":2694,"timestamp":2695},"Importance of PRDs for complex AI projects","https://youtu.be/dyOdjNiar8E?t=400","00:06:40",{"title":2697,"url":2698,"timestamp":2699},"Context engineering for long-running development sessions","https://youtu.be/dyOdjNiar8E?t=520","00:08:40",{"title":2701,"url":2702,"timestamp":2703},"Project genesis and PRD creation process","https://youtu.be/dyOdjNiar8E?t=640","00:10:40","Ryan MacLean shares his weekend experiment building a Lovable clone using test-driven development with Claude Code. He demonstrates the importance of PRDs for complex AI-assisted projects, the challenges of scope management, and how context engineering helps maintain focus during long development sessions. The episode covers practical approaches to TDD with LLM agents, Kubernetes integration, and the balance between rapid prototyping and maintaining code quality. Perfect for developers working on complex AI-assisted projects who need strategies for managing scope, maintaining context, and ensuring code quality.","src/content/episodes/ep36.mdx","352f214a4c9136fe","ep36.mdx","ep37",{"id":2708,"data":2710,"body":2798,"filePath":2799,"digest":2800,"legacyId":2801,"deferredRender":104},{"title":2711,"description":2712,"heroImg":2713,"videoId":2714,"episodeNumber":2715,"date":2340,"author":20,"participants":2716,"tags":2717,"takeaways":2721,"resources":2754,"jumpTo":2769,"summary":2798,"featured":54,"transcriptAvailable":104},"Capturing Knowledge and Learning from Vibe Coding Sessions","Jason Hand introduces his automated retrospective system for capturing learnings during AI-assisted development sessions, demonstrating how to create real-time documentation and team knowledge bases for collaborative projects.","../images/thumbnails/ep37.png","hlDGl4XTzsw",37,[22,23],[2718,2719,1034,2720,2106],"knowledge-capture","retrospectives","collaboration",[2722,2727,2733,2738,2744,2749],{"text":2723,"tools":2724},"Automated retrospectives capture learnings in real-time during AI-assisted development sessions",[2725,2726,2294],"Retrospectives","Knowledge Capture",{"text":2728,"tools":2729},"Team knowledge bases help transfer knowledge when projects grow beyond individual developers",[2730,2731,2732],"Knowledge Transfer","Documentation","Collaboration",{"text":2734,"tools":2735},"Decision trees and implementation strategies should be documented for future reference",[2736,2640,2737],"Decision Documentation","Knowledge Management",{"text":2739,"tools":2740},"Real-time capture is essential as the value of learnings diminishes over time",[2741,2742,2743],"Real-time Documentation","Learning Capture","Knowledge Retention",{"text":2745,"tools":2746},"AI agents can automate the documentation process that developers often skip",[2747,2731,2748],"AI Automation","Process Improvement",{"text":2750,"tools":2751},"Context engineering helps maintain focus and capture important decisions during development",[2641,2752,2753],"Decision Making","Project Documentation",[2755,2759,2762,2766],{"name":2756,"url":2757,"description":2758,"featured":54},"Retrospective Best Practices","https://www.atlassian.com/agile/scrum/retrospectives","Guide to conducting effective retrospectives in agile development",{"name":2760,"url":1181,"description":2761,"featured":54},"Knowledge Management Tools","Tools for creating and managing team knowledge bases",{"name":2763,"url":2764,"description":2765,"featured":54},"Decision Tree Documentation","https://www.lucidchart.com/pages/decision-tree","Resources for creating and documenting decision trees",{"name":2767,"url":1938,"description":2768,"featured":54},"AI-Assisted Documentation","AI tools for automating documentation and knowledge capture",[2770,2773,2777,2780,2783,2786,2789,2792,2795],{"title":2771,"url":2772,"timestamp":70},"Introduction to learning from failure and vibe coding","https://youtu.be/hlDGl4XTzsw?t=0",{"title":2774,"url":2775,"timestamp":2776},"Jason's approach to capturing knowledge during rapid development","https://youtu.be/hlDGl4XTzsw?t=12","00:00:12",{"title":2778,"url":2779,"timestamp":331},"The importance of knowledge transfer for collaborative projects","https://youtu.be/hlDGl4XTzsw?t=120",{"title":2781,"url":2782,"timestamp":158},"Ryan's perspective on DevOps and team knowledge sharing","https://youtu.be/hlDGl4XTzsw?t=180",{"title":2784,"url":2785,"timestamp":338},"Automated retrospective system demonstration","https://youtu.be/hlDGl4XTzsw?t=300",{"title":2787,"url":2788,"timestamp":642},"Team knowledge base and decision documentation","https://youtu.be/hlDGl4XTzsw?t=420",{"title":2790,"url":2791,"timestamp":2598},"Ryan's concept of alla prima and teaching others to paint quickly","https://youtu.be/hlDGl4XTzsw?t=535",{"title":2793,"url":2794,"timestamp":1221},"The importance of walking the walk in development best practices","https://youtu.be/hlDGl4XTzsw?t=660",{"title":2796,"url":2797,"timestamp":170},"Future plans for step-by-step vibe coding guide","https://youtu.be/hlDGl4XTzsw?t=720","Jason Hand introduces his innovative approach to capturing knowledge during AI-assisted development sessions. He demonstrates an automated retrospective system that creates real-time documentation, team knowledge bases, and decision trees during vibe coding sessions. The episode explores the importance of knowledge transfer for collaborative projects, the concept of 'alla prima' in development, and how AI agents can automate the documentation process that developers often skip. Perfect for teams working on AI-assisted projects who need strategies for maintaining institutional knowledge and improving collaborative development practices.","src/content/episodes/ep37.mdx","1be602f5061e2c84","ep37.mdx"]